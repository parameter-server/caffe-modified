I0702 00:34:48.750244  4664 caffe.cpp:178] Use CPU.
I0702 00:34:48.751008 32261 caffe.cpp:178] Use CPU.
I0702 00:34:48.751701 20914 caffe.cpp:178] Use CPU.
I0702 00:34:48.752465 13010 caffe.cpp:178] Use CPU.
I0702 00:34:48.809976 20914 solver.cpp:68] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.1
display: 100
max_iter: 64000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 20000
snapshot_prefix: "cifar10_res20_4nodes"
solver_mode: CPU
net: "res20_cifar_train_test.prototxt"
stepvalue: 32000
stepvalue: 48000
I0702 00:34:48.809657 32261 solver.cpp:68] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.1
display: 100
max_iter: 64000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 20000
snapshot_prefix: "cifar10_res20_4nodes"
solver_mode: CPU
net: "res20_cifar_train_test.prototxt"
stepvalue: 32000
stepvalue: 48000
I0702 00:34:48.809453  4664 solver.cpp:68] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.1
display: 100
max_iter: 64000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 20000
snapshot_prefix: "cifar10_res20_4nodes"
solver_mode: CPU
net: "res20_cifar_train_test.prototxt"
stepvalue: 32000
stepvalue: 48000
I0702 00:34:48.810353 13010 solver.cpp:68] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.1
display: 100
max_iter: 64000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 20000
snapshot_prefix: "cifar10_res20_4nodes"
solver_mode: CPU
net: "res20_cifar_train_test.prototxt"
stepvalue: 32000
stepvalue: 48000
I0702 00:34:48.812822 32261 solver.cpp:110] Creating training net from net file: res20_cifar_train_test.prototxt
I0702 00:34:48.813827 13010 solver.cpp:110] Creating training net from net file: res20_cifar_train_test.prototxt
I0702 00:34:48.813333  4664 solver.cpp:110] Creating training net from net file: res20_cifar_train_test.prototxt
I0702 00:34:48.814136 20914 solver.cpp:110] Creating training net from net file: res20_cifar_train_test.prototxt
I0702 00:34:48.884747 32261 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0702 00:34:48.884850 32261 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0702 00:34:48.884765  4664 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0702 00:34:48.884866  4664 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0702 00:34:48.886039 13010 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0702 00:34:48.886143 13010 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0702 00:34:48.885826 20914 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I0702 00:34:48.885928 20914 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I0702 00:34:48.884871 32261 net.cpp:49] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
}
layer {
  name: "Data1"
  type: "ImageData"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.0078125
    mirror: true
    crop_size: 32
    mean_value: 128
  }
  image_data_param {
    source: "/HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/train/label.txt"
    batch_size: 32
    shuffle: true
    new_height: 40
    new_width: 40
    is_color: true
    root_folder: "/HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/train/Img/"
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
I0702 00:34:48.884889  4664 net.cpp:49] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
}
layer {
  name: "Data1"
  type: "ImageData"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.0078125
    mirror: true
    crop_size: 32
    mean_value: 128
  }
  image_data_param {
    source: "/HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/train/label.txt"
    batch_size: 32
    shuffle: true
    new_height: 40
    new_width: 40
    is_color: true
    root_folder: "/HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/train/Img/"
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  type: "ReLU"
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
I0702 00:34:48.886167 13010 net.cpp:49] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
}
layer {
  name: "Data1"
  type: "ImageData"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.0078125
    mirror: true
    crop_size: 32
    mean_value: 128
  }
  image_data_param {
    source: "/HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/train/label.txt"
    batch_size: 32
    shuffle: true
    new_height: 40
    new_width: 40
    is_color: true
    root_folder: "/HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/train/Img/"
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
  type: "ReLU"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
I0702 00:34:48.885951 20914 net.cpp:49] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
}
layer {
  name: "Data1"
  type: "ImageData"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.0078125
    mirror: true
    crop_size: 32
    mean_value: 128
  }
  image_data_param {
    source: "/HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/train/label.txt"
    batch_size: 32
    shuffle: true
    new_height: 40
    new_width: 40
    is_color: true
    root_folder: "/HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/train/Img/"
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  type: "ReLU"
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
    }
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
  type: "ReLU"
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
  type: "ReLU"
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
I0702 00:34:48.887032 32261 layer_factory.hpp:77] Creating layer Data1
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    }
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
  type: "ReLU"
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
  type: "ReLU"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
I0702 00:34:48.887178  4664 layer_factory.hpp:77] Creating layer Data1
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    }
  }
}
layer {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    }
  }
}
layer {
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
I0702 00:34:48.888371 13010 layer_factory.hpp:77] Creating layer Data1
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
I0702 00:34:48.888489 32261 net.cpp:106] Creating Layer Data1
I0702 00:34:48.888514 32261 net.cpp:411] Data1 -> Data1
I0702 00:34:48.888697  4664 net.cpp:106] Creating Layer Data1
I0702 00:34:48.888726  4664 net.cpp:411] Data1 -> Data1
I0702 00:34:48.889987 13010 net.cpp:106] Creating Layer Data1
I0702 00:34:48.890017 13010 net.cpp:411] Data1 -> Data1
I0702 00:34:48.889782 32261 net.cpp:411] Data1 -> Data2
I0702 00:34:48.889816  4664 net.cpp:411] Data1 -> Data2
I0702 00:34:48.890941 13010 net.cpp:411] Data1 -> Data2
I0702 00:34:48.895647  4664 image_data_layer.cpp:49] 1 MPI_Barrier 0
I0702 00:34:48.896540 13010 image_data_layer.cpp:49] 3 MPI_Barrier 0
I0702 00:34:48.895855 32261 image_data_layer.cpp:49] 2 MPI_Barrier 0
I0702 00:34:48.888221 20914 layer_factory.hpp:77] Creating layer Data1
I0702 00:34:48.889878 20914 net.cpp:106] Creating Layer Data1
I0702 00:34:48.889909 20914 net.cpp:411] Data1 -> Data1
I0702 00:34:48.890805 20914 net.cpp:411] Data1 -> Data2
I0702 00:34:48.896175 20914 image_data_layer.cpp:49] 0 MPI_Barrier 0
I0702 00:34:48.896199 20914 image_data_layer.cpp:51] 0: Opening file /HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/train/label.txt
I0702 00:34:48.978235 20914 image_data_layer.cpp:58] List loaded
I0702 00:34:48.978255 20914 image_data_layer.cpp:61] Shuffling data
I0702 00:34:48.983741 20914 image_data_layer.cpp:49] 0 MPI_Barrier 1
I0702 00:34:48.983207  4664 image_data_layer.cpp:49] 1 MPI_Barrier 1
I0702 00:34:48.983217  4664 image_data_layer.cpp:51] 1: Opening file /HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/train/label.txt
I0702 00:34:48.983417 32261 image_data_layer.cpp:49] 2 MPI_Barrier 1
I0702 00:34:48.984110 13010 image_data_layer.cpp:49] 3 MPI_Barrier 1
I0702 00:34:49.014322  4664 image_data_layer.cpp:58] List loaded
I0702 00:34:49.014343  4664 image_data_layer.cpp:61] Shuffling data
I0702 00:34:49.020233 20914 image_data_layer.cpp:49] 0 MPI_Barrier 2
I0702 00:34:49.019699  4664 image_data_layer.cpp:49] 1 MPI_Barrier 2
I0702 00:34:49.019902 32261 image_data_layer.cpp:49] 2 MPI_Barrier 2
I0702 00:34:49.019913 32261 image_data_layer.cpp:51] 2: Opening file /HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/train/label.txt
I0702 00:34:49.020598 13010 image_data_layer.cpp:49] 3 MPI_Barrier 2
I0702 00:34:49.050423 32261 image_data_layer.cpp:58] List loaded
I0702 00:34:49.050444 32261 image_data_layer.cpp:61] Shuffling data
I0702 00:34:49.056133 20914 image_data_layer.cpp:49] 0 MPI_Barrier 3
I0702 00:34:49.056143 20914 image_data_layer.cpp:69] 0: A total of 50000 images.
I0702 00:34:49.055807 32261 image_data_layer.cpp:49] 2 MPI_Barrier 3
I0702 00:34:49.055829 32261 image_data_layer.cpp:69] 2: A total of 50000 images.
I0702 00:34:49.055603  4664 image_data_layer.cpp:49] 1 MPI_Barrier 3
I0702 00:34:49.055613  4664 image_data_layer.cpp:69] 1: A total of 50000 images.
I0702 00:34:49.056495 13010 image_data_layer.cpp:49] 3 MPI_Barrier 3
I0702 00:34:49.056504 13010 image_data_layer.cpp:51] 3: Opening file /HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/train/label.txt
I0702 00:34:49.086647 13010 image_data_layer.cpp:58] List loaded
I0702 00:34:49.086668 13010 image_data_layer.cpp:61] Shuffling data
I0702 00:34:49.092108 13010 image_data_layer.cpp:69] 3: A total of 50000 images.
I0702 00:34:49.120590 32261 image_data_layer.cpp:96] output data size: 32,3,32,32
I0702 00:34:49.121459 20914 image_data_layer.cpp:96] output data size: 32,3,32,32
I0702 00:34:49.122093 13010 image_data_layer.cpp:96] output data size: 32,3,32,32
I0702 00:34:49.121487 32261 net.cpp:150] Setting up Data1
I0702 00:34:49.121510 32261 net.cpp:157] Top shape: 32 3 32 32 (98304)
I0702 00:34:49.121577 32261 net.cpp:157] Top shape: 32 (32)
I0702 00:34:49.121588 32261 net.cpp:165] Memory required for data: 393344
I0702 00:34:49.121600 32261 layer_factory.hpp:77] Creating layer Convolution1
I0702 00:34:49.121637 32261 net.cpp:106] Creating Layer Convolution1
I0702 00:34:49.121649 32261 net.cpp:454] Convolution1 <- Data1
I0702 00:34:49.121672 32261 net.cpp:411] Convolution1 -> Convolution1
I0702 00:34:49.122468 20914 net.cpp:150] Setting up Data1
I0702 00:34:49.122488 20914 net.cpp:157] Top shape: 32 3 32 32 (98304)
I0702 00:34:49.122579 20914 net.cpp:157] Top shape: 32 (32)
I0702 00:34:49.122593 20914 net.cpp:165] Memory required for data: 393344
I0702 00:34:49.122606 20914 layer_factory.hpp:77] Creating layer Convolution1
I0702 00:34:49.122643 20914 net.cpp:106] Creating Layer Convolution1
I0702 00:34:49.122655 20914 net.cpp:454] Convolution1 <- Data1
I0702 00:34:49.122679 20914 net.cpp:411] Convolution1 -> Convolution1
I0702 00:34:49.122987 13010 net.cpp:150] Setting up Data1
I0702 00:34:49.123008 13010 net.cpp:157] Top shape: 32 3 32 32 (98304)
I0702 00:34:49.123093 13010 net.cpp:157] Top shape: 32 (32)
I0702 00:34:49.123107 13010 net.cpp:165] Memory required for data: 393344
I0702 00:34:49.123119 13010 layer_factory.hpp:77] Creating layer Convolution1
I0702 00:34:49.123155 13010 net.cpp:106] Creating Layer Convolution1
I0702 00:34:49.123168 13010 net.cpp:454] Convolution1 <- Data1
I0702 00:34:49.123191 13010 net.cpp:411] Convolution1 -> Convolution1
I0702 00:34:49.123625 32261 net.cpp:150] Setting up Convolution1
I0702 00:34:49.123647 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.123659 32261 net.cpp:165] Memory required for data: 2490496
I0702 00:34:49.123747 32261 layer_factory.hpp:77] Creating layer BatchNorm1
I0702 00:34:49.123805 32261 net.cpp:106] Creating Layer BatchNorm1
I0702 00:34:49.123819 32261 net.cpp:454] BatchNorm1 <- Convolution1
I0702 00:34:49.123831 32261 net.cpp:397] BatchNorm1 -> Convolution1 (in-place)
I0702 00:34:49.124747 20914 net.cpp:150] Setting up Convolution1
I0702 00:34:49.124768 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.124778 20914 net.cpp:165] Memory required for data: 2490496
I0702 00:34:49.125185 13010 net.cpp:150] Setting up Convolution1
I0702 00:34:49.125207 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.125219 13010 net.cpp:165] Memory required for data: 2490496
I0702 00:34:49.124899 20914 layer_factory.hpp:77] Creating layer BatchNorm1
I0702 00:34:49.125308 13010 layer_factory.hpp:77] Creating layer BatchNorm1
I0702 00:34:49.125366 13010 net.cpp:106] Creating Layer BatchNorm1
I0702 00:34:49.125012 20914 net.cpp:106] Creating Layer BatchNorm1
I0702 00:34:49.125028 20914 net.cpp:454] BatchNorm1 <- Convolution1
I0702 00:34:49.125381 13010 net.cpp:454] BatchNorm1 <- Convolution1
I0702 00:34:49.125062 20914 net.cpp:397] BatchNorm1 -> Convolution1 (in-place)
I0702 00:34:49.125392 13010 net.cpp:397] BatchNorm1 -> Convolution1 (in-place)
I0702 00:34:49.125111 32261 net.cpp:150] Setting up BatchNorm1
I0702 00:34:49.125138 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.125151 32261 net.cpp:165] Memory required for data: 4587648
I0702 00:34:49.125219 32261 layer_factory.hpp:77] Creating layer Scale1
I0702 00:34:49.125285 32261 net.cpp:106] Creating Layer Scale1
I0702 00:34:49.125300 32261 net.cpp:454] Scale1 <- Convolution1
I0702 00:34:49.125311 32261 net.cpp:397] Scale1 -> Convolution1 (in-place)
I0702 00:34:49.125396 32261 layer_factory.hpp:77] Creating layer Scale1
I0702 00:34:49.126410 13010 net.cpp:150] Setting up BatchNorm1
I0702 00:34:49.126432 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.126444 13010 net.cpp:165] Memory required for data: 4587648
I0702 00:34:49.126505 13010 layer_factory.hpp:77] Creating layer Scale1
I0702 00:34:49.126565 13010 net.cpp:106] Creating Layer Scale1
I0702 00:34:49.126580 13010 net.cpp:454] Scale1 <- Convolution1
I0702 00:34:49.126591 13010 net.cpp:397] Scale1 -> Convolution1 (in-place)
I0702 00:34:49.126240 20914 net.cpp:150] Setting up BatchNorm1
I0702 00:34:49.126268 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.126284 20914 net.cpp:165] Memory required for data: 4587648
I0702 00:34:49.126677 13010 layer_factory.hpp:77] Creating layer Scale1
I0702 00:34:49.126371 20914 layer_factory.hpp:77] Creating layer Scale1
I0702 00:34:49.126444 20914 net.cpp:106] Creating Layer Scale1
I0702 00:34:49.126459 20914 net.cpp:454] Scale1 <- Convolution1
I0702 00:34:49.126473 20914 net.cpp:397] Scale1 -> Convolution1 (in-place)
I0702 00:34:49.126591 20914 layer_factory.hpp:77] Creating layer Scale1
I0702 00:34:49.129623 32261 net.cpp:150] Setting up Scale1
I0702 00:34:49.129647 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.129657 32261 net.cpp:165] Memory required for data: 6684800
I0702 00:34:49.129673 32261 layer_factory.hpp:77] Creating layer ReLU1
I0702 00:34:49.129727 32261 net.cpp:106] Creating Layer ReLU1
I0702 00:34:49.129742 32261 net.cpp:454] ReLU1 <- Convolution1
I0702 00:34:49.129758 32261 net.cpp:397] ReLU1 -> Convolution1 (in-place)
I0702 00:34:49.129775 32261 net.cpp:150] Setting up ReLU1
I0702 00:34:49.129781 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.129792 32261 net.cpp:165] Memory required for data: 8781952
I0702 00:34:49.129799 32261 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0702 00:34:49.129847 32261 net.cpp:106] Creating Layer Convolution1_ReLU1_0_split
I0702 00:34:49.129859 32261 net.cpp:454] Convolution1_ReLU1_0_split <- Convolution1
I0702 00:34:49.129869 32261 net.cpp:411] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0702 00:34:49.129894 32261 net.cpp:411] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0702 00:34:49.129912 32261 net.cpp:150] Setting up Convolution1_ReLU1_0_split
I0702 00:34:49.129921 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.129931 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.129940 32261 net.cpp:165] Memory required for data: 12976256
I0702 00:34:49.129946 32261 layer_factory.hpp:77] Creating layer Convolution2
I0702 00:34:49.129971 32261 net.cpp:106] Creating Layer Convolution2
I0702 00:34:49.129981 32261 net.cpp:454] Convolution2 <- Convolution1_ReLU1_0_split_0
I0702 00:34:49.129992 32261 net.cpp:411] Convolution2 -> Convolution2
I0702 00:34:49.130678 13010 net.cpp:150] Setting up Scale1
I0702 00:34:49.130699 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.130712 13010 net.cpp:165] Memory required for data: 6684800
I0702 00:34:49.130726 13010 layer_factory.hpp:77] Creating layer ReLU1
I0702 00:34:49.130779 13010 net.cpp:106] Creating Layer ReLU1
I0702 00:34:49.130792 13010 net.cpp:454] ReLU1 <- Convolution1
I0702 00:34:49.130803 13010 net.cpp:397] ReLU1 -> Convolution1 (in-place)
I0702 00:34:49.130816 13010 net.cpp:150] Setting up ReLU1
I0702 00:34:49.130823 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.130180 32261 net.cpp:150] Setting up Convolution2
I0702 00:34:49.130833 13010 net.cpp:165] Memory required for data: 8781952
I0702 00:34:49.130841 13010 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0702 00:34:49.130197 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.130206 32261 net.cpp:165] Memory required for data: 15073408
I0702 00:34:49.130890 13010 net.cpp:106] Creating Layer Convolution1_ReLU1_0_split
I0702 00:34:49.130223 32261 layer_factory.hpp:77] Creating layer BatchNorm2
I0702 00:34:49.130904 13010 net.cpp:454] Convolution1_ReLU1_0_split <- Convolution1
I0702 00:34:49.130239 32261 net.cpp:106] Creating Layer BatchNorm2
I0702 00:34:49.130246 32261 net.cpp:454] BatchNorm2 <- Convolution2
I0702 00:34:49.130914 13010 net.cpp:411] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0702 00:34:49.130264 32261 net.cpp:397] BatchNorm2 -> Convolution2 (in-place)
I0702 00:34:49.130939 13010 net.cpp:411] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0702 00:34:49.130955 13010 net.cpp:150] Setting up Convolution1_ReLU1_0_split
I0702 00:34:49.130964 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.130296 32261 net.cpp:150] Setting up BatchNorm2
I0702 00:34:49.130620 20914 net.cpp:150] Setting up Scale1
I0702 00:34:49.130306 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.130647 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.130314 32261 net.cpp:165] Memory required for data: 17170560
I0702 00:34:49.130973 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.130659 20914 net.cpp:165] Memory required for data: 6684800
I0702 00:34:49.130673 20914 layer_factory.hpp:77] Creating layer ReLU1
I0702 00:34:49.130981 13010 net.cpp:165] Memory required for data: 12976256
I0702 00:34:49.130329 32261 layer_factory.hpp:77] Creating layer Scale2
I0702 00:34:49.130988 13010 layer_factory.hpp:77] Creating layer Convolution2
I0702 00:34:49.130734 20914 net.cpp:106] Creating Layer ReLU1
I0702 00:34:49.130347 32261 net.cpp:106] Creating Layer Scale2
I0702 00:34:49.131008 13010 net.cpp:106] Creating Layer Convolution2
I0702 00:34:49.130749 20914 net.cpp:454] ReLU1 <- Convolution1
I0702 00:34:49.130355 32261 net.cpp:454] Scale2 <- Convolution2
I0702 00:34:49.131018 13010 net.cpp:454] Convolution2 <- Convolution1_ReLU1_0_split_0
I0702 00:34:49.130760 20914 net.cpp:397] ReLU1 -> Convolution1 (in-place)
I0702 00:34:49.130364 32261 net.cpp:397] Scale2 -> Convolution2 (in-place)
I0702 00:34:49.131029 13010 net.cpp:411] Convolution2 -> Convolution2
I0702 00:34:49.130774 20914 net.cpp:150] Setting up ReLU1
I0702 00:34:49.130780 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.130383 32261 layer_factory.hpp:77] Creating layer Scale2
I0702 00:34:49.130789 20914 net.cpp:165] Memory required for data: 8781952
I0702 00:34:49.130797 20914 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0702 00:34:49.130847 20914 net.cpp:106] Creating Layer Convolution1_ReLU1_0_split
I0702 00:34:49.130417 32261 net.cpp:150] Setting up Scale2
I0702 00:34:49.130861 20914 net.cpp:454] Convolution1_ReLU1_0_split <- Convolution1
I0702 00:34:49.130429 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.131216 13010 net.cpp:150] Setting up Convolution2
I0702 00:34:49.130875 20914 net.cpp:411] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0702 00:34:49.130437 32261 net.cpp:165] Memory required for data: 19267712
I0702 00:34:49.130901 20914 net.cpp:411] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0702 00:34:49.130450 32261 layer_factory.hpp:77] Creating layer ReLU2
I0702 00:34:49.130918 20914 net.cpp:150] Setting up Convolution1_ReLU1_0_split
I0702 00:34:49.130458 32261 net.cpp:106] Creating Layer ReLU2
I0702 00:34:49.131230 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.131243 13010 net.cpp:165] Memory required for data: 15073408
I0702 00:34:49.130928 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.130467 32261 net.cpp:454] ReLU2 <- Convolution2
I0702 00:34:49.131259 13010 layer_factory.hpp:77] Creating layer BatchNorm2
I0702 00:34:49.130937 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.130478 32261 net.cpp:397] ReLU2 -> Convolution2 (in-place)
I0702 00:34:49.131275 13010 net.cpp:106] Creating Layer BatchNorm2
I0702 00:34:49.130946 20914 net.cpp:165] Memory required for data: 12976256
I0702 00:34:49.130489 32261 net.cpp:150] Setting up ReLU2
I0702 00:34:49.131284 13010 net.cpp:454] BatchNorm2 <- Convolution2
I0702 00:34:49.130952 20914 layer_factory.hpp:77] Creating layer Convolution2
I0702 00:34:49.130497 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.130973 20914 net.cpp:106] Creating Layer Convolution2
I0702 00:34:49.130506 32261 net.cpp:165] Memory required for data: 21364864
I0702 00:34:49.131294 13010 net.cpp:397] BatchNorm2 -> Convolution2 (in-place)
I0702 00:34:49.130983 20914 net.cpp:454] Convolution2 <- Convolution1_ReLU1_0_split_0
I0702 00:34:49.130512 32261 layer_factory.hpp:77] Creating layer Convolution3
I0702 00:34:49.131325 13010 net.cpp:150] Setting up BatchNorm2
I0702 00:34:49.130995 20914 net.cpp:411] Convolution2 -> Convolution2
I0702 00:34:49.131333 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.130532 32261 net.cpp:106] Creating Layer Convolution3
I0702 00:34:49.131342 13010 net.cpp:165] Memory required for data: 17170560
I0702 00:34:49.130542 32261 net.cpp:454] Convolution3 <- Convolution2
I0702 00:34:49.131356 13010 layer_factory.hpp:77] Creating layer Scale2
I0702 00:34:49.130553 32261 net.cpp:411] Convolution3 -> Convolution3
I0702 00:34:49.131369 13010 net.cpp:106] Creating Layer Scale2
I0702 00:34:49.130679 32261 net.cpp:150] Setting up Convolution3
I0702 00:34:49.131376 13010 net.cpp:454] Scale2 <- Convolution2
I0702 00:34:49.130692 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.130705 32261 net.cpp:165] Memory required for data: 23462016
I0702 00:34:49.130717 32261 layer_factory.hpp:77] Creating layer BatchNorm3
I0702 00:34:49.130728 32261 net.cpp:106] Creating Layer BatchNorm3
I0702 00:34:49.131388 13010 net.cpp:397] Scale2 -> Convolution2 (in-place)
I0702 00:34:49.131417 13010 layer_factory.hpp:77] Creating layer Scale2
I0702 00:34:49.131459 13010 net.cpp:150] Setting up Scale2
I0702 00:34:49.130735 32261 net.cpp:454] BatchNorm3 <- Convolution3
I0702 00:34:49.131469 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.130748 32261 net.cpp:397] BatchNorm3 -> Convolution3 (in-place)
I0702 00:34:49.130771 32261 net.cpp:150] Setting up BatchNorm3
I0702 00:34:49.131175 20914 net.cpp:150] Setting up Convolution2
I0702 00:34:49.130780 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.130789 32261 net.cpp:165] Memory required for data: 25559168
I0702 00:34:49.131484 13010 net.cpp:165] Memory required for data: 19267712
I0702 00:34:49.131191 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.131207 20914 net.cpp:165] Memory required for data: 15073408
I0702 00:34:49.130808 32261 layer_factory.hpp:77] Creating layer Scale3
I0702 00:34:49.131495 13010 layer_factory.hpp:77] Creating layer ReLU2
I0702 00:34:49.131505 13010 net.cpp:106] Creating Layer ReLU2
I0702 00:34:49.131242 20914 layer_factory.hpp:77] Creating layer BatchNorm2
I0702 00:34:49.131511 13010 net.cpp:454] ReLU2 <- Convolution2
I0702 00:34:49.131258 20914 net.cpp:106] Creating Layer BatchNorm2
I0702 00:34:49.130820 32261 net.cpp:106] Creating Layer Scale3
I0702 00:34:49.131520 13010 net.cpp:397] ReLU2 -> Convolution2 (in-place)
I0702 00:34:49.131268 20914 net.cpp:454] BatchNorm2 <- Convolution2
I0702 00:34:49.130830 32261 net.cpp:454] Scale3 <- Convolution3
I0702 00:34:49.131531 13010 net.cpp:150] Setting up ReLU2
I0702 00:34:49.131278 20914 net.cpp:397] BatchNorm2 -> Convolution2 (in-place)
I0702 00:34:49.130841 32261 net.cpp:397] Scale3 -> Convolution3 (in-place)
I0702 00:34:49.131538 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.131309 20914 net.cpp:150] Setting up BatchNorm2
I0702 00:34:49.130857 32261 layer_factory.hpp:77] Creating layer Scale3
I0702 00:34:49.131547 13010 net.cpp:165] Memory required for data: 21364864
I0702 00:34:49.131323 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.130888 32261 net.cpp:150] Setting up Scale3
I0702 00:34:49.131553 13010 layer_factory.hpp:77] Creating layer Convolution3
I0702 00:34:49.131332 20914 net.cpp:165] Memory required for data: 17170560
I0702 00:34:49.130898 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.131347 20914 layer_factory.hpp:77] Creating layer Scale2
I0702 00:34:49.130910 32261 net.cpp:165] Memory required for data: 27656320
I0702 00:34:49.131572 13010 net.cpp:106] Creating Layer Convolution3
I0702 00:34:49.131361 20914 net.cpp:106] Creating Layer Scale2
I0702 00:34:49.131580 13010 net.cpp:454] Convolution3 <- Convolution2
I0702 00:34:49.131368 20914 net.cpp:454] Scale2 <- Convolution2
I0702 00:34:49.131593 13010 net.cpp:411] Convolution3 -> Convolution3
I0702 00:34:49.131382 20914 net.cpp:397] Scale2 -> Convolution2 (in-place)
I0702 00:34:49.130923 32261 layer_factory.hpp:77] Creating layer Eltwise1
I0702 00:34:49.131716 13010 net.cpp:150] Setting up Convolution3
I0702 00:34:49.131405 20914 layer_factory.hpp:77] Creating layer Scale2
I0702 00:34:49.130983 32261 net.cpp:106] Creating Layer Eltwise1
I0702 00:34:49.131727 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.131446 20914 net.cpp:150] Setting up Scale2
I0702 00:34:49.130997 32261 net.cpp:454] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0702 00:34:49.131736 13010 net.cpp:165] Memory required for data: 23462016
I0702 00:34:49.131458 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.131006 32261 net.cpp:454] Eltwise1 <- Convolution3
I0702 00:34:49.131475 20914 net.cpp:165] Memory required for data: 19267712
I0702 00:34:49.131016 32261 net.cpp:411] Eltwise1 -> Eltwise1
I0702 00:34:49.131748 13010 layer_factory.hpp:77] Creating layer BatchNorm3
I0702 00:34:49.131489 20914 layer_factory.hpp:77] Creating layer ReLU2
I0702 00:34:49.131763 13010 net.cpp:106] Creating Layer BatchNorm3
I0702 00:34:49.131498 20914 net.cpp:106] Creating Layer ReLU2
I0702 00:34:49.131772 13010 net.cpp:454] BatchNorm3 <- Convolution3
I0702 00:34:49.131505 20914 net.cpp:454] ReLU2 <- Convolution2
I0702 00:34:49.131781 13010 net.cpp:397] BatchNorm3 -> Convolution3 (in-place)
I0702 00:34:49.131513 20914 net.cpp:397] ReLU2 -> Convolution2 (in-place)
I0702 00:34:49.131808 13010 net.cpp:150] Setting up BatchNorm3
I0702 00:34:49.131525 20914 net.cpp:150] Setting up ReLU2
I0702 00:34:49.131816 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.131531 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.131825 13010 net.cpp:165] Memory required for data: 25559168
I0702 00:34:49.131539 20914 net.cpp:165] Memory required for data: 21364864
I0702 00:34:49.131846 13010 layer_factory.hpp:77] Creating layer Scale3
I0702 00:34:49.131546 20914 layer_factory.hpp:77] Creating layer Convolution3
I0702 00:34:49.131858 13010 net.cpp:106] Creating Layer Scale3
I0702 00:34:49.131567 20914 net.cpp:106] Creating Layer Convolution3
I0702 00:34:49.131578 20914 net.cpp:454] Convolution3 <- Convolution2
I0702 00:34:49.131592 20914 net.cpp:411] Convolution3 -> Convolution3
I0702 00:34:49.131866 13010 net.cpp:454] Scale3 <- Convolution3
I0702 00:34:49.131875 13010 net.cpp:397] Scale3 -> Convolution3 (in-place)
I0702 00:34:49.131896 13010 layer_factory.hpp:77] Creating layer Scale3
I0702 00:34:49.131928 13010 net.cpp:150] Setting up Scale3
I0702 00:34:49.131938 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.131947 13010 net.cpp:165] Memory required for data: 27656320
I0702 00:34:49.131958 13010 layer_factory.hpp:77] Creating layer Eltwise1
I0702 00:34:49.132024 13010 net.cpp:106] Creating Layer Eltwise1
I0702 00:34:49.132038 13010 net.cpp:454] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0702 00:34:49.132046 13010 net.cpp:454] Eltwise1 <- Convolution3
I0702 00:34:49.132056 13010 net.cpp:411] Eltwise1 -> Eltwise1
I0702 00:34:49.131783 20914 net.cpp:150] Setting up Convolution3
I0702 00:34:49.131799 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.131809 20914 net.cpp:165] Memory required for data: 23462016
I0702 00:34:49.131821 20914 layer_factory.hpp:77] Creating layer BatchNorm3
I0702 00:34:49.131839 20914 net.cpp:106] Creating Layer BatchNorm3
I0702 00:34:49.131847 20914 net.cpp:454] BatchNorm3 <- Convolution3
I0702 00:34:49.131857 20914 net.cpp:397] BatchNorm3 -> Convolution3 (in-place)
I0702 00:34:49.131889 20914 net.cpp:150] Setting up BatchNorm3
I0702 00:34:49.131899 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.131909 20914 net.cpp:165] Memory required for data: 25559168
I0702 00:34:49.131932 20914 layer_factory.hpp:77] Creating layer Scale3
I0702 00:34:49.131945 20914 net.cpp:106] Creating Layer Scale3
I0702 00:34:49.131953 20914 net.cpp:454] Scale3 <- Convolution3
I0702 00:34:49.131961 20914 net.cpp:397] Scale3 -> Convolution3 (in-place)
I0702 00:34:49.131984 20914 layer_factory.hpp:77] Creating layer Scale3
I0702 00:34:49.132025 20914 net.cpp:150] Setting up Scale3
I0702 00:34:49.132036 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.132045 20914 net.cpp:165] Memory required for data: 27656320
I0702 00:34:49.132056 20914 layer_factory.hpp:77] Creating layer Eltwise1
I0702 00:34:49.132128 20914 net.cpp:106] Creating Layer Eltwise1
I0702 00:34:49.132144 20914 net.cpp:454] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0702 00:34:49.132153 20914 net.cpp:454] Eltwise1 <- Convolution3
I0702 00:34:49.132163 20914 net.cpp:411] Eltwise1 -> Eltwise1
I0702 00:34:49.132050 32261 net.cpp:150] Setting up Eltwise1
I0702 00:34:49.132073 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.132084 32261 net.cpp:165] Memory required for data: 29753472
I0702 00:34:49.132093 32261 layer_factory.hpp:77] Creating layer ReLU3
I0702 00:34:49.132104 32261 net.cpp:106] Creating Layer ReLU3
I0702 00:34:49.132112 32261 net.cpp:454] ReLU3 <- Eltwise1
I0702 00:34:49.132122 32261 net.cpp:397] ReLU3 -> Eltwise1 (in-place)
I0702 00:34:49.132134 32261 net.cpp:150] Setting up ReLU3
I0702 00:34:49.132141 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.132149 32261 net.cpp:165] Memory required for data: 31850624
I0702 00:34:49.132156 32261 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0702 00:34:49.132172 32261 net.cpp:106] Creating Layer Eltwise1_ReLU3_0_split
I0702 00:34:49.132182 32261 net.cpp:454] Eltwise1_ReLU3_0_split <- Eltwise1
I0702 00:34:49.132191 32261 net.cpp:411] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0702 00:34:49.132205 32261 net.cpp:411] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0702 00:34:49.132220 32261 net.cpp:150] Setting up Eltwise1_ReLU3_0_split
I0702 00:34:49.132226 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.132236 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.132243 32261 net.cpp:165] Memory required for data: 36044928
I0702 00:34:49.132249 32261 layer_factory.hpp:77] Creating layer Convolution4
I0702 00:34:49.132985 13010 net.cpp:150] Setting up Eltwise1
I0702 00:34:49.132288 32261 net.cpp:106] Creating Layer Convolution4
I0702 00:34:49.132302 32261 net.cpp:454] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0702 00:34:49.133008 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.132313 32261 net.cpp:411] Convolution4 -> Convolution4
I0702 00:34:49.133019 13010 net.cpp:165] Memory required for data: 29753472
I0702 00:34:49.133028 13010 layer_factory.hpp:77] Creating layer ReLU3
I0702 00:34:49.133039 13010 net.cpp:106] Creating Layer ReLU3
I0702 00:34:49.133047 13010 net.cpp:454] ReLU3 <- Eltwise1
I0702 00:34:49.133057 13010 net.cpp:397] ReLU3 -> Eltwise1 (in-place)
I0702 00:34:49.133069 13010 net.cpp:150] Setting up ReLU3
I0702 00:34:49.133076 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133085 13010 net.cpp:165] Memory required for data: 31850624
I0702 00:34:49.132444 32261 net.cpp:150] Setting up Convolution4
I0702 00:34:49.133091 13010 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0702 00:34:49.132457 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.132467 32261 net.cpp:165] Memory required for data: 38142080
I0702 00:34:49.133101 13010 net.cpp:106] Creating Layer Eltwise1_ReLU3_0_split
I0702 00:34:49.132479 32261 layer_factory.hpp:77] Creating layer BatchNorm4
I0702 00:34:49.133108 13010 net.cpp:454] Eltwise1_ReLU3_0_split <- Eltwise1
I0702 00:34:49.133122 13010 net.cpp:411] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0702 00:34:49.133138 13010 net.cpp:411] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0702 00:34:49.132493 32261 net.cpp:106] Creating Layer BatchNorm4
I0702 00:34:49.133153 13010 net.cpp:150] Setting up Eltwise1_ReLU3_0_split
I0702 00:34:49.132499 32261 net.cpp:454] BatchNorm4 <- Convolution4
I0702 00:34:49.133162 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.132513 32261 net.cpp:397] BatchNorm4 -> Convolution4 (in-place)
I0702 00:34:49.133170 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133178 13010 net.cpp:165] Memory required for data: 36044928
I0702 00:34:49.132537 32261 net.cpp:150] Setting up BatchNorm4
I0702 00:34:49.132546 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.132555 32261 net.cpp:165] Memory required for data: 40239232
I0702 00:34:49.133185 13010 layer_factory.hpp:77] Creating layer Convolution4
I0702 00:34:49.132573 32261 layer_factory.hpp:77] Creating layer Scale4
I0702 00:34:49.133208 13010 net.cpp:106] Creating Layer Convolution4
I0702 00:34:49.133219 13010 net.cpp:454] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0702 00:34:49.133229 13010 net.cpp:411] Convolution4 -> Convolution4
I0702 00:34:49.132947 20914 net.cpp:150] Setting up Eltwise1
I0702 00:34:49.132586 32261 net.cpp:106] Creating Layer Scale4
I0702 00:34:49.132593 32261 net.cpp:454] Scale4 <- Convolution4
I0702 00:34:49.132972 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.132983 20914 net.cpp:165] Memory required for data: 29753472
I0702 00:34:49.132602 32261 net.cpp:397] Scale4 -> Convolution4 (in-place)
I0702 00:34:49.132992 20914 layer_factory.hpp:77] Creating layer ReLU3
I0702 00:34:49.132622 32261 layer_factory.hpp:77] Creating layer Scale4
I0702 00:34:49.133360 13010 net.cpp:150] Setting up Convolution4
I0702 00:34:49.133003 20914 net.cpp:106] Creating Layer ReLU3
I0702 00:34:49.133010 20914 net.cpp:454] ReLU3 <- Eltwise1
I0702 00:34:49.133021 20914 net.cpp:397] ReLU3 -> Eltwise1 (in-place)
I0702 00:34:49.133033 20914 net.cpp:150] Setting up ReLU3
I0702 00:34:49.132663 32261 net.cpp:150] Setting up Scale4
I0702 00:34:49.133373 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133383 13010 net.cpp:165] Memory required for data: 38142080
I0702 00:34:49.133040 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.132673 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133395 13010 layer_factory.hpp:77] Creating layer BatchNorm4
I0702 00:34:49.133049 20914 net.cpp:165] Memory required for data: 31850624
I0702 00:34:49.132683 32261 net.cpp:165] Memory required for data: 42336384
I0702 00:34:49.133421 13010 net.cpp:106] Creating Layer BatchNorm4
I0702 00:34:49.133056 20914 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0702 00:34:49.132694 32261 layer_factory.hpp:77] Creating layer ReLU4
I0702 00:34:49.133430 13010 net.cpp:454] BatchNorm4 <- Convolution4
I0702 00:34:49.133065 20914 net.cpp:106] Creating Layer Eltwise1_ReLU3_0_split
I0702 00:34:49.132709 32261 net.cpp:106] Creating Layer ReLU4
I0702 00:34:49.133072 20914 net.cpp:454] Eltwise1_ReLU3_0_split <- Eltwise1
I0702 00:34:49.132716 32261 net.cpp:454] ReLU4 <- Convolution4
I0702 00:34:49.133090 20914 net.cpp:411] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0702 00:34:49.132725 32261 net.cpp:397] ReLU4 -> Convolution4 (in-place)
I0702 00:34:49.133443 13010 net.cpp:397] BatchNorm4 -> Convolution4 (in-place)
I0702 00:34:49.133111 20914 net.cpp:411] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0702 00:34:49.132735 32261 net.cpp:150] Setting up ReLU4
I0702 00:34:49.133471 13010 net.cpp:150] Setting up BatchNorm4
I0702 00:34:49.133126 20914 net.cpp:150] Setting up Eltwise1_ReLU3_0_split
I0702 00:34:49.133481 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133134 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133489 13010 net.cpp:165] Memory required for data: 40239232
I0702 00:34:49.133143 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.132742 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133507 13010 layer_factory.hpp:77] Creating layer Scale4
I0702 00:34:49.133152 20914 net.cpp:165] Memory required for data: 36044928
I0702 00:34:49.132750 32261 net.cpp:165] Memory required for data: 44433536
I0702 00:34:49.133158 20914 layer_factory.hpp:77] Creating layer Convolution4
I0702 00:34:49.132757 32261 layer_factory.hpp:77] Creating layer Convolution5
I0702 00:34:49.133185 20914 net.cpp:106] Creating Layer Convolution4
I0702 00:34:49.132774 32261 net.cpp:106] Creating Layer Convolution5
I0702 00:34:49.133519 13010 net.cpp:106] Creating Layer Scale4
I0702 00:34:49.133198 20914 net.cpp:454] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0702 00:34:49.132786 32261 net.cpp:454] Convolution5 <- Convolution4
I0702 00:34:49.133527 13010 net.cpp:454] Scale4 <- Convolution4
I0702 00:34:49.133210 20914 net.cpp:411] Convolution4 -> Convolution4
I0702 00:34:49.132797 32261 net.cpp:411] Convolution5 -> Convolution5
I0702 00:34:49.133536 13010 net.cpp:397] Scale4 -> Convolution4 (in-place)
I0702 00:34:49.133554 13010 layer_factory.hpp:77] Creating layer Scale4
I0702 00:34:49.133589 13010 net.cpp:150] Setting up Scale4
I0702 00:34:49.133599 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.132920 32261 net.cpp:150] Setting up Convolution5
I0702 00:34:49.133608 13010 net.cpp:165] Memory required for data: 42336384
I0702 00:34:49.132939 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.132949 32261 net.cpp:165] Memory required for data: 46530688
I0702 00:34:49.132961 32261 layer_factory.hpp:77] Creating layer BatchNorm5
I0702 00:34:49.132977 32261 net.cpp:106] Creating Layer BatchNorm5
I0702 00:34:49.133620 13010 layer_factory.hpp:77] Creating layer ReLU4
I0702 00:34:49.133358 20914 net.cpp:150] Setting up Convolution4
I0702 00:34:49.133631 13010 net.cpp:106] Creating Layer ReLU4
I0702 00:34:49.133373 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133383 20914 net.cpp:165] Memory required for data: 38142080
I0702 00:34:49.132985 32261 net.cpp:454] BatchNorm5 <- Convolution5
I0702 00:34:49.133638 13010 net.cpp:454] ReLU4 <- Convolution4
I0702 00:34:49.133395 20914 layer_factory.hpp:77] Creating layer BatchNorm4
I0702 00:34:49.132994 32261 net.cpp:397] BatchNorm5 -> Convolution5 (in-place)
I0702 00:34:49.133649 13010 net.cpp:397] ReLU4 -> Convolution4 (in-place)
I0702 00:34:49.133412 20914 net.cpp:106] Creating Layer BatchNorm4
I0702 00:34:49.133024 32261 net.cpp:150] Setting up BatchNorm5
I0702 00:34:49.133661 13010 net.cpp:150] Setting up ReLU4
I0702 00:34:49.133424 20914 net.cpp:454] BatchNorm4 <- Convolution4
I0702 00:34:49.133033 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133668 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133436 20914 net.cpp:397] BatchNorm4 -> Convolution4 (in-place)
I0702 00:34:49.133042 32261 net.cpp:165] Memory required for data: 48627840
I0702 00:34:49.133677 13010 net.cpp:165] Memory required for data: 44433536
I0702 00:34:49.133467 20914 net.cpp:150] Setting up BatchNorm4
I0702 00:34:49.133683 13010 layer_factory.hpp:77] Creating layer Convolution5
I0702 00:34:49.133478 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133700 13010 net.cpp:106] Creating Layer Convolution5
I0702 00:34:49.133486 20914 net.cpp:165] Memory required for data: 40239232
I0702 00:34:49.133062 32261 layer_factory.hpp:77] Creating layer Scale5
I0702 00:34:49.133709 13010 net.cpp:454] Convolution5 <- Convolution4
I0702 00:34:49.133503 20914 layer_factory.hpp:77] Creating layer Scale4
I0702 00:34:49.133075 32261 net.cpp:106] Creating Layer Scale5
I0702 00:34:49.133517 20914 net.cpp:106] Creating Layer Scale4
I0702 00:34:49.133082 32261 net.cpp:454] Scale5 <- Convolution5
I0702 00:34:49.133525 20914 net.cpp:454] Scale4 <- Convolution4
I0702 00:34:49.133093 32261 net.cpp:397] Scale5 -> Convolution5 (in-place)
I0702 00:34:49.133723 13010 net.cpp:411] Convolution5 -> Convolution5
I0702 00:34:49.133534 20914 net.cpp:397] Scale4 -> Convolution4 (in-place)
I0702 00:34:49.133112 32261 layer_factory.hpp:77] Creating layer Scale5
I0702 00:34:49.133848 13010 net.cpp:150] Setting up Convolution5
I0702 00:34:49.133553 20914 layer_factory.hpp:77] Creating layer Scale4
I0702 00:34:49.133147 32261 net.cpp:150] Setting up Scale5
I0702 00:34:49.133869 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133592 20914 net.cpp:150] Setting up Scale4
I0702 00:34:49.133157 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133879 13010 net.cpp:165] Memory required for data: 46530688
I0702 00:34:49.133605 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133169 32261 net.cpp:165] Memory required for data: 50724992
I0702 00:34:49.133890 13010 layer_factory.hpp:77] Creating layer BatchNorm5
I0702 00:34:49.133613 20914 net.cpp:165] Memory required for data: 42336384
I0702 00:34:49.133903 13010 net.cpp:106] Creating Layer BatchNorm5
I0702 00:34:49.133625 20914 layer_factory.hpp:77] Creating layer ReLU4
I0702 00:34:49.133909 13010 net.cpp:454] BatchNorm5 <- Convolution5
I0702 00:34:49.133635 20914 net.cpp:106] Creating Layer ReLU4
I0702 00:34:49.133182 32261 layer_factory.hpp:77] Creating layer Eltwise2
I0702 00:34:49.133641 20914 net.cpp:454] ReLU4 <- Convolution4
I0702 00:34:49.133193 32261 net.cpp:106] Creating Layer Eltwise2
I0702 00:34:49.133200 32261 net.cpp:454] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0702 00:34:49.133656 20914 net.cpp:397] ReLU4 -> Convolution4 (in-place)
I0702 00:34:49.133208 32261 net.cpp:454] Eltwise2 <- Convolution5
I0702 00:34:49.133921 13010 net.cpp:397] BatchNorm5 -> Convolution5 (in-place)
I0702 00:34:49.133669 20914 net.cpp:150] Setting up ReLU4
I0702 00:34:49.133216 32261 net.cpp:411] Eltwise2 -> Eltwise2
I0702 00:34:49.133949 13010 net.cpp:150] Setting up BatchNorm5
I0702 00:34:49.133677 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133229 32261 net.cpp:150] Setting up Eltwise2
I0702 00:34:49.133958 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133685 20914 net.cpp:165] Memory required for data: 44433536
I0702 00:34:49.133237 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133967 13010 net.cpp:165] Memory required for data: 48627840
I0702 00:34:49.133692 20914 layer_factory.hpp:77] Creating layer Convolution5
I0702 00:34:49.133246 32261 net.cpp:165] Memory required for data: 52822144
I0702 00:34:49.133990 13010 layer_factory.hpp:77] Creating layer Scale5
I0702 00:34:49.133713 20914 net.cpp:106] Creating Layer Convolution5
I0702 00:34:49.133253 32261 layer_factory.hpp:77] Creating layer ReLU5
I0702 00:34:49.134002 13010 net.cpp:106] Creating Layer Scale5
I0702 00:34:49.133723 20914 net.cpp:454] Convolution5 <- Convolution4
I0702 00:34:49.133270 32261 net.cpp:106] Creating Layer ReLU5
I0702 00:34:49.134009 13010 net.cpp:454] Scale5 <- Convolution5
I0702 00:34:49.133739 20914 net.cpp:411] Convolution5 -> Convolution5
I0702 00:34:49.133277 32261 net.cpp:454] ReLU5 <- Eltwise2
I0702 00:34:49.134018 13010 net.cpp:397] Scale5 -> Convolution5 (in-place)
I0702 00:34:49.133285 32261 net.cpp:397] ReLU5 -> Eltwise2 (in-place)
I0702 00:34:49.134035 13010 layer_factory.hpp:77] Creating layer Scale5
I0702 00:34:49.133296 32261 net.cpp:150] Setting up ReLU5
I0702 00:34:49.133301 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133311 32261 net.cpp:165] Memory required for data: 54919296
I0702 00:34:49.133316 32261 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0702 00:34:49.133325 32261 net.cpp:106] Creating Layer Eltwise2_ReLU5_0_split
I0702 00:34:49.134069 13010 net.cpp:150] Setting up Scale5
I0702 00:34:49.133332 32261 net.cpp:454] Eltwise2_ReLU5_0_split <- Eltwise2
I0702 00:34:49.134079 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134088 13010 net.cpp:165] Memory required for data: 50724992
I0702 00:34:49.134100 13010 layer_factory.hpp:77] Creating layer Eltwise2
I0702 00:34:49.133343 32261 net.cpp:411] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0702 00:34:49.134110 13010 net.cpp:106] Creating Layer Eltwise2
I0702 00:34:49.133358 32261 net.cpp:411] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0702 00:34:49.134119 13010 net.cpp:454] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0702 00:34:49.133878 20914 net.cpp:150] Setting up Convolution5
I0702 00:34:49.133368 32261 net.cpp:150] Setting up Eltwise2_ReLU5_0_split
I0702 00:34:49.134129 13010 net.cpp:454] Eltwise2 <- Convolution5
I0702 00:34:49.133901 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133911 20914 net.cpp:165] Memory required for data: 46530688
I0702 00:34:49.133376 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134140 13010 net.cpp:411] Eltwise2 -> Eltwise2
I0702 00:34:49.133924 20914 layer_factory.hpp:77] Creating layer BatchNorm5
I0702 00:34:49.133385 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134153 13010 net.cpp:150] Setting up Eltwise2
I0702 00:34:49.133935 20914 net.cpp:106] Creating Layer BatchNorm5
I0702 00:34:49.133942 20914 net.cpp:454] BatchNorm5 <- Convolution5
I0702 00:34:49.133394 32261 net.cpp:165] Memory required for data: 59113600
I0702 00:34:49.134161 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133958 20914 net.cpp:397] BatchNorm5 -> Convolution5 (in-place)
I0702 00:34:49.133400 32261 layer_factory.hpp:77] Creating layer Convolution6
I0702 00:34:49.134171 13010 net.cpp:165] Memory required for data: 52822144
I0702 00:34:49.133991 20914 net.cpp:150] Setting up BatchNorm5
I0702 00:34:49.133417 32261 net.cpp:106] Creating Layer Convolution6
I0702 00:34:49.134177 13010 layer_factory.hpp:77] Creating layer ReLU5
I0702 00:34:49.133427 32261 net.cpp:454] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0702 00:34:49.134186 13010 net.cpp:106] Creating Layer ReLU5
I0702 00:34:49.134001 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133438 32261 net.cpp:411] Convolution6 -> Convolution6
I0702 00:34:49.134192 13010 net.cpp:454] ReLU5 <- Eltwise2
I0702 00:34:49.134019 20914 net.cpp:165] Memory required for data: 48627840
I0702 00:34:49.134042 20914 layer_factory.hpp:77] Creating layer Scale5
I0702 00:34:49.133564 32261 net.cpp:150] Setting up Convolution6
I0702 00:34:49.134202 13010 net.cpp:397] ReLU5 -> Eltwise2 (in-place)
I0702 00:34:49.134212 13010 net.cpp:150] Setting up ReLU5
I0702 00:34:49.134054 20914 net.cpp:106] Creating Layer Scale5
I0702 00:34:49.133577 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134218 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134061 20914 net.cpp:454] Scale5 <- Convolution5
I0702 00:34:49.133586 32261 net.cpp:165] Memory required for data: 61210752
I0702 00:34:49.134227 13010 net.cpp:165] Memory required for data: 54919296
I0702 00:34:49.134070 20914 net.cpp:397] Scale5 -> Convolution5 (in-place)
I0702 00:34:49.133599 32261 layer_factory.hpp:77] Creating layer BatchNorm6
I0702 00:34:49.134232 13010 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0702 00:34:49.134093 20914 layer_factory.hpp:77] Creating layer Scale5
I0702 00:34:49.133616 32261 net.cpp:106] Creating Layer BatchNorm6
I0702 00:34:49.134241 13010 net.cpp:106] Creating Layer Eltwise2_ReLU5_0_split
I0702 00:34:49.134135 20914 net.cpp:150] Setting up Scale5
I0702 00:34:49.133625 32261 net.cpp:454] BatchNorm6 <- Convolution6
I0702 00:34:49.134248 13010 net.cpp:454] Eltwise2_ReLU5_0_split <- Eltwise2
I0702 00:34:49.134147 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134156 20914 net.cpp:165] Memory required for data: 50724992
I0702 00:34:49.133635 32261 net.cpp:397] BatchNorm6 -> Convolution6 (in-place)
I0702 00:34:49.134256 13010 net.cpp:411] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0702 00:34:49.134168 20914 layer_factory.hpp:77] Creating layer Eltwise2
I0702 00:34:49.133662 32261 net.cpp:150] Setting up BatchNorm6
I0702 00:34:49.134268 13010 net.cpp:411] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0702 00:34:49.134184 20914 net.cpp:106] Creating Layer Eltwise2
I0702 00:34:49.133671 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134279 13010 net.cpp:150] Setting up Eltwise2_ReLU5_0_split
I0702 00:34:49.134193 20914 net.cpp:454] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0702 00:34:49.133680 32261 net.cpp:165] Memory required for data: 63307904
I0702 00:34:49.134287 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134202 20914 net.cpp:454] Eltwise2 <- Convolution5
I0702 00:34:49.133693 32261 layer_factory.hpp:77] Creating layer Scale6
I0702 00:34:49.134300 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134212 20914 net.cpp:411] Eltwise2 -> Eltwise2
I0702 00:34:49.133708 32261 net.cpp:106] Creating Layer Scale6
I0702 00:34:49.134308 13010 net.cpp:165] Memory required for data: 59113600
I0702 00:34:49.134232 20914 net.cpp:150] Setting up Eltwise2
I0702 00:34:49.133723 32261 net.cpp:454] Scale6 <- Convolution6
I0702 00:34:49.134315 13010 layer_factory.hpp:77] Creating layer Convolution6
I0702 00:34:49.134240 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134335 13010 net.cpp:106] Creating Layer Convolution6
I0702 00:34:49.134249 20914 net.cpp:165] Memory required for data: 52822144
I0702 00:34:49.134346 13010 net.cpp:454] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0702 00:34:49.134256 20914 layer_factory.hpp:77] Creating layer ReLU5
I0702 00:34:49.133733 32261 net.cpp:397] Scale6 -> Convolution6 (in-place)
I0702 00:34:49.134356 13010 net.cpp:411] Convolution6 -> Convolution6
I0702 00:34:49.134265 20914 net.cpp:106] Creating Layer ReLU5
I0702 00:34:49.133750 32261 layer_factory.hpp:77] Creating layer Scale6
I0702 00:34:49.134272 20914 net.cpp:454] ReLU5 <- Eltwise2
I0702 00:34:49.133783 32261 net.cpp:150] Setting up Scale6
I0702 00:34:49.134280 20914 net.cpp:397] ReLU5 -> Eltwise2 (in-place)
I0702 00:34:49.133795 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134498 13010 net.cpp:150] Setting up Convolution6
I0702 00:34:49.134291 20914 net.cpp:150] Setting up ReLU5
I0702 00:34:49.133803 32261 net.cpp:165] Memory required for data: 65405056
I0702 00:34:49.134512 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134297 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133814 32261 layer_factory.hpp:77] Creating layer ReLU6
I0702 00:34:49.134521 13010 net.cpp:165] Memory required for data: 61210752
I0702 00:34:49.134305 20914 net.cpp:165] Memory required for data: 54919296
I0702 00:34:49.133826 32261 net.cpp:106] Creating Layer ReLU6
I0702 00:34:49.134533 13010 layer_factory.hpp:77] Creating layer BatchNorm6
I0702 00:34:49.134312 20914 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0702 00:34:49.133831 32261 net.cpp:454] ReLU6 <- Convolution6
I0702 00:34:49.134544 13010 net.cpp:106] Creating Layer BatchNorm6
I0702 00:34:49.134321 20914 net.cpp:106] Creating Layer Eltwise2_ReLU5_0_split
I0702 00:34:49.133841 32261 net.cpp:397] ReLU6 -> Convolution6 (in-place)
I0702 00:34:49.134553 13010 net.cpp:454] BatchNorm6 <- Convolution6
I0702 00:34:49.134327 20914 net.cpp:454] Eltwise2_ReLU5_0_split <- Eltwise2
I0702 00:34:49.133850 32261 net.cpp:150] Setting up ReLU6
I0702 00:34:49.134565 13010 net.cpp:397] BatchNorm6 -> Convolution6 (in-place)
I0702 00:34:49.134341 20914 net.cpp:411] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0702 00:34:49.133857 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134594 13010 net.cpp:150] Setting up BatchNorm6
I0702 00:34:49.134357 20914 net.cpp:411] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0702 00:34:49.133869 32261 net.cpp:165] Memory required for data: 67502208
I0702 00:34:49.134603 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134371 20914 net.cpp:150] Setting up Eltwise2_ReLU5_0_split
I0702 00:34:49.133877 32261 layer_factory.hpp:77] Creating layer Convolution7
I0702 00:34:49.134616 13010 net.cpp:165] Memory required for data: 63307904
I0702 00:34:49.134379 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133895 32261 net.cpp:106] Creating Layer Convolution7
I0702 00:34:49.134630 13010 layer_factory.hpp:77] Creating layer Scale6
I0702 00:34:49.134388 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.133904 32261 net.cpp:454] Convolution7 <- Convolution6
I0702 00:34:49.134642 13010 net.cpp:106] Creating Layer Scale6
I0702 00:34:49.134397 20914 net.cpp:165] Memory required for data: 59113600
I0702 00:34:49.133919 32261 net.cpp:411] Convolution7 -> Convolution7
I0702 00:34:49.134658 13010 net.cpp:454] Scale6 <- Convolution6
I0702 00:34:49.134403 20914 layer_factory.hpp:77] Creating layer Convolution6
I0702 00:34:49.134671 13010 net.cpp:397] Scale6 -> Convolution6 (in-place)
I0702 00:34:49.134423 20914 net.cpp:106] Creating Layer Convolution6
I0702 00:34:49.134690 13010 layer_factory.hpp:77] Creating layer Scale6
I0702 00:34:49.134435 20914 net.cpp:454] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0702 00:34:49.134045 32261 net.cpp:150] Setting up Convolution7
I0702 00:34:49.134446 20914 net.cpp:411] Convolution6 -> Convolution6
I0702 00:34:49.134057 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134066 32261 net.cpp:165] Memory required for data: 69599360
I0702 00:34:49.134721 13010 net.cpp:150] Setting up Scale6
I0702 00:34:49.134078 32261 layer_factory.hpp:77] Creating layer BatchNorm7
I0702 00:34:49.134732 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134088 32261 net.cpp:106] Creating Layer BatchNorm7
I0702 00:34:49.134739 13010 net.cpp:165] Memory required for data: 65405056
I0702 00:34:49.134096 32261 net.cpp:454] BatchNorm7 <- Convolution7
I0702 00:34:49.134754 13010 layer_factory.hpp:77] Creating layer ReLU6
I0702 00:34:49.134109 32261 net.cpp:397] BatchNorm7 -> Convolution7 (in-place)
I0702 00:34:49.134765 13010 net.cpp:106] Creating Layer ReLU6
I0702 00:34:49.134136 32261 net.cpp:150] Setting up BatchNorm7
I0702 00:34:49.134773 13010 net.cpp:454] ReLU6 <- Convolution6
I0702 00:34:49.134579 20914 net.cpp:150] Setting up Convolution6
I0702 00:34:49.134145 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134780 13010 net.cpp:397] ReLU6 -> Convolution6 (in-place)
I0702 00:34:49.134593 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134603 20914 net.cpp:165] Memory required for data: 61210752
I0702 00:34:49.134157 32261 net.cpp:165] Memory required for data: 71696512
I0702 00:34:49.134790 13010 net.cpp:150] Setting up ReLU6
I0702 00:34:49.134614 20914 layer_factory.hpp:77] Creating layer BatchNorm6
I0702 00:34:49.134171 32261 layer_factory.hpp:77] Creating layer Scale7
I0702 00:34:49.134798 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134630 20914 net.cpp:106] Creating Layer BatchNorm6
I0702 00:34:49.134639 20914 net.cpp:454] BatchNorm6 <- Convolution6
I0702 00:34:49.134805 13010 net.cpp:165] Memory required for data: 67502208
I0702 00:34:49.134649 20914 net.cpp:397] BatchNorm6 -> Convolution6 (in-place)
I0702 00:34:49.134187 32261 net.cpp:106] Creating Layer Scale7
I0702 00:34:49.134811 13010 layer_factory.hpp:77] Creating layer Convolution7
I0702 00:34:49.134677 20914 net.cpp:150] Setting up BatchNorm6
I0702 00:34:49.134196 32261 net.cpp:454] Scale7 <- Convolution7
I0702 00:34:49.134829 13010 net.cpp:106] Creating Layer Convolution7
I0702 00:34:49.134687 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134205 32261 net.cpp:397] Scale7 -> Convolution7 (in-place)
I0702 00:34:49.134837 13010 net.cpp:454] Convolution7 <- Convolution6
I0702 00:34:49.134697 20914 net.cpp:165] Memory required for data: 63307904
I0702 00:34:49.134222 32261 layer_factory.hpp:77] Creating layer Scale7
I0702 00:34:49.134848 13010 net.cpp:411] Convolution7 -> Convolution7
I0702 00:34:49.134711 20914 layer_factory.hpp:77] Creating layer Scale6
I0702 00:34:49.134261 32261 net.cpp:150] Setting up Scale7
I0702 00:34:49.134726 20914 net.cpp:106] Creating Layer Scale6
I0702 00:34:49.134272 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134973 13010 net.cpp:150] Setting up Convolution7
I0702 00:34:49.134742 20914 net.cpp:454] Scale6 <- Convolution6
I0702 00:34:49.134281 32261 net.cpp:165] Memory required for data: 73793664
I0702 00:34:49.134984 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134752 20914 net.cpp:397] Scale6 -> Convolution6 (in-place)
I0702 00:34:49.134294 32261 layer_factory.hpp:77] Creating layer Eltwise3
I0702 00:34:49.134994 13010 net.cpp:165] Memory required for data: 69599360
I0702 00:34:49.134769 20914 layer_factory.hpp:77] Creating layer Scale6
I0702 00:34:49.134304 32261 net.cpp:106] Creating Layer Eltwise3
I0702 00:34:49.135007 13010 layer_factory.hpp:77] Creating layer BatchNorm7
I0702 00:34:49.134807 20914 net.cpp:150] Setting up Scale6
I0702 00:34:49.134312 32261 net.cpp:454] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0702 00:34:49.135020 13010 net.cpp:106] Creating Layer BatchNorm7
I0702 00:34:49.134819 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134320 32261 net.cpp:454] Eltwise3 <- Convolution7
I0702 00:34:49.135026 13010 net.cpp:454] BatchNorm7 <- Convolution7
I0702 00:34:49.134829 20914 net.cpp:165] Memory required for data: 65405056
I0702 00:34:49.135036 13010 net.cpp:397] BatchNorm7 -> Convolution7 (in-place)
I0702 00:34:49.134840 20914 layer_factory.hpp:77] Creating layer ReLU6
I0702 00:34:49.135063 13010 net.cpp:150] Setting up BatchNorm7
I0702 00:34:49.134331 32261 net.cpp:411] Eltwise3 -> Eltwise3
I0702 00:34:49.135071 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134850 20914 net.cpp:106] Creating Layer ReLU6
I0702 00:34:49.134346 32261 net.cpp:150] Setting up Eltwise3
I0702 00:34:49.135080 13010 net.cpp:165] Memory required for data: 71696512
I0702 00:34:49.134855 20914 net.cpp:454] ReLU6 <- Convolution6
I0702 00:34:49.134353 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.135093 13010 layer_factory.hpp:77] Creating layer Scale7
I0702 00:34:49.134865 20914 net.cpp:397] ReLU6 -> Convolution6 (in-place)
I0702 00:34:49.134361 32261 net.cpp:165] Memory required for data: 75890816
I0702 00:34:49.135109 13010 net.cpp:106] Creating Layer Scale7
I0702 00:34:49.134874 20914 net.cpp:150] Setting up ReLU6
I0702 00:34:49.134368 32261 layer_factory.hpp:77] Creating layer ReLU7
I0702 00:34:49.135119 13010 net.cpp:454] Scale7 <- Convolution7
I0702 00:34:49.134881 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134377 32261 net.cpp:106] Creating Layer ReLU7
I0702 00:34:49.134889 20914 net.cpp:165] Memory required for data: 67502208
I0702 00:34:49.134383 32261 net.cpp:454] ReLU7 <- Eltwise3
I0702 00:34:49.134896 20914 layer_factory.hpp:77] Creating layer Convolution7
I0702 00:34:49.134392 32261 net.cpp:397] ReLU7 -> Eltwise3 (in-place)
I0702 00:34:49.135130 13010 net.cpp:397] Scale7 -> Convolution7 (in-place)
I0702 00:34:49.134917 20914 net.cpp:106] Creating Layer Convolution7
I0702 00:34:49.134400 32261 net.cpp:150] Setting up ReLU7
I0702 00:34:49.135149 13010 layer_factory.hpp:77] Creating layer Scale7
I0702 00:34:49.134927 20914 net.cpp:454] Convolution7 <- Convolution6
I0702 00:34:49.134407 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.135181 13010 net.cpp:150] Setting up Scale7
I0702 00:34:49.134941 20914 net.cpp:411] Convolution7 -> Convolution7
I0702 00:34:49.134415 32261 net.cpp:165] Memory required for data: 77987968
I0702 00:34:49.135190 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134421 32261 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0702 00:34:49.135200 13010 net.cpp:165] Memory required for data: 73793664
I0702 00:34:49.134430 32261 net.cpp:106] Creating Layer Eltwise3_ReLU7_0_split
I0702 00:34:49.135210 13010 layer_factory.hpp:77] Creating layer Eltwise3
I0702 00:34:49.134438 32261 net.cpp:454] Eltwise3_ReLU7_0_split <- Eltwise3
I0702 00:34:49.135223 13010 net.cpp:106] Creating Layer Eltwise3
I0702 00:34:49.134445 32261 net.cpp:411] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0702 00:34:49.135231 13010 net.cpp:454] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0702 00:34:49.134455 32261 net.cpp:411] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0702 00:34:49.135239 13010 net.cpp:454] Eltwise3 <- Convolution7
I0702 00:34:49.134467 32261 net.cpp:150] Setting up Eltwise3_ReLU7_0_split
I0702 00:34:49.135248 13010 net.cpp:411] Eltwise3 -> Eltwise3
I0702 00:34:49.134475 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.135262 13010 net.cpp:150] Setting up Eltwise3
I0702 00:34:49.134483 32261 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.135269 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134500 32261 net.cpp:165] Memory required for data: 82182272
I0702 00:34:49.135277 13010 net.cpp:165] Memory required for data: 75890816
I0702 00:34:49.134507 32261 layer_factory.hpp:77] Creating layer Convolution8
I0702 00:34:49.135284 13010 layer_factory.hpp:77] Creating layer ReLU7
I0702 00:34:49.135082 20914 net.cpp:150] Setting up Convolution7
I0702 00:34:49.134527 32261 net.cpp:106] Creating Layer Convolution8
I0702 00:34:49.135295 13010 net.cpp:106] Creating Layer ReLU7
I0702 00:34:49.135097 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.135107 20914 net.cpp:165] Memory required for data: 69599360
I0702 00:34:49.134537 32261 net.cpp:454] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0702 00:34:49.135303 13010 net.cpp:454] ReLU7 <- Eltwise3
I0702 00:34:49.135118 20914 layer_factory.hpp:77] Creating layer BatchNorm7
I0702 00:34:49.135311 13010 net.cpp:397] ReLU7 -> Eltwise3 (in-place)
I0702 00:34:49.135128 20914 net.cpp:106] Creating Layer BatchNorm7
I0702 00:34:49.135135 20914 net.cpp:454] BatchNorm7 <- Convolution7
I0702 00:34:49.135150 20914 net.cpp:397] BatchNorm7 -> Convolution7 (in-place)
I0702 00:34:49.135321 13010 net.cpp:150] Setting up ReLU7
I0702 00:34:49.135184 20914 net.cpp:150] Setting up BatchNorm7
I0702 00:34:49.134551 32261 net.cpp:411] Convolution8 -> Convolution8
I0702 00:34:49.135327 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.135335 13010 net.cpp:165] Memory required for data: 77987968
I0702 00:34:49.135195 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134640 32261 net.cpp:150] Setting up Convolution8
I0702 00:34:49.135342 13010 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0702 00:34:49.135210 20914 net.cpp:165] Memory required for data: 71696512
I0702 00:34:49.134652 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.135350 13010 net.cpp:106] Creating Layer Eltwise3_ReLU7_0_split
I0702 00:34:49.135229 20914 layer_factory.hpp:77] Creating layer Scale7
I0702 00:34:49.134665 32261 net.cpp:165] Memory required for data: 83230848
I0702 00:34:49.135357 13010 net.cpp:454] Eltwise3_ReLU7_0_split <- Eltwise3
I0702 00:34:49.135248 20914 net.cpp:106] Creating Layer Scale7
I0702 00:34:49.134677 32261 layer_factory.hpp:77] Creating layer BatchNorm8
I0702 00:34:49.135365 13010 net.cpp:411] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0702 00:34:49.135257 20914 net.cpp:454] Scale7 <- Convolution7
I0702 00:34:49.134690 32261 net.cpp:106] Creating Layer BatchNorm8
I0702 00:34:49.135376 13010 net.cpp:411] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0702 00:34:49.135267 20914 net.cpp:397] Scale7 -> Convolution7 (in-place)
I0702 00:34:49.134697 32261 net.cpp:454] BatchNorm8 <- Convolution8
I0702 00:34:49.135387 13010 net.cpp:150] Setting up Eltwise3_ReLU7_0_split
I0702 00:34:49.135284 20914 layer_factory.hpp:77] Creating layer Scale7
I0702 00:34:49.134706 32261 net.cpp:397] BatchNorm8 -> Convolution8 (in-place)
I0702 00:34:49.135396 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.135320 20914 net.cpp:150] Setting up Scale7
I0702 00:34:49.134730 32261 net.cpp:150] Setting up BatchNorm8
I0702 00:34:49.135413 13010 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.135332 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134739 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.135428 13010 net.cpp:165] Memory required for data: 82182272
I0702 00:34:49.135341 20914 net.cpp:165] Memory required for data: 73793664
I0702 00:34:49.134747 32261 net.cpp:165] Memory required for data: 84279424
I0702 00:34:49.135437 13010 layer_factory.hpp:77] Creating layer Convolution8
I0702 00:34:49.135352 20914 layer_factory.hpp:77] Creating layer Eltwise3
I0702 00:34:49.134762 32261 layer_factory.hpp:77] Creating layer Scale8
I0702 00:34:49.135455 13010 net.cpp:106] Creating Layer Convolution8
I0702 00:34:49.135363 20914 net.cpp:106] Creating Layer Eltwise3
I0702 00:34:49.134773 32261 net.cpp:106] Creating Layer Scale8
I0702 00:34:49.135464 13010 net.cpp:454] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0702 00:34:49.135370 20914 net.cpp:454] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0702 00:34:49.134779 32261 net.cpp:454] Scale8 <- Convolution8
I0702 00:34:49.135475 13010 net.cpp:411] Convolution8 -> Convolution8
I0702 00:34:49.135378 20914 net.cpp:454] Eltwise3 <- Convolution7
I0702 00:34:49.134790 32261 net.cpp:397] Scale8 -> Convolution8 (in-place)
I0702 00:34:49.135392 20914 net.cpp:411] Eltwise3 -> Eltwise3
I0702 00:34:49.134809 32261 layer_factory.hpp:77] Creating layer Scale8
I0702 00:34:49.135411 20914 net.cpp:150] Setting up Eltwise3
I0702 00:34:49.134840 32261 net.cpp:150] Setting up Scale8
I0702 00:34:49.135566 13010 net.cpp:150] Setting up Convolution8
I0702 00:34:49.135419 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.135578 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.135427 20914 net.cpp:165] Memory required for data: 75890816
I0702 00:34:49.135587 13010 net.cpp:165] Memory required for data: 83230848
I0702 00:34:49.135434 20914 layer_factory.hpp:77] Creating layer ReLU7
I0702 00:34:49.134850 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.135599 13010 layer_factory.hpp:77] Creating layer BatchNorm8
I0702 00:34:49.135443 20914 net.cpp:106] Creating Layer ReLU7
I0702 00:34:49.134860 32261 net.cpp:165] Memory required for data: 85328000
I0702 00:34:49.135612 13010 net.cpp:106] Creating Layer BatchNorm8
I0702 00:34:49.135450 20914 net.cpp:454] ReLU7 <- Eltwise3
I0702 00:34:49.134871 32261 layer_factory.hpp:77] Creating layer Convolution9
I0702 00:34:49.135622 13010 net.cpp:454] BatchNorm8 <- Convolution8
I0702 00:34:49.135458 20914 net.cpp:397] ReLU7 -> Eltwise3 (in-place)
I0702 00:34:49.134892 32261 net.cpp:106] Creating Layer Convolution9
I0702 00:34:49.135630 13010 net.cpp:397] BatchNorm8 -> Convolution8 (in-place)
I0702 00:34:49.135468 20914 net.cpp:150] Setting up ReLU7
I0702 00:34:49.134902 32261 net.cpp:454] Convolution9 <- Eltwise3_ReLU7_0_split_1
I0702 00:34:49.135654 13010 net.cpp:150] Setting up BatchNorm8
I0702 00:34:49.135474 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.134912 32261 net.cpp:411] Convolution9 -> Convolution9
I0702 00:34:49.135663 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.135483 20914 net.cpp:165] Memory required for data: 77987968
I0702 00:34:49.135077 32261 net.cpp:150] Setting up Convolution9
I0702 00:34:49.135671 13010 net.cpp:165] Memory required for data: 84279424
I0702 00:34:49.135489 20914 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0702 00:34:49.135089 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.135687 13010 layer_factory.hpp:77] Creating layer Scale8
I0702 00:34:49.135499 20914 net.cpp:106] Creating Layer Eltwise3_ReLU7_0_split
I0702 00:34:49.135098 32261 net.cpp:165] Memory required for data: 86376576
I0702 00:34:49.135699 13010 net.cpp:106] Creating Layer Scale8
I0702 00:34:49.135504 20914 net.cpp:454] Eltwise3_ReLU7_0_split <- Eltwise3
I0702 00:34:49.135110 32261 layer_factory.hpp:77] Creating layer BatchNorm9
I0702 00:34:49.135706 13010 net.cpp:454] Scale8 <- Convolution8
I0702 00:34:49.135514 20914 net.cpp:411] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0702 00:34:49.135121 32261 net.cpp:106] Creating Layer BatchNorm9
I0702 00:34:49.135715 13010 net.cpp:397] Scale8 -> Convolution8 (in-place)
I0702 00:34:49.135524 20914 net.cpp:411] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0702 00:34:49.135129 32261 net.cpp:454] BatchNorm9 <- Convolution9
I0702 00:34:49.135735 13010 layer_factory.hpp:77] Creating layer Scale8
I0702 00:34:49.135535 20914 net.cpp:150] Setting up Eltwise3_ReLU7_0_split
I0702 00:34:49.135140 32261 net.cpp:397] BatchNorm9 -> Convolution9 (in-place)
I0702 00:34:49.135762 13010 net.cpp:150] Setting up Scale8
I0702 00:34:49.135542 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.135772 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.135550 20914 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.135781 13010 net.cpp:165] Memory required for data: 85328000
I0702 00:34:49.135567 20914 net.cpp:165] Memory required for data: 82182272
I0702 00:34:49.135792 13010 layer_factory.hpp:77] Creating layer Convolution9
I0702 00:34:49.135576 20914 layer_factory.hpp:77] Creating layer Convolution8
I0702 00:34:49.135166 32261 net.cpp:150] Setting up BatchNorm9
I0702 00:34:49.135596 20914 net.cpp:106] Creating Layer Convolution8
I0702 00:34:49.135175 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.135607 20914 net.cpp:454] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0702 00:34:49.135185 32261 net.cpp:165] Memory required for data: 87425152
I0702 00:34:49.135812 13010 net.cpp:106] Creating Layer Convolution9
I0702 00:34:49.135623 20914 net.cpp:411] Convolution8 -> Convolution8
I0702 00:34:49.135200 32261 layer_factory.hpp:77] Creating layer Scale9
I0702 00:34:49.135821 13010 net.cpp:454] Convolution9 <- Eltwise3_ReLU7_0_split_1
I0702 00:34:49.135720 20914 net.cpp:150] Setting up Convolution8
I0702 00:34:49.135212 32261 net.cpp:106] Creating Layer Scale9
I0702 00:34:49.135834 13010 net.cpp:411] Convolution9 -> Convolution9
I0702 00:34:49.135219 32261 net.cpp:454] Scale9 <- Convolution9
I0702 00:34:49.135998 13010 net.cpp:150] Setting up Convolution9
I0702 00:34:49.135733 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.135227 32261 net.cpp:397] Scale9 -> Convolution9 (in-place)
I0702 00:34:49.136009 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.135749 20914 net.cpp:165] Memory required for data: 83230848
I0702 00:34:49.135243 32261 layer_factory.hpp:77] Creating layer Scale9
I0702 00:34:49.136018 13010 net.cpp:165] Memory required for data: 86376576
I0702 00:34:49.135761 20914 layer_factory.hpp:77] Creating layer BatchNorm8
I0702 00:34:49.135277 32261 net.cpp:150] Setting up Scale9
I0702 00:34:49.136032 13010 layer_factory.hpp:77] Creating layer BatchNorm9
I0702 00:34:49.135772 20914 net.cpp:106] Creating Layer BatchNorm8
I0702 00:34:49.135779 20914 net.cpp:454] BatchNorm8 <- Convolution8
I0702 00:34:49.135288 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.136044 13010 net.cpp:106] Creating Layer BatchNorm9
I0702 00:34:49.135788 20914 net.cpp:397] BatchNorm8 -> Convolution8 (in-place)
I0702 00:34:49.135298 32261 net.cpp:165] Memory required for data: 88473728
I0702 00:34:49.136051 13010 net.cpp:454] BatchNorm9 <- Convolution9
I0702 00:34:49.135815 20914 net.cpp:150] Setting up BatchNorm8
I0702 00:34:49.135308 32261 layer_factory.hpp:77] Creating layer ReLU8
I0702 00:34:49.135825 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.135323 32261 net.cpp:106] Creating Layer ReLU8
I0702 00:34:49.136063 13010 net.cpp:397] BatchNorm9 -> Convolution9 (in-place)
I0702 00:34:49.135835 20914 net.cpp:165] Memory required for data: 84279424
I0702 00:34:49.136090 13010 net.cpp:150] Setting up BatchNorm9
I0702 00:34:49.135848 20914 layer_factory.hpp:77] Creating layer Scale8
I0702 00:34:49.136097 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.135864 20914 net.cpp:106] Creating Layer Scale8
I0702 00:34:49.135330 32261 net.cpp:454] ReLU8 <- Convolution9
I0702 00:34:49.136106 13010 net.cpp:165] Memory required for data: 87425152
I0702 00:34:49.135874 20914 net.cpp:454] Scale8 <- Convolution8
I0702 00:34:49.135339 32261 net.cpp:397] ReLU8 -> Convolution9 (in-place)
I0702 00:34:49.135349 32261 net.cpp:150] Setting up ReLU8
I0702 00:34:49.136119 13010 layer_factory.hpp:77] Creating layer Scale9
I0702 00:34:49.135885 20914 net.cpp:397] Scale8 -> Convolution8 (in-place)
I0702 00:34:49.135355 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.136135 13010 net.cpp:106] Creating Layer Scale9
I0702 00:34:49.135901 20914 layer_factory.hpp:77] Creating layer Scale8
I0702 00:34:49.135363 32261 net.cpp:165] Memory required for data: 89522304
I0702 00:34:49.136144 13010 net.cpp:454] Scale9 <- Convolution9
I0702 00:34:49.135934 20914 net.cpp:150] Setting up Scale8
I0702 00:34:49.135370 32261 layer_factory.hpp:77] Creating layer Convolution10
I0702 00:34:49.136153 13010 net.cpp:397] Scale9 -> Convolution9 (in-place)
I0702 00:34:49.135946 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.135393 32261 net.cpp:106] Creating Layer Convolution10
I0702 00:34:49.136170 13010 layer_factory.hpp:77] Creating layer Scale9
I0702 00:34:49.135956 20914 net.cpp:165] Memory required for data: 85328000
I0702 00:34:49.135402 32261 net.cpp:454] Convolution10 <- Convolution9
I0702 00:34:49.136198 13010 net.cpp:150] Setting up Scale9
I0702 00:34:49.135967 20914 layer_factory.hpp:77] Creating layer Convolution9
I0702 00:34:49.135413 32261 net.cpp:411] Convolution10 -> Convolution10
I0702 00:34:49.135991 20914 net.cpp:106] Creating Layer Convolution9
I0702 00:34:49.136206 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.136003 20914 net.cpp:454] Convolution9 <- Eltwise3_ReLU7_0_split_1
I0702 00:34:49.136219 13010 net.cpp:165] Memory required for data: 88473728
I0702 00:34:49.136014 20914 net.cpp:411] Convolution9 -> Convolution9
I0702 00:34:49.135675 32261 net.cpp:150] Setting up Convolution10
I0702 00:34:49.136230 13010 layer_factory.hpp:77] Creating layer ReLU8
I0702 00:34:49.135689 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.136240 13010 net.cpp:106] Creating Layer ReLU8
I0702 00:34:49.135705 32261 net.cpp:165] Memory required for data: 90570880
I0702 00:34:49.136247 13010 net.cpp:454] ReLU8 <- Convolution9
I0702 00:34:49.136257 13010 net.cpp:397] ReLU8 -> Convolution9 (in-place)
I0702 00:34:49.136268 13010 net.cpp:150] Setting up ReLU8
I0702 00:34:49.135730 32261 layer_factory.hpp:77] Creating layer BatchNorm10
I0702 00:34:49.136276 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.135747 32261 net.cpp:106] Creating Layer BatchNorm10
I0702 00:34:49.136286 13010 net.cpp:165] Memory required for data: 89522304
I0702 00:34:49.135756 32261 net.cpp:454] BatchNorm10 <- Convolution10
I0702 00:34:49.136291 13010 layer_factory.hpp:77] Creating layer Convolution10
I0702 00:34:49.135766 32261 net.cpp:397] BatchNorm10 -> Convolution10 (in-place)
I0702 00:34:49.136310 13010 net.cpp:106] Creating Layer Convolution10
I0702 00:34:49.136319 13010 net.cpp:454] Convolution10 <- Convolution9
I0702 00:34:49.136332 13010 net.cpp:411] Convolution10 -> Convolution10
I0702 00:34:49.135792 32261 net.cpp:150] Setting up BatchNorm10
I0702 00:34:49.135802 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.135810 32261 net.cpp:165] Memory required for data: 91619456
I0702 00:34:49.135823 32261 layer_factory.hpp:77] Creating layer Scale10
I0702 00:34:49.136194 20914 net.cpp:150] Setting up Convolution9
I0702 00:34:49.135838 32261 net.cpp:106] Creating Layer Scale10
I0702 00:34:49.136209 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.135846 32261 net.cpp:454] Scale10 <- Convolution10
I0702 00:34:49.136219 20914 net.cpp:165] Memory required for data: 86376576
I0702 00:34:49.135855 32261 net.cpp:397] Scale10 -> Convolution10 (in-place)
I0702 00:34:49.136235 20914 layer_factory.hpp:77] Creating layer BatchNorm9
I0702 00:34:49.136597 13010 net.cpp:150] Setting up Convolution10
I0702 00:34:49.136252 20914 net.cpp:106] Creating Layer BatchNorm9
I0702 00:34:49.135872 32261 layer_factory.hpp:77] Creating layer Scale10
I0702 00:34:49.136261 20914 net.cpp:454] BatchNorm9 <- Convolution9
I0702 00:34:49.135903 32261 net.cpp:150] Setting up Scale10
I0702 00:34:49.136272 20914 net.cpp:397] BatchNorm9 -> Convolution9 (in-place)
I0702 00:34:49.135913 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.136611 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.136299 20914 net.cpp:150] Setting up BatchNorm9
I0702 00:34:49.135922 32261 net.cpp:165] Memory required for data: 92668032
I0702 00:34:49.136631 13010 net.cpp:165] Memory required for data: 90570880
I0702 00:34:49.136309 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.135933 32261 layer_factory.hpp:77] Creating layer Eltwise4
I0702 00:34:49.136652 13010 layer_factory.hpp:77] Creating layer BatchNorm10
I0702 00:34:49.136318 20914 net.cpp:165] Memory required for data: 87425152
I0702 00:34:49.135944 32261 net.cpp:106] Creating Layer Eltwise4
I0702 00:34:49.136334 20914 layer_factory.hpp:77] Creating layer Scale9
I0702 00:34:49.136669 13010 net.cpp:106] Creating Layer BatchNorm10
I0702 00:34:49.136346 20914 net.cpp:106] Creating Layer Scale9
I0702 00:34:49.136679 13010 net.cpp:454] BatchNorm10 <- Convolution10
I0702 00:34:49.136354 20914 net.cpp:454] Scale9 <- Convolution9
I0702 00:34:49.135951 32261 net.cpp:454] Eltwise4 <- Convolution8
I0702 00:34:49.136692 13010 net.cpp:397] BatchNorm10 -> Convolution10 (in-place)
I0702 00:34:49.136363 20914 net.cpp:397] Scale9 -> Convolution9 (in-place)
I0702 00:34:49.135960 32261 net.cpp:454] Eltwise4 <- Convolution10
I0702 00:34:49.136714 13010 net.cpp:150] Setting up BatchNorm10
I0702 00:34:49.136384 20914 layer_factory.hpp:77] Creating layer Scale9
I0702 00:34:49.135972 32261 net.cpp:411] Eltwise4 -> Eltwise4
I0702 00:34:49.136723 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.136418 20914 net.cpp:150] Setting up Scale9
I0702 00:34:49.135984 32261 net.cpp:150] Setting up Eltwise4
I0702 00:34:49.136732 13010 net.cpp:165] Memory required for data: 91619456
I0702 00:34:49.136430 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.135993 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.136438 20914 net.cpp:165] Memory required for data: 88473728
I0702 00:34:49.136001 32261 net.cpp:165] Memory required for data: 93716608
I0702 00:34:49.136449 20914 layer_factory.hpp:77] Creating layer ReLU8
I0702 00:34:49.136008 32261 layer_factory.hpp:77] Creating layer ReLU9
I0702 00:34:49.136749 13010 layer_factory.hpp:77] Creating layer Scale10
I0702 00:34:49.136461 20914 net.cpp:106] Creating Layer ReLU8
I0702 00:34:49.136016 32261 net.cpp:106] Creating Layer ReLU9
I0702 00:34:49.136760 13010 net.cpp:106] Creating Layer Scale10
I0702 00:34:49.136471 20914 net.cpp:454] ReLU8 <- Convolution9
I0702 00:34:49.136023 32261 net.cpp:454] ReLU9 <- Eltwise4
I0702 00:34:49.136767 13010 net.cpp:454] Scale10 <- Convolution10
I0702 00:34:49.136479 20914 net.cpp:397] ReLU8 -> Convolution9 (in-place)
I0702 00:34:49.136034 32261 net.cpp:397] ReLU9 -> Eltwise4 (in-place)
I0702 00:34:49.136778 13010 net.cpp:397] Scale10 -> Convolution10 (in-place)
I0702 00:34:49.136489 20914 net.cpp:150] Setting up ReLU8
I0702 00:34:49.136045 32261 net.cpp:150] Setting up ReLU9
I0702 00:34:49.136796 13010 layer_factory.hpp:77] Creating layer Scale10
I0702 00:34:49.136497 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.136052 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.136824 13010 net.cpp:150] Setting up Scale10
I0702 00:34:49.136504 20914 net.cpp:165] Memory required for data: 89522304
I0702 00:34:49.136060 32261 net.cpp:165] Memory required for data: 94765184
I0702 00:34:49.136833 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.136512 20914 layer_factory.hpp:77] Creating layer Convolution10
I0702 00:34:49.136066 32261 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0702 00:34:49.136842 13010 net.cpp:165] Memory required for data: 92668032
I0702 00:34:49.136535 20914 net.cpp:106] Creating Layer Convolution10
I0702 00:34:49.136548 20914 net.cpp:454] Convolution10 <- Convolution9
I0702 00:34:49.136559 20914 net.cpp:411] Convolution10 -> Convolution10
I0702 00:34:49.136075 32261 net.cpp:106] Creating Layer Eltwise4_ReLU9_0_split
I0702 00:34:49.136857 13010 layer_factory.hpp:77] Creating layer Eltwise4
I0702 00:34:49.136081 32261 net.cpp:454] Eltwise4_ReLU9_0_split <- Eltwise4
I0702 00:34:49.136868 13010 net.cpp:106] Creating Layer Eltwise4
I0702 00:34:49.136090 32261 net.cpp:411] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0702 00:34:49.136874 13010 net.cpp:454] Eltwise4 <- Convolution8
I0702 00:34:49.136101 32261 net.cpp:411] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0702 00:34:49.136883 13010 net.cpp:454] Eltwise4 <- Convolution10
I0702 00:34:49.136112 32261 net.cpp:150] Setting up Eltwise4_ReLU9_0_split
I0702 00:34:49.136891 13010 net.cpp:411] Eltwise4 -> Eltwise4
I0702 00:34:49.136118 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.136904 13010 net.cpp:150] Setting up Eltwise4
I0702 00:34:49.136132 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.136912 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.136139 32261 net.cpp:165] Memory required for data: 96862336
I0702 00:34:49.136925 13010 net.cpp:165] Memory required for data: 93716608
I0702 00:34:49.136147 32261 layer_factory.hpp:77] Creating layer Convolution11
I0702 00:34:49.136932 13010 layer_factory.hpp:77] Creating layer ReLU9
I0702 00:34:49.136162 32261 net.cpp:106] Creating Layer Convolution11
I0702 00:34:49.136941 13010 net.cpp:106] Creating Layer ReLU9
I0702 00:34:49.136171 32261 net.cpp:454] Convolution11 <- Eltwise4_ReLU9_0_split_0
I0702 00:34:49.136948 13010 net.cpp:454] ReLU9 <- Eltwise4
I0702 00:34:49.136185 32261 net.cpp:411] Convolution11 -> Convolution11
I0702 00:34:49.136956 13010 net.cpp:397] ReLU9 -> Eltwise4 (in-place)
I0702 00:34:49.136966 13010 net.cpp:150] Setting up ReLU9
I0702 00:34:49.136972 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.136981 13010 net.cpp:165] Memory required for data: 94765184
I0702 00:34:49.136987 13010 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0702 00:34:49.136996 13010 net.cpp:106] Creating Layer Eltwise4_ReLU9_0_split
I0702 00:34:49.137007 13010 net.cpp:454] Eltwise4_ReLU9_0_split <- Eltwise4
I0702 00:34:49.137017 13010 net.cpp:411] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0702 00:34:49.137028 13010 net.cpp:411] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0702 00:34:49.137040 13010 net.cpp:150] Setting up Eltwise4_ReLU9_0_split
I0702 00:34:49.137048 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137058 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137065 13010 net.cpp:165] Memory required for data: 96862336
I0702 00:34:49.136451 32261 net.cpp:150] Setting up Convolution11
I0702 00:34:49.137071 13010 layer_factory.hpp:77] Creating layer Convolution11
I0702 00:34:49.136464 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.136473 32261 net.cpp:165] Memory required for data: 97910912
I0702 00:34:49.137090 13010 net.cpp:106] Creating Layer Convolution11
I0702 00:34:49.136834 20914 net.cpp:150] Setting up Convolution10
I0702 00:34:49.136485 32261 layer_factory.hpp:77] Creating layer BatchNorm11
I0702 00:34:49.137099 13010 net.cpp:454] Convolution11 <- Eltwise4_ReLU9_0_split_0
I0702 00:34:49.136495 32261 net.cpp:106] Creating Layer BatchNorm11
I0702 00:34:49.137110 13010 net.cpp:411] Convolution11 -> Convolution11
I0702 00:34:49.136848 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.136864 20914 net.cpp:165] Memory required for data: 90570880
I0702 00:34:49.136503 32261 net.cpp:454] BatchNorm11 <- Convolution11
I0702 00:34:49.136893 20914 layer_factory.hpp:77] Creating layer BatchNorm10
I0702 00:34:49.136514 32261 net.cpp:397] BatchNorm11 -> Convolution11 (in-place)
I0702 00:34:49.136912 20914 net.cpp:106] Creating Layer BatchNorm10
I0702 00:34:49.136539 32261 net.cpp:150] Setting up BatchNorm11
I0702 00:34:49.136922 20914 net.cpp:454] BatchNorm10 <- Convolution10
I0702 00:34:49.136932 20914 net.cpp:397] BatchNorm10 -> Convolution10 (in-place)
I0702 00:34:49.136548 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.136963 20914 net.cpp:150] Setting up BatchNorm10
I0702 00:34:49.136557 32261 net.cpp:165] Memory required for data: 98959488
I0702 00:34:49.136974 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.136571 32261 layer_factory.hpp:77] Creating layer Scale11
I0702 00:34:49.136983 20914 net.cpp:165] Memory required for data: 91619456
I0702 00:34:49.136584 32261 net.cpp:106] Creating Layer Scale11
I0702 00:34:49.137364 13010 net.cpp:150] Setting up Convolution11
I0702 00:34:49.136997 20914 layer_factory.hpp:77] Creating layer Scale10
I0702 00:34:49.136600 32261 net.cpp:454] Scale11 <- Convolution11
I0702 00:34:49.137012 20914 net.cpp:106] Creating Layer Scale10
I0702 00:34:49.136610 32261 net.cpp:397] Scale11 -> Convolution11 (in-place)
I0702 00:34:49.137377 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137385 13010 net.cpp:165] Memory required for data: 97910912
I0702 00:34:49.137022 20914 net.cpp:454] Scale10 <- Convolution10
I0702 00:34:49.136626 32261 layer_factory.hpp:77] Creating layer Scale11
I0702 00:34:49.137398 13010 layer_factory.hpp:77] Creating layer BatchNorm11
I0702 00:34:49.137032 20914 net.cpp:397] Scale10 -> Convolution10 (in-place)
I0702 00:34:49.137051 20914 layer_factory.hpp:77] Creating layer Scale10
I0702 00:34:49.136656 32261 net.cpp:150] Setting up Scale11
I0702 00:34:49.137420 13010 net.cpp:106] Creating Layer BatchNorm11
I0702 00:34:49.137082 20914 net.cpp:150] Setting up Scale10
I0702 00:34:49.136667 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137428 13010 net.cpp:454] BatchNorm11 <- Convolution11
I0702 00:34:49.137094 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.136675 32261 net.cpp:165] Memory required for data: 100008064
I0702 00:34:49.137437 13010 net.cpp:397] BatchNorm11 -> Convolution11 (in-place)
I0702 00:34:49.137102 20914 net.cpp:165] Memory required for data: 92668032
I0702 00:34:49.136687 32261 layer_factory.hpp:77] Creating layer ReLU10
I0702 00:34:49.137115 20914 layer_factory.hpp:77] Creating layer Eltwise4
I0702 00:34:49.136696 32261 net.cpp:106] Creating Layer ReLU10
I0702 00:34:49.137461 13010 net.cpp:150] Setting up BatchNorm11
I0702 00:34:49.137125 20914 net.cpp:106] Creating Layer Eltwise4
I0702 00:34:49.136703 32261 net.cpp:454] ReLU10 <- Convolution11
I0702 00:34:49.137470 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137131 20914 net.cpp:454] Eltwise4 <- Convolution8
I0702 00:34:49.136714 32261 net.cpp:397] ReLU10 -> Convolution11 (in-place)
I0702 00:34:49.137482 13010 net.cpp:165] Memory required for data: 98959488
I0702 00:34:49.137140 20914 net.cpp:454] Eltwise4 <- Convolution10
I0702 00:34:49.136725 32261 net.cpp:150] Setting up ReLU10
I0702 00:34:49.137495 13010 layer_factory.hpp:77] Creating layer Scale11
I0702 00:34:49.137153 20914 net.cpp:411] Eltwise4 -> Eltwise4
I0702 00:34:49.136732 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137507 13010 net.cpp:106] Creating Layer Scale11
I0702 00:34:49.137171 20914 net.cpp:150] Setting up Eltwise4
I0702 00:34:49.136741 32261 net.cpp:165] Memory required for data: 101056640
I0702 00:34:49.137522 13010 net.cpp:454] Scale11 <- Convolution11
I0702 00:34:49.137179 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137188 20914 net.cpp:165] Memory required for data: 93716608
I0702 00:34:49.136747 32261 layer_factory.hpp:77] Creating layer Convolution12
I0702 00:34:49.137195 20914 layer_factory.hpp:77] Creating layer ReLU9
I0702 00:34:49.137204 20914 net.cpp:106] Creating Layer ReLU9
I0702 00:34:49.137210 20914 net.cpp:454] ReLU9 <- Eltwise4
I0702 00:34:49.136766 32261 net.cpp:106] Creating Layer Convolution12
I0702 00:34:49.137536 13010 net.cpp:397] Scale11 -> Convolution11 (in-place)
I0702 00:34:49.137239 20914 net.cpp:397] ReLU9 -> Eltwise4 (in-place)
I0702 00:34:49.136775 32261 net.cpp:454] Convolution12 <- Convolution11
I0702 00:34:49.137554 13010 layer_factory.hpp:77] Creating layer Scale11
I0702 00:34:49.137254 20914 net.cpp:150] Setting up ReLU9
I0702 00:34:49.136787 32261 net.cpp:411] Convolution12 -> Convolution12
I0702 00:34:49.137581 13010 net.cpp:150] Setting up Scale11
I0702 00:34:49.137261 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137591 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137270 20914 net.cpp:165] Memory required for data: 94765184
I0702 00:34:49.137600 13010 net.cpp:165] Memory required for data: 100008064
I0702 00:34:49.137276 20914 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0702 00:34:49.137611 13010 layer_factory.hpp:77] Creating layer ReLU10
I0702 00:34:49.137286 20914 net.cpp:106] Creating Layer Eltwise4_ReLU9_0_split
I0702 00:34:49.137292 20914 net.cpp:454] Eltwise4_ReLU9_0_split <- Eltwise4
I0702 00:34:49.137301 20914 net.cpp:411] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0702 00:34:49.137312 20914 net.cpp:411] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0702 00:34:49.137626 13010 net.cpp:106] Creating Layer ReLU10
I0702 00:34:49.137327 20914 net.cpp:150] Setting up Eltwise4_ReLU9_0_split
I0702 00:34:49.137045 32261 net.cpp:150] Setting up Convolution12
I0702 00:34:49.137635 13010 net.cpp:454] ReLU10 <- Convolution11
I0702 00:34:49.137337 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137643 13010 net.cpp:397] ReLU10 -> Convolution11 (in-place)
I0702 00:34:49.137351 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137655 13010 net.cpp:150] Setting up ReLU10
I0702 00:34:49.137361 20914 net.cpp:165] Memory required for data: 96862336
I0702 00:34:49.137058 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137660 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137367 20914 layer_factory.hpp:77] Creating layer Convolution11
I0702 00:34:49.137070 32261 net.cpp:165] Memory required for data: 102105216
I0702 00:34:49.137668 13010 net.cpp:165] Memory required for data: 101056640
I0702 00:34:49.137392 20914 net.cpp:106] Creating Layer Convolution11
I0702 00:34:49.137082 32261 layer_factory.hpp:77] Creating layer BatchNorm12
I0702 00:34:49.137676 13010 layer_factory.hpp:77] Creating layer Convolution12
I0702 00:34:49.137403 20914 net.cpp:454] Convolution11 <- Eltwise4_ReLU9_0_split_0
I0702 00:34:49.137092 32261 net.cpp:106] Creating Layer BatchNorm12
I0702 00:34:49.137696 13010 net.cpp:106] Creating Layer Convolution12
I0702 00:34:49.137414 20914 net.cpp:411] Convolution11 -> Convolution11
I0702 00:34:49.137706 13010 net.cpp:454] Convolution12 <- Convolution11
I0702 00:34:49.137099 32261 net.cpp:454] BatchNorm12 <- Convolution12
I0702 00:34:49.137718 13010 net.cpp:411] Convolution12 -> Convolution12
I0702 00:34:49.137111 32261 net.cpp:397] BatchNorm12 -> Convolution12 (in-place)
I0702 00:34:49.137136 32261 net.cpp:150] Setting up BatchNorm12
I0702 00:34:49.137145 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137154 32261 net.cpp:165] Memory required for data: 103153792
I0702 00:34:49.137168 32261 layer_factory.hpp:77] Creating layer Scale12
I0702 00:34:49.137179 32261 net.cpp:106] Creating Layer Scale12
I0702 00:34:49.137187 32261 net.cpp:454] Scale12 <- Convolution12
I0702 00:34:49.137197 32261 net.cpp:397] Scale12 -> Convolution12 (in-place)
I0702 00:34:49.137214 32261 layer_factory.hpp:77] Creating layer Scale12
I0702 00:34:49.137244 32261 net.cpp:150] Setting up Scale12
I0702 00:34:49.137254 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137980 13010 net.cpp:150] Setting up Convolution12
I0702 00:34:49.137272 32261 net.cpp:165] Memory required for data: 104202368
I0702 00:34:49.137284 32261 layer_factory.hpp:77] Creating layer Eltwise5
I0702 00:34:49.137295 32261 net.cpp:106] Creating Layer Eltwise5
I0702 00:34:49.137993 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138002 13010 net.cpp:165] Memory required for data: 102105216
I0702 00:34:49.137300 32261 net.cpp:454] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0702 00:34:49.138013 13010 layer_factory.hpp:77] Creating layer BatchNorm12
I0702 00:34:49.137308 32261 net.cpp:454] Eltwise5 <- Convolution12
I0702 00:34:49.137692 20914 net.cpp:150] Setting up Convolution11
I0702 00:34:49.138027 13010 net.cpp:106] Creating Layer BatchNorm12
I0702 00:34:49.137706 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137717 20914 net.cpp:165] Memory required for data: 97910912
I0702 00:34:49.137320 32261 net.cpp:411] Eltwise5 -> Eltwise5
I0702 00:34:49.138036 13010 net.cpp:454] BatchNorm12 <- Convolution12
I0702 00:34:49.137727 20914 layer_factory.hpp:77] Creating layer BatchNorm11
I0702 00:34:49.137336 32261 net.cpp:150] Setting up Eltwise5
I0702 00:34:49.138046 13010 net.cpp:397] BatchNorm12 -> Convolution12 (in-place)
I0702 00:34:49.137744 20914 net.cpp:106] Creating Layer BatchNorm11
I0702 00:34:49.137342 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137755 20914 net.cpp:454] BatchNorm11 <- Convolution11
I0702 00:34:49.137351 32261 net.cpp:165] Memory required for data: 105250944
I0702 00:34:49.137765 20914 net.cpp:397] BatchNorm11 -> Convolution11 (in-place)
I0702 00:34:49.137357 32261 layer_factory.hpp:77] Creating layer ReLU11
I0702 00:34:49.138068 13010 net.cpp:150] Setting up BatchNorm12
I0702 00:34:49.137792 20914 net.cpp:150] Setting up BatchNorm11
I0702 00:34:49.137365 32261 net.cpp:106] Creating Layer ReLU11
I0702 00:34:49.138077 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137804 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137812 20914 net.cpp:165] Memory required for data: 98959488
I0702 00:34:49.137372 32261 net.cpp:454] ReLU11 <- Eltwise5
I0702 00:34:49.138087 13010 net.cpp:165] Memory required for data: 103153792
I0702 00:34:49.137828 20914 layer_factory.hpp:77] Creating layer Scale11
I0702 00:34:49.138103 13010 layer_factory.hpp:77] Creating layer Scale12
I0702 00:34:49.137840 20914 net.cpp:106] Creating Layer Scale11
I0702 00:34:49.137383 32261 net.cpp:397] ReLU11 -> Eltwise5 (in-place)
I0702 00:34:49.138114 13010 net.cpp:106] Creating Layer Scale12
I0702 00:34:49.137856 20914 net.cpp:454] Scale11 <- Convolution11
I0702 00:34:49.137395 32261 net.cpp:150] Setting up ReLU11
I0702 00:34:49.138120 13010 net.cpp:454] Scale12 <- Convolution12
I0702 00:34:49.137866 20914 net.cpp:397] Scale11 -> Convolution11 (in-place)
I0702 00:34:49.137401 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138129 13010 net.cpp:397] Scale12 -> Convolution12 (in-place)
I0702 00:34:49.137883 20914 layer_factory.hpp:77] Creating layer Scale11
I0702 00:34:49.137409 32261 net.cpp:165] Memory required for data: 106299520
I0702 00:34:49.137914 20914 net.cpp:150] Setting up Scale11
I0702 00:34:49.137416 32261 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0702 00:34:49.138149 13010 layer_factory.hpp:77] Creating layer Scale12
I0702 00:34:49.137926 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137424 32261 net.cpp:106] Creating Layer Eltwise5_ReLU11_0_split
I0702 00:34:49.138176 13010 net.cpp:150] Setting up Scale12
I0702 00:34:49.137935 20914 net.cpp:165] Memory required for data: 100008064
I0702 00:34:49.137431 32261 net.cpp:454] Eltwise5_ReLU11_0_split <- Eltwise5
I0702 00:34:49.138185 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137946 20914 layer_factory.hpp:77] Creating layer ReLU10
I0702 00:34:49.137439 32261 net.cpp:411] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0702 00:34:49.138195 13010 net.cpp:165] Memory required for data: 104202368
I0702 00:34:49.137960 20914 net.cpp:106] Creating Layer ReLU10
I0702 00:34:49.137450 32261 net.cpp:411] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0702 00:34:49.138206 13010 layer_factory.hpp:77] Creating layer Eltwise5
I0702 00:34:49.137969 20914 net.cpp:454] ReLU10 <- Convolution11
I0702 00:34:49.137462 32261 net.cpp:150] Setting up Eltwise5_ReLU11_0_split
I0702 00:34:49.138218 13010 net.cpp:106] Creating Layer Eltwise5
I0702 00:34:49.137979 20914 net.cpp:397] ReLU10 -> Convolution11 (in-place)
I0702 00:34:49.137470 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138226 13010 net.cpp:454] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0702 00:34:49.137989 20914 net.cpp:150] Setting up ReLU10
I0702 00:34:49.137487 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138234 13010 net.cpp:454] Eltwise5 <- Convolution12
I0702 00:34:49.137995 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.137495 32261 net.cpp:165] Memory required for data: 108396672
I0702 00:34:49.138243 13010 net.cpp:411] Eltwise5 -> Eltwise5
I0702 00:34:49.138003 20914 net.cpp:165] Memory required for data: 101056640
I0702 00:34:49.137502 32261 layer_factory.hpp:77] Creating layer Convolution13
I0702 00:34:49.138257 13010 net.cpp:150] Setting up Eltwise5
I0702 00:34:49.138010 20914 layer_factory.hpp:77] Creating layer Convolution12
I0702 00:34:49.137521 32261 net.cpp:106] Creating Layer Convolution13
I0702 00:34:49.138264 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138036 20914 net.cpp:106] Creating Layer Convolution12
I0702 00:34:49.137531 32261 net.cpp:454] Convolution13 <- Eltwise5_ReLU11_0_split_0
I0702 00:34:49.138273 13010 net.cpp:165] Memory required for data: 105250944
I0702 00:34:49.138048 20914 net.cpp:454] Convolution12 <- Convolution11
I0702 00:34:49.138279 13010 layer_factory.hpp:77] Creating layer ReLU11
I0702 00:34:49.138061 20914 net.cpp:411] Convolution12 -> Convolution12
I0702 00:34:49.138290 13010 net.cpp:106] Creating Layer ReLU11
I0702 00:34:49.138298 13010 net.cpp:454] ReLU11 <- Eltwise5
I0702 00:34:49.137543 32261 net.cpp:411] Convolution13 -> Convolution13
I0702 00:34:49.137801 32261 net.cpp:150] Setting up Convolution13
I0702 00:34:49.138305 13010 net.cpp:397] ReLU11 -> Eltwise5 (in-place)
I0702 00:34:49.138315 13010 net.cpp:150] Setting up ReLU11
I0702 00:34:49.138321 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138329 13010 net.cpp:165] Memory required for data: 106299520
I0702 00:34:49.138336 13010 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0702 00:34:49.137814 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138345 13010 net.cpp:106] Creating Layer Eltwise5_ReLU11_0_split
I0702 00:34:49.137823 32261 net.cpp:165] Memory required for data: 109445248
I0702 00:34:49.138351 13010 net.cpp:454] Eltwise5_ReLU11_0_split <- Eltwise5
I0702 00:34:49.137835 32261 layer_factory.hpp:77] Creating layer BatchNorm13
I0702 00:34:49.138362 13010 net.cpp:411] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0702 00:34:49.137845 32261 net.cpp:106] Creating Layer BatchNorm13
I0702 00:34:49.138373 13010 net.cpp:411] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0702 00:34:49.137852 32261 net.cpp:454] BatchNorm13 <- Convolution13
I0702 00:34:49.138386 13010 net.cpp:150] Setting up Eltwise5_ReLU11_0_split
I0702 00:34:49.138394 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138418 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138427 13010 net.cpp:165] Memory required for data: 108396672
I0702 00:34:49.137864 32261 net.cpp:397] BatchNorm13 -> Convolution13 (in-place)
I0702 00:34:49.138434 13010 layer_factory.hpp:77] Creating layer Convolution13
I0702 00:34:49.137889 32261 net.cpp:150] Setting up BatchNorm13
I0702 00:34:49.138454 13010 net.cpp:106] Creating Layer Convolution13
I0702 00:34:49.137898 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138463 13010 net.cpp:454] Convolution13 <- Eltwise5_ReLU11_0_split_0
I0702 00:34:49.137907 32261 net.cpp:165] Memory required for data: 110493824
I0702 00:34:49.138474 13010 net.cpp:411] Convolution13 -> Convolution13
I0702 00:34:49.137920 32261 layer_factory.hpp:77] Creating layer Scale13
I0702 00:34:49.137934 32261 net.cpp:106] Creating Layer Scale13
I0702 00:34:49.137941 32261 net.cpp:454] Scale13 <- Convolution13
I0702 00:34:49.137950 32261 net.cpp:397] Scale13 -> Convolution13 (in-place)
I0702 00:34:49.137966 32261 layer_factory.hpp:77] Creating layer Scale13
I0702 00:34:49.138350 20914 net.cpp:150] Setting up Convolution12
I0702 00:34:49.137996 32261 net.cpp:150] Setting up Scale13
I0702 00:34:49.138363 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138373 20914 net.cpp:165] Memory required for data: 102105216
I0702 00:34:49.138006 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138386 20914 layer_factory.hpp:77] Creating layer BatchNorm12
I0702 00:34:49.138015 32261 net.cpp:165] Memory required for data: 111542400
I0702 00:34:49.138731 13010 net.cpp:150] Setting up Convolution13
I0702 00:34:49.138398 20914 net.cpp:106] Creating Layer BatchNorm12
I0702 00:34:49.138406 20914 net.cpp:454] BatchNorm12 <- Convolution12
I0702 00:34:49.138415 20914 net.cpp:397] BatchNorm12 -> Convolution12 (in-place)
I0702 00:34:49.138026 32261 layer_factory.hpp:77] Creating layer ReLU12
I0702 00:34:49.138743 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138752 13010 net.cpp:165] Memory required for data: 109445248
I0702 00:34:49.138442 20914 net.cpp:150] Setting up BatchNorm12
I0702 00:34:49.138036 32261 net.cpp:106] Creating Layer ReLU12
I0702 00:34:49.138764 13010 layer_factory.hpp:77] Creating layer BatchNorm13
I0702 00:34:49.138453 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138042 32261 net.cpp:454] ReLU12 <- Convolution13
I0702 00:34:49.138777 13010 net.cpp:106] Creating Layer BatchNorm13
I0702 00:34:49.138463 20914 net.cpp:165] Memory required for data: 103153792
I0702 00:34:49.138053 32261 net.cpp:397] ReLU12 -> Convolution13 (in-place)
I0702 00:34:49.138787 13010 net.cpp:454] BatchNorm13 <- Convolution13
I0702 00:34:49.138474 20914 layer_factory.hpp:77] Creating layer Scale12
I0702 00:34:49.138063 32261 net.cpp:150] Setting up ReLU12
I0702 00:34:49.138795 13010 net.cpp:397] BatchNorm13 -> Convolution13 (in-place)
I0702 00:34:49.138490 20914 net.cpp:106] Creating Layer Scale12
I0702 00:34:49.138070 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138500 20914 net.cpp:454] Scale12 <- Convolution12
I0702 00:34:49.138078 32261 net.cpp:165] Memory required for data: 112590976
I0702 00:34:49.138510 20914 net.cpp:397] Scale12 -> Convolution12 (in-place)
I0702 00:34:49.138084 32261 layer_factory.hpp:77] Creating layer Convolution14
I0702 00:34:49.138819 13010 net.cpp:150] Setting up BatchNorm13
I0702 00:34:49.138531 20914 layer_factory.hpp:77] Creating layer Scale12
I0702 00:34:49.138828 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138561 20914 net.cpp:150] Setting up Scale12
I0702 00:34:49.138103 32261 net.cpp:106] Creating Layer Convolution14
I0702 00:34:49.138839 13010 net.cpp:165] Memory required for data: 110493824
I0702 00:34:49.138573 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138111 32261 net.cpp:454] Convolution14 <- Convolution13
I0702 00:34:49.138852 13010 layer_factory.hpp:77] Creating layer Scale13
I0702 00:34:49.138582 20914 net.cpp:165] Memory required for data: 104202368
I0702 00:34:49.138128 32261 net.cpp:411] Convolution14 -> Convolution14
I0702 00:34:49.138864 13010 net.cpp:106] Creating Layer Scale13
I0702 00:34:49.138593 20914 layer_factory.hpp:77] Creating layer Eltwise5
I0702 00:34:49.138871 13010 net.cpp:454] Scale13 <- Convolution13
I0702 00:34:49.138608 20914 net.cpp:106] Creating Layer Eltwise5
I0702 00:34:49.138882 13010 net.cpp:397] Scale13 -> Convolution13 (in-place)
I0702 00:34:49.138619 20914 net.cpp:454] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0702 00:34:49.138628 20914 net.cpp:454] Eltwise5 <- Convolution12
I0702 00:34:49.138638 20914 net.cpp:411] Eltwise5 -> Eltwise5
I0702 00:34:49.138650 20914 net.cpp:150] Setting up Eltwise5
I0702 00:34:49.138900 13010 layer_factory.hpp:77] Creating layer Scale13
I0702 00:34:49.138659 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138931 13010 net.cpp:150] Setting up Scale13
I0702 00:34:49.138669 20914 net.cpp:165] Memory required for data: 105250944
I0702 00:34:49.138941 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138674 20914 layer_factory.hpp:77] Creating layer ReLU11
I0702 00:34:49.138949 13010 net.cpp:165] Memory required for data: 111542400
I0702 00:34:49.138686 20914 net.cpp:106] Creating Layer ReLU11
I0702 00:34:49.138960 13010 layer_factory.hpp:77] Creating layer ReLU12
I0702 00:34:49.138694 20914 net.cpp:454] ReLU11 <- Eltwise5
I0702 00:34:49.138972 13010 net.cpp:106] Creating Layer ReLU12
I0702 00:34:49.138702 20914 net.cpp:397] ReLU11 -> Eltwise5 (in-place)
I0702 00:34:49.138398 32261 net.cpp:150] Setting up Convolution14
I0702 00:34:49.138980 13010 net.cpp:454] ReLU12 <- Convolution13
I0702 00:34:49.138712 20914 net.cpp:150] Setting up ReLU11
I0702 00:34:49.138989 13010 net.cpp:397] ReLU12 -> Convolution13 (in-place)
I0702 00:34:49.138718 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138412 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138422 32261 net.cpp:165] Memory required for data: 113639552
I0702 00:34:49.138999 13010 net.cpp:150] Setting up ReLU12
I0702 00:34:49.138726 20914 net.cpp:165] Memory required for data: 106299520
I0702 00:34:49.138433 32261 layer_factory.hpp:77] Creating layer BatchNorm14
I0702 00:34:49.139006 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138733 20914 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0702 00:34:49.139014 13010 net.cpp:165] Memory required for data: 112590976
I0702 00:34:49.138742 20914 net.cpp:106] Creating Layer Eltwise5_ReLU11_0_split
I0702 00:34:49.138748 20914 net.cpp:454] Eltwise5_ReLU11_0_split <- Eltwise5
I0702 00:34:49.139020 13010 layer_factory.hpp:77] Creating layer Convolution14
I0702 00:34:49.138762 20914 net.cpp:411] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0702 00:34:49.138451 32261 net.cpp:106] Creating Layer BatchNorm14
I0702 00:34:49.138777 20914 net.cpp:411] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0702 00:34:49.138460 32261 net.cpp:454] BatchNorm14 <- Convolution14
I0702 00:34:49.139040 13010 net.cpp:106] Creating Layer Convolution14
I0702 00:34:49.138789 20914 net.cpp:150] Setting up Eltwise5_ReLU11_0_split
I0702 00:34:49.138473 32261 net.cpp:397] BatchNorm14 -> Convolution14 (in-place)
I0702 00:34:49.139052 13010 net.cpp:454] Convolution14 <- Convolution13
I0702 00:34:49.138797 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.139063 13010 net.cpp:411] Convolution14 -> Convolution14
I0702 00:34:49.138813 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138823 20914 net.cpp:165] Memory required for data: 108396672
I0702 00:34:49.138500 32261 net.cpp:150] Setting up BatchNorm14
I0702 00:34:49.138828 20914 layer_factory.hpp:77] Creating layer Convolution13
I0702 00:34:49.138509 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138850 20914 net.cpp:106] Creating Layer Convolution13
I0702 00:34:49.138519 32261 net.cpp:165] Memory required for data: 114688128
I0702 00:34:49.138865 20914 net.cpp:454] Convolution13 <- Eltwise5_ReLU11_0_split_0
I0702 00:34:49.138532 32261 layer_factory.hpp:77] Creating layer Scale14
I0702 00:34:49.138877 20914 net.cpp:411] Convolution13 -> Convolution13
I0702 00:34:49.138546 32261 net.cpp:106] Creating Layer Scale14
I0702 00:34:49.138556 32261 net.cpp:454] Scale14 <- Convolution14
I0702 00:34:49.139325 13010 net.cpp:150] Setting up Convolution14
I0702 00:34:49.138564 32261 net.cpp:397] Scale14 -> Convolution14 (in-place)
I0702 00:34:49.138581 32261 layer_factory.hpp:77] Creating layer Scale14
I0702 00:34:49.138608 32261 net.cpp:150] Setting up Scale14
I0702 00:34:49.138618 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.139338 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138628 32261 net.cpp:165] Memory required for data: 115736704
I0702 00:34:49.139350 13010 net.cpp:165] Memory required for data: 113639552
I0702 00:34:49.138638 32261 layer_factory.hpp:77] Creating layer Eltwise6
I0702 00:34:49.139362 13010 layer_factory.hpp:77] Creating layer BatchNorm14
I0702 00:34:49.138650 32261 net.cpp:106] Creating Layer Eltwise6
I0702 00:34:49.139379 13010 net.cpp:106] Creating Layer BatchNorm14
I0702 00:34:49.138658 32261 net.cpp:454] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0702 00:34:49.139389 13010 net.cpp:454] BatchNorm14 <- Convolution14
I0702 00:34:49.138665 32261 net.cpp:454] Eltwise6 <- Convolution14
I0702 00:34:49.139405 13010 net.cpp:397] BatchNorm14 -> Convolution14 (in-place)
I0702 00:34:49.138684 32261 net.cpp:411] Eltwise6 -> Eltwise6
I0702 00:34:49.138700 32261 net.cpp:150] Setting up Eltwise6
I0702 00:34:49.138708 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138716 32261 net.cpp:165] Memory required for data: 116785280
I0702 00:34:49.139432 13010 net.cpp:150] Setting up BatchNorm14
I0702 00:34:49.139441 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.139453 13010 net.cpp:165] Memory required for data: 114688128
I0702 00:34:49.138723 32261 layer_factory.hpp:77] Creating layer ReLU13
I0702 00:34:49.138731 32261 net.cpp:106] Creating Layer ReLU13
I0702 00:34:49.139467 13010 layer_factory.hpp:77] Creating layer Scale14
I0702 00:34:49.139155 20914 net.cpp:150] Setting up Convolution13
I0702 00:34:49.138738 32261 net.cpp:454] ReLU13 <- Eltwise6
I0702 00:34:49.139479 13010 net.cpp:106] Creating Layer Scale14
I0702 00:34:49.138746 32261 net.cpp:397] ReLU13 -> Eltwise6 (in-place)
I0702 00:34:49.139487 13010 net.cpp:454] Scale14 <- Convolution14
I0702 00:34:49.139169 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.139179 20914 net.cpp:165] Memory required for data: 109445248
I0702 00:34:49.138756 32261 net.cpp:150] Setting up ReLU13
I0702 00:34:49.139497 13010 net.cpp:397] Scale14 -> Convolution14 (in-place)
I0702 00:34:49.139190 20914 layer_factory.hpp:77] Creating layer BatchNorm13
I0702 00:34:49.138762 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.139207 20914 net.cpp:106] Creating Layer BatchNorm13
I0702 00:34:49.138775 32261 net.cpp:165] Memory required for data: 117833856
I0702 00:34:49.139514 13010 layer_factory.hpp:77] Creating layer Scale14
I0702 00:34:49.139216 20914 net.cpp:454] BatchNorm13 <- Convolution13
I0702 00:34:49.138782 32261 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0702 00:34:49.139542 13010 net.cpp:150] Setting up Scale14
I0702 00:34:49.139232 20914 net.cpp:397] BatchNorm13 -> Convolution13 (in-place)
I0702 00:34:49.138792 32261 net.cpp:106] Creating Layer Eltwise6_ReLU13_0_split
I0702 00:34:49.139552 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.139259 20914 net.cpp:150] Setting up BatchNorm13
I0702 00:34:49.138798 32261 net.cpp:454] Eltwise6_ReLU13_0_split <- Eltwise6
I0702 00:34:49.139564 13010 net.cpp:165] Memory required for data: 115736704
I0702 00:34:49.139268 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.139576 13010 layer_factory.hpp:77] Creating layer Eltwise6
I0702 00:34:49.139277 20914 net.cpp:165] Memory required for data: 110493824
I0702 00:34:49.139293 20914 layer_factory.hpp:77] Creating layer Scale13
I0702 00:34:49.138806 32261 net.cpp:411] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0702 00:34:49.139586 13010 net.cpp:106] Creating Layer Eltwise6
I0702 00:34:49.139305 20914 net.cpp:106] Creating Layer Scale13
I0702 00:34:49.138818 32261 net.cpp:411] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0702 00:34:49.139595 13010 net.cpp:454] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0702 00:34:49.139313 20914 net.cpp:454] Scale13 <- Convolution13
I0702 00:34:49.138828 32261 net.cpp:150] Setting up Eltwise6_ReLU13_0_split
I0702 00:34:49.139602 13010 net.cpp:454] Eltwise6 <- Convolution14
I0702 00:34:49.139322 20914 net.cpp:397] Scale13 -> Convolution13 (in-place)
I0702 00:34:49.138834 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.139344 20914 layer_factory.hpp:77] Creating layer Scale13
I0702 00:34:49.138844 32261 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.139693 13010 net.cpp:411] Eltwise6 -> Eltwise6
I0702 00:34:49.139379 20914 net.cpp:150] Setting up Scale13
I0702 00:34:49.138851 32261 net.cpp:165] Memory required for data: 119931008
I0702 00:34:49.139717 13010 net.cpp:150] Setting up Eltwise6
I0702 00:34:49.139389 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.138857 32261 layer_factory.hpp:77] Creating layer Convolution15
I0702 00:34:49.139726 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.139398 20914 net.cpp:165] Memory required for data: 111542400
I0702 00:34:49.138876 32261 net.cpp:106] Creating Layer Convolution15
I0702 00:34:49.139735 13010 net.cpp:165] Memory required for data: 116785280
I0702 00:34:49.139410 20914 layer_factory.hpp:77] Creating layer ReLU12
I0702 00:34:49.138885 32261 net.cpp:454] Convolution15 <- Eltwise6_ReLU13_0_split_0
I0702 00:34:49.139742 13010 layer_factory.hpp:77] Creating layer ReLU13
I0702 00:34:49.139422 20914 net.cpp:106] Creating Layer ReLU12
I0702 00:34:49.138896 32261 net.cpp:411] Convolution15 -> Convolution15
I0702 00:34:49.139430 20914 net.cpp:454] ReLU12 <- Convolution13
I0702 00:34:49.139439 20914 net.cpp:397] ReLU12 -> Convolution13 (in-place)
I0702 00:34:49.139755 13010 net.cpp:106] Creating Layer ReLU13
I0702 00:34:49.139451 20914 net.cpp:150] Setting up ReLU12
I0702 00:34:49.139011 32261 net.cpp:150] Setting up Convolution15
I0702 00:34:49.139763 13010 net.cpp:454] ReLU13 <- Eltwise6
I0702 00:34:49.139456 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.139024 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.139772 13010 net.cpp:397] ReLU13 -> Eltwise6 (in-place)
I0702 00:34:49.139464 20914 net.cpp:165] Memory required for data: 112590976
I0702 00:34:49.139083 32261 net.cpp:165] Memory required for data: 120455296
I0702 00:34:49.139782 13010 net.cpp:150] Setting up ReLU13
I0702 00:34:49.139472 20914 layer_factory.hpp:77] Creating layer Convolution14
I0702 00:34:49.139101 32261 layer_factory.hpp:77] Creating layer BatchNorm15
I0702 00:34:49.139789 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.139494 20914 net.cpp:106] Creating Layer Convolution14
I0702 00:34:49.139117 32261 net.cpp:106] Creating Layer BatchNorm15
I0702 00:34:49.139797 13010 net.cpp:165] Memory required for data: 117833856
I0702 00:34:49.139505 20914 net.cpp:454] Convolution14 <- Convolution13
I0702 00:34:49.139127 32261 net.cpp:454] BatchNorm15 <- Convolution15
I0702 00:34:49.139804 13010 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0702 00:34:49.139518 20914 net.cpp:411] Convolution14 -> Convolution14
I0702 00:34:49.139138 32261 net.cpp:397] BatchNorm15 -> Convolution15 (in-place)
I0702 00:34:49.139813 13010 net.cpp:106] Creating Layer Eltwise6_ReLU13_0_split
I0702 00:34:49.139820 13010 net.cpp:454] Eltwise6_ReLU13_0_split <- Eltwise6
I0702 00:34:49.139828 13010 net.cpp:411] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0702 00:34:49.139164 32261 net.cpp:150] Setting up BatchNorm15
I0702 00:34:49.139173 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.139183 32261 net.cpp:165] Memory required for data: 120979584
I0702 00:34:49.139843 13010 net.cpp:411] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0702 00:34:49.139201 32261 layer_factory.hpp:77] Creating layer Scale15
I0702 00:34:49.139858 13010 net.cpp:150] Setting up Eltwise6_ReLU13_0_split
I0702 00:34:49.139214 32261 net.cpp:106] Creating Layer Scale15
I0702 00:34:49.139864 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.139220 32261 net.cpp:454] Scale15 <- Convolution15
I0702 00:34:49.139873 13010 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.139230 32261 net.cpp:397] Scale15 -> Convolution15 (in-place)
I0702 00:34:49.139881 13010 net.cpp:165] Memory required for data: 119931008
I0702 00:34:49.139250 32261 layer_factory.hpp:77] Creating layer Scale15
I0702 00:34:49.139889 13010 layer_factory.hpp:77] Creating layer Convolution15
I0702 00:34:49.139911 13010 net.cpp:106] Creating Layer Convolution15
I0702 00:34:49.139920 13010 net.cpp:454] Convolution15 <- Eltwise6_ReLU13_0_split_0
I0702 00:34:49.139932 13010 net.cpp:411] Convolution15 -> Convolution15
I0702 00:34:49.139286 32261 net.cpp:150] Setting up Scale15
I0702 00:34:49.139297 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.139307 32261 net.cpp:165] Memory required for data: 121503872
I0702 00:34:49.139318 32261 layer_factory.hpp:77] Creating layer Convolution16
I0702 00:34:49.140050 13010 net.cpp:150] Setting up Convolution15
I0702 00:34:49.139341 32261 net.cpp:106] Creating Layer Convolution16
I0702 00:34:49.140064 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.139351 32261 net.cpp:454] Convolution16 <- Eltwise6_ReLU13_0_split_1
I0702 00:34:49.140072 13010 net.cpp:165] Memory required for data: 120455296
I0702 00:34:49.140084 13010 layer_factory.hpp:77] Creating layer BatchNorm15
I0702 00:34:49.139362 32261 net.cpp:411] Convolution16 -> Convolution16
I0702 00:34:49.140094 13010 net.cpp:106] Creating Layer BatchNorm15
I0702 00:34:49.140103 13010 net.cpp:454] BatchNorm15 <- Convolution15
I0702 00:34:49.140125 13010 net.cpp:397] BatchNorm15 -> Convolution15 (in-place)
I0702 00:34:49.139797 20914 net.cpp:150] Setting up Convolution14
I0702 00:34:49.139812 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.139822 20914 net.cpp:165] Memory required for data: 113639552
I0702 00:34:49.139837 20914 layer_factory.hpp:77] Creating layer BatchNorm14
I0702 00:34:49.140152 13010 net.cpp:150] Setting up BatchNorm15
I0702 00:34:49.139856 20914 net.cpp:106] Creating Layer BatchNorm14
I0702 00:34:49.140161 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.139868 20914 net.cpp:454] BatchNorm14 <- Convolution14
I0702 00:34:49.140169 13010 net.cpp:165] Memory required for data: 120979584
I0702 00:34:49.139880 20914 net.cpp:397] BatchNorm14 -> Convolution14 (in-place)
I0702 00:34:49.140183 13010 layer_factory.hpp:77] Creating layer Scale15
I0702 00:34:49.139907 20914 net.cpp:150] Setting up BatchNorm14
I0702 00:34:49.139919 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.139927 20914 net.cpp:165] Memory required for data: 114688128
I0702 00:34:49.140198 13010 net.cpp:106] Creating Layer Scale15
I0702 00:34:49.139941 20914 layer_factory.hpp:77] Creating layer Scale14
I0702 00:34:49.139952 20914 net.cpp:106] Creating Layer Scale14
I0702 00:34:49.140208 13010 net.cpp:454] Scale15 <- Convolution15
I0702 00:34:49.139959 20914 net.cpp:454] Scale14 <- Convolution14
I0702 00:34:49.140218 13010 net.cpp:397] Scale15 -> Convolution15 (in-place)
I0702 00:34:49.140235 13010 layer_factory.hpp:77] Creating layer Scale15
I0702 00:34:49.139976 20914 net.cpp:397] Scale14 -> Convolution14 (in-place)
I0702 00:34:49.140262 13010 net.cpp:150] Setting up Scale15
I0702 00:34:49.139994 20914 layer_factory.hpp:77] Creating layer Scale14
I0702 00:34:49.140272 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.140281 13010 net.cpp:165] Memory required for data: 121503872
I0702 00:34:49.140025 20914 net.cpp:150] Setting up Scale14
I0702 00:34:49.140039 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.140048 20914 net.cpp:165] Memory required for data: 115736704
I0702 00:34:49.140292 13010 layer_factory.hpp:77] Creating layer Convolution16
I0702 00:34:49.140060 20914 layer_factory.hpp:77] Creating layer Eltwise6
I0702 00:34:49.140070 20914 net.cpp:106] Creating Layer Eltwise6
I0702 00:34:49.140316 13010 net.cpp:106] Creating Layer Convolution16
I0702 00:34:49.140079 20914 net.cpp:454] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0702 00:34:49.140327 13010 net.cpp:454] Convolution16 <- Eltwise6_ReLU13_0_split_1
I0702 00:34:49.140085 20914 net.cpp:454] Eltwise6 <- Convolution14
I0702 00:34:49.140338 13010 net.cpp:411] Convolution16 -> Convolution16
I0702 00:34:49.140102 20914 net.cpp:411] Eltwise6 -> Eltwise6
I0702 00:34:49.140116 20914 net.cpp:150] Setting up Eltwise6
I0702 00:34:49.140123 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.140139 20914 net.cpp:165] Memory required for data: 116785280
I0702 00:34:49.139801 32261 net.cpp:150] Setting up Convolution16
I0702 00:34:49.140146 20914 layer_factory.hpp:77] Creating layer ReLU13
I0702 00:34:49.140156 20914 net.cpp:106] Creating Layer ReLU13
I0702 00:34:49.140162 20914 net.cpp:454] ReLU13 <- Eltwise6
I0702 00:34:49.140172 20914 net.cpp:397] ReLU13 -> Eltwise6 (in-place)
I0702 00:34:49.139814 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.139823 32261 net.cpp:165] Memory required for data: 122028160
I0702 00:34:49.140182 20914 net.cpp:150] Setting up ReLU13
I0702 00:34:49.139835 32261 layer_factory.hpp:77] Creating layer BatchNorm16
I0702 00:34:49.140188 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.139845 32261 net.cpp:106] Creating Layer BatchNorm16
I0702 00:34:49.140197 20914 net.cpp:165] Memory required for data: 117833856
I0702 00:34:49.140202 20914 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0702 00:34:49.139853 32261 net.cpp:454] BatchNorm16 <- Convolution16
I0702 00:34:49.140213 20914 net.cpp:106] Creating Layer Eltwise6_ReLU13_0_split
I0702 00:34:49.140225 20914 net.cpp:454] Eltwise6_ReLU13_0_split <- Eltwise6
I0702 00:34:49.140238 20914 net.cpp:411] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0702 00:34:49.139866 32261 net.cpp:397] BatchNorm16 -> Convolution16 (in-place)
I0702 00:34:49.140249 20914 net.cpp:411] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0702 00:34:49.139890 32261 net.cpp:150] Setting up BatchNorm16
I0702 00:34:49.140260 20914 net.cpp:150] Setting up Eltwise6_ReLU13_0_split
I0702 00:34:49.139899 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.140269 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.140277 20914 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.139912 32261 net.cpp:165] Memory required for data: 122552448
I0702 00:34:49.140285 20914 net.cpp:165] Memory required for data: 119931008
I0702 00:34:49.140291 20914 layer_factory.hpp:77] Creating layer Convolution15
I0702 00:34:49.140314 20914 net.cpp:106] Creating Layer Convolution15
I0702 00:34:49.139935 32261 layer_factory.hpp:77] Creating layer Scale16
I0702 00:34:49.140326 20914 net.cpp:454] Convolution15 <- Eltwise6_ReLU13_0_split_0
I0702 00:34:49.139946 32261 net.cpp:106] Creating Layer Scale16
I0702 00:34:49.140342 20914 net.cpp:411] Convolution15 -> Convolution15
I0702 00:34:49.139955 32261 net.cpp:454] Scale16 <- Convolution16
I0702 00:34:49.139968 32261 net.cpp:397] Scale16 -> Convolution16 (in-place)
I0702 00:34:49.139987 32261 layer_factory.hpp:77] Creating layer Scale16
I0702 00:34:49.140017 32261 net.cpp:150] Setting up Scale16
I0702 00:34:49.140027 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.140036 32261 net.cpp:165] Memory required for data: 123076736
I0702 00:34:49.140048 32261 layer_factory.hpp:77] Creating layer ReLU14
I0702 00:34:49.140058 32261 net.cpp:106] Creating Layer ReLU14
I0702 00:34:49.140064 32261 net.cpp:454] ReLU14 <- Convolution16
I0702 00:34:49.140075 32261 net.cpp:397] ReLU14 -> Convolution16 (in-place)
I0702 00:34:49.140460 20914 net.cpp:150] Setting up Convolution15
I0702 00:34:49.140820 13010 net.cpp:150] Setting up Convolution16
I0702 00:34:49.140475 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.140485 20914 net.cpp:165] Memory required for data: 120455296
I0702 00:34:49.140087 32261 net.cpp:150] Setting up ReLU14
I0702 00:34:49.140496 20914 layer_factory.hpp:77] Creating layer BatchNorm15
I0702 00:34:49.140094 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.140102 32261 net.cpp:165] Memory required for data: 123601024
I0702 00:34:49.140836 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.140846 13010 net.cpp:165] Memory required for data: 122028160
I0702 00:34:49.140509 20914 net.cpp:106] Creating Layer BatchNorm15
I0702 00:34:49.140110 32261 layer_factory.hpp:77] Creating layer Convolution17
I0702 00:34:49.140857 13010 layer_factory.hpp:77] Creating layer BatchNorm16
I0702 00:34:49.140517 20914 net.cpp:454] BatchNorm15 <- Convolution15
I0702 00:34:49.140130 32261 net.cpp:106] Creating Layer Convolution17
I0702 00:34:49.140872 13010 net.cpp:106] Creating Layer BatchNorm16
I0702 00:34:49.140527 20914 net.cpp:397] BatchNorm15 -> Convolution15 (in-place)
I0702 00:34:49.140138 32261 net.cpp:454] Convolution17 <- Convolution16
I0702 00:34:49.140882 13010 net.cpp:454] BatchNorm16 <- Convolution16
I0702 00:34:49.140553 20914 net.cpp:150] Setting up BatchNorm15
I0702 00:34:49.140564 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.140573 20914 net.cpp:165] Memory required for data: 120979584
I0702 00:34:49.140151 32261 net.cpp:411] Convolution17 -> Convolution17
I0702 00:34:49.140890 13010 net.cpp:397] BatchNorm16 -> Convolution16 (in-place)
I0702 00:34:49.140586 20914 layer_factory.hpp:77] Creating layer Scale15
I0702 00:34:49.140929 13010 net.cpp:150] Setting up BatchNorm16
I0702 00:34:49.140604 20914 net.cpp:106] Creating Layer Scale15
I0702 00:34:49.140941 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.140614 20914 net.cpp:454] Scale15 <- Convolution15
I0702 00:34:49.140950 13010 net.cpp:165] Memory required for data: 122552448
I0702 00:34:49.140624 20914 net.cpp:397] Scale15 -> Convolution15 (in-place)
I0702 00:34:49.140643 20914 layer_factory.hpp:77] Creating layer Scale15
I0702 00:34:49.140671 20914 net.cpp:150] Setting up Scale15
I0702 00:34:49.140974 13010 layer_factory.hpp:77] Creating layer Scale16
I0702 00:34:49.140682 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.140691 20914 net.cpp:165] Memory required for data: 121503872
I0702 00:34:49.140995 13010 net.cpp:106] Creating Layer Scale16
I0702 00:34:49.140705 20914 layer_factory.hpp:77] Creating layer Convolution16
I0702 00:34:49.141006 13010 net.cpp:454] Scale16 <- Convolution16
I0702 00:34:49.141016 13010 net.cpp:397] Scale16 -> Convolution16 (in-place)
I0702 00:34:49.140729 20914 net.cpp:106] Creating Layer Convolution16
I0702 00:34:49.140740 20914 net.cpp:454] Convolution16 <- Eltwise6_ReLU13_0_split_1
I0702 00:34:49.140756 20914 net.cpp:411] Convolution16 -> Convolution16
I0702 00:34:49.141036 13010 layer_factory.hpp:77] Creating layer Scale16
I0702 00:34:49.141065 13010 net.cpp:150] Setting up Scale16
I0702 00:34:49.141077 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.141086 13010 net.cpp:165] Memory required for data: 123076736
I0702 00:34:49.141098 13010 layer_factory.hpp:77] Creating layer ReLU14
I0702 00:34:49.141111 13010 net.cpp:106] Creating Layer ReLU14
I0702 00:34:49.141120 13010 net.cpp:454] ReLU14 <- Convolution16
I0702 00:34:49.141129 13010 net.cpp:397] ReLU14 -> Convolution16 (in-place)
I0702 00:34:49.141139 13010 net.cpp:150] Setting up ReLU14
I0702 00:34:49.141145 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.141153 13010 net.cpp:165] Memory required for data: 123601024
I0702 00:34:49.141160 13010 layer_factory.hpp:77] Creating layer Convolution17
I0702 00:34:49.141183 13010 net.cpp:106] Creating Layer Convolution17
I0702 00:34:49.141196 13010 net.cpp:454] Convolution17 <- Convolution16
I0702 00:34:49.141206 13010 net.cpp:411] Convolution17 -> Convolution17
I0702 00:34:49.141242 20914 net.cpp:150] Setting up Convolution16
I0702 00:34:49.141258 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.141268 20914 net.cpp:165] Memory required for data: 122028160
I0702 00:34:49.141280 20914 layer_factory.hpp:77] Creating layer BatchNorm16
I0702 00:34:49.141296 20914 net.cpp:106] Creating Layer BatchNorm16
I0702 00:34:49.141309 20914 net.cpp:454] BatchNorm16 <- Convolution16
I0702 00:34:49.140980 32261 net.cpp:150] Setting up Convolution17
I0702 00:34:49.141320 20914 net.cpp:397] BatchNorm16 -> Convolution16 (in-place)
I0702 00:34:49.141345 20914 net.cpp:150] Setting up BatchNorm16
I0702 00:34:49.141355 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.140995 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.141003 32261 net.cpp:165] Memory required for data: 124125312
I0702 00:34:49.141364 20914 net.cpp:165] Memory required for data: 122552448
I0702 00:34:49.141016 32261 layer_factory.hpp:77] Creating layer BatchNorm17
I0702 00:34:49.141388 20914 layer_factory.hpp:77] Creating layer Scale16
I0702 00:34:49.141402 20914 net.cpp:106] Creating Layer Scale16
I0702 00:34:49.141408 20914 net.cpp:454] Scale16 <- Convolution16
I0702 00:34:49.141031 32261 net.cpp:106] Creating Layer BatchNorm17
I0702 00:34:49.141417 20914 net.cpp:397] Scale16 -> Convolution16 (in-place)
I0702 00:34:49.141041 32261 net.cpp:454] BatchNorm17 <- Convolution17
I0702 00:34:49.141440 20914 layer_factory.hpp:77] Creating layer Scale16
I0702 00:34:49.141049 32261 net.cpp:397] BatchNorm17 -> Convolution17 (in-place)
I0702 00:34:49.141474 20914 net.cpp:150] Setting up Scale16
I0702 00:34:49.141073 32261 net.cpp:150] Setting up BatchNorm17
I0702 00:34:49.141484 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.141083 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.141494 20914 net.cpp:165] Memory required for data: 123076736
I0702 00:34:49.141090 32261 net.cpp:165] Memory required for data: 124649600
I0702 00:34:49.141505 20914 layer_factory.hpp:77] Creating layer ReLU14
I0702 00:34:49.141515 20914 net.cpp:106] Creating Layer ReLU14
I0702 00:34:49.141521 20914 net.cpp:454] ReLU14 <- Convolution16
I0702 00:34:49.141533 20914 net.cpp:397] ReLU14 -> Convolution16 (in-place)
I0702 00:34:49.141104 32261 layer_factory.hpp:77] Creating layer Scale17
I0702 00:34:49.141546 20914 net.cpp:150] Setting up ReLU14
I0702 00:34:49.141119 32261 net.cpp:106] Creating Layer Scale17
I0702 00:34:49.141553 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.141127 32261 net.cpp:454] Scale17 <- Convolution17
I0702 00:34:49.141561 20914 net.cpp:165] Memory required for data: 123601024
I0702 00:34:49.141139 32261 net.cpp:397] Scale17 -> Convolution17 (in-place)
I0702 00:34:49.141568 20914 layer_factory.hpp:77] Creating layer Convolution17
I0702 00:34:49.141157 32261 layer_factory.hpp:77] Creating layer Scale17
I0702 00:34:49.141590 20914 net.cpp:106] Creating Layer Convolution17
I0702 00:34:49.141185 32261 net.cpp:150] Setting up Scale17
I0702 00:34:49.141602 20914 net.cpp:454] Convolution17 <- Convolution16
I0702 00:34:49.141194 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.141615 20914 net.cpp:411] Convolution17 -> Convolution17
I0702 00:34:49.141203 32261 net.cpp:165] Memory required for data: 125173888
I0702 00:34:49.141214 32261 layer_factory.hpp:77] Creating layer Eltwise7
I0702 00:34:49.141227 32261 net.cpp:106] Creating Layer Eltwise7
I0702 00:34:49.141233 32261 net.cpp:454] Eltwise7 <- Convolution15
I0702 00:34:49.141242 32261 net.cpp:454] Eltwise7 <- Convolution17
I0702 00:34:49.141250 32261 net.cpp:411] Eltwise7 -> Eltwise7
I0702 00:34:49.141271 32261 net.cpp:150] Setting up Eltwise7
I0702 00:34:49.141280 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.141294 32261 net.cpp:165] Memory required for data: 125698176
I0702 00:34:49.141300 32261 layer_factory.hpp:77] Creating layer ReLU15
I0702 00:34:49.141309 32261 net.cpp:106] Creating Layer ReLU15
I0702 00:34:49.141316 32261 net.cpp:454] ReLU15 <- Eltwise7
I0702 00:34:49.141324 32261 net.cpp:397] ReLU15 -> Eltwise7 (in-place)
I0702 00:34:49.141335 32261 net.cpp:150] Setting up ReLU15
I0702 00:34:49.141340 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.141348 32261 net.cpp:165] Memory required for data: 126222464
I0702 00:34:49.141355 32261 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0702 00:34:49.141366 32261 net.cpp:106] Creating Layer Eltwise7_ReLU15_0_split
I0702 00:34:49.141373 32261 net.cpp:454] Eltwise7_ReLU15_0_split <- Eltwise7
I0702 00:34:49.141382 32261 net.cpp:411] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0702 00:34:49.141392 32261 net.cpp:411] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0702 00:34:49.141417 32261 net.cpp:150] Setting up Eltwise7_ReLU15_0_split
I0702 00:34:49.141427 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.141435 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.141443 32261 net.cpp:165] Memory required for data: 127271040
I0702 00:34:49.141450 32261 layer_factory.hpp:77] Creating layer Convolution18
I0702 00:34:49.141472 32261 net.cpp:106] Creating Layer Convolution18
I0702 00:34:49.141480 32261 net.cpp:454] Convolution18 <- Eltwise7_ReLU15_0_split_0
I0702 00:34:49.141494 32261 net.cpp:411] Convolution18 -> Convolution18
I0702 00:34:49.142218 13010 net.cpp:150] Setting up Convolution17
I0702 00:34:49.142235 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.142252 13010 net.cpp:165] Memory required for data: 124125312
I0702 00:34:49.142266 13010 layer_factory.hpp:77] Creating layer BatchNorm17
I0702 00:34:49.142280 13010 net.cpp:106] Creating Layer BatchNorm17
I0702 00:34:49.142288 13010 net.cpp:454] BatchNorm17 <- Convolution17
I0702 00:34:49.142297 13010 net.cpp:397] BatchNorm17 -> Convolution17 (in-place)
I0702 00:34:49.142325 13010 net.cpp:150] Setting up BatchNorm17
I0702 00:34:49.142336 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.142345 13010 net.cpp:165] Memory required for data: 124649600
I0702 00:34:49.142359 13010 layer_factory.hpp:77] Creating layer Scale17
I0702 00:34:49.142370 13010 net.cpp:106] Creating Layer Scale17
I0702 00:34:49.142379 13010 net.cpp:454] Scale17 <- Convolution17
I0702 00:34:49.142392 13010 net.cpp:397] Scale17 -> Convolution17 (in-place)
I0702 00:34:49.142422 13010 layer_factory.hpp:77] Creating layer Scale17
I0702 00:34:49.142457 13010 net.cpp:150] Setting up Scale17
I0702 00:34:49.142469 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.142479 13010 net.cpp:165] Memory required for data: 125173888
I0702 00:34:49.142490 13010 layer_factory.hpp:77] Creating layer Eltwise7
I0702 00:34:49.142503 13010 net.cpp:106] Creating Layer Eltwise7
I0702 00:34:49.142513 13010 net.cpp:454] Eltwise7 <- Convolution15
I0702 00:34:49.142520 13010 net.cpp:454] Eltwise7 <- Convolution17
I0702 00:34:49.142530 13010 net.cpp:411] Eltwise7 -> Eltwise7
I0702 00:34:49.142544 13010 net.cpp:150] Setting up Eltwise7
I0702 00:34:49.142552 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.142560 13010 net.cpp:165] Memory required for data: 125698176
I0702 00:34:49.142567 13010 layer_factory.hpp:77] Creating layer ReLU15
I0702 00:34:49.142576 13010 net.cpp:106] Creating Layer ReLU15
I0702 00:34:49.142582 13010 net.cpp:454] ReLU15 <- Eltwise7
I0702 00:34:49.142597 13010 net.cpp:397] ReLU15 -> Eltwise7 (in-place)
I0702 00:34:49.142612 13010 net.cpp:150] Setting up ReLU15
I0702 00:34:49.142619 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.142627 13010 net.cpp:165] Memory required for data: 126222464
I0702 00:34:49.142634 13010 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0702 00:34:49.142643 13010 net.cpp:106] Creating Layer Eltwise7_ReLU15_0_split
I0702 00:34:49.142650 13010 net.cpp:454] Eltwise7_ReLU15_0_split <- Eltwise7
I0702 00:34:49.142663 13010 net.cpp:411] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0702 00:34:49.142675 13010 net.cpp:411] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0702 00:34:49.142699 13010 net.cpp:150] Setting up Eltwise7_ReLU15_0_split
I0702 00:34:49.142709 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.142717 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.142725 13010 net.cpp:165] Memory required for data: 127271040
I0702 00:34:49.142731 13010 layer_factory.hpp:77] Creating layer Convolution18
I0702 00:34:49.142755 13010 net.cpp:106] Creating Layer Convolution18
I0702 00:34:49.142767 13010 net.cpp:454] Convolution18 <- Eltwise7_ReLU15_0_split_0
I0702 00:34:49.142779 13010 net.cpp:411] Convolution18 -> Convolution18
I0702 00:34:49.142454 20914 net.cpp:150] Setting up Convolution17
I0702 00:34:49.142470 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.142480 20914 net.cpp:165] Memory required for data: 124125312
I0702 00:34:49.142491 20914 layer_factory.hpp:77] Creating layer BatchNorm17
I0702 00:34:49.142508 20914 net.cpp:106] Creating Layer BatchNorm17
I0702 00:34:49.142519 20914 net.cpp:454] BatchNorm17 <- Convolution17
I0702 00:34:49.142529 20914 net.cpp:397] BatchNorm17 -> Convolution17 (in-place)
I0702 00:34:49.142560 20914 net.cpp:150] Setting up BatchNorm17
I0702 00:34:49.142570 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.142580 20914 net.cpp:165] Memory required for data: 124649600
I0702 00:34:49.142592 20914 layer_factory.hpp:77] Creating layer Scale17
I0702 00:34:49.142606 20914 net.cpp:106] Creating Layer Scale17
I0702 00:34:49.142613 20914 net.cpp:454] Scale17 <- Convolution17
I0702 00:34:49.142622 20914 net.cpp:397] Scale17 -> Convolution17 (in-place)
I0702 00:34:49.142639 20914 layer_factory.hpp:77] Creating layer Scale17
I0702 00:34:49.142668 20914 net.cpp:150] Setting up Scale17
I0702 00:34:49.142309 32261 net.cpp:150] Setting up Convolution18
I0702 00:34:49.142679 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.142695 20914 net.cpp:165] Memory required for data: 125173888
I0702 00:34:49.142709 20914 layer_factory.hpp:77] Creating layer Eltwise7
I0702 00:34:49.142324 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.142333 32261 net.cpp:165] Memory required for data: 127795328
I0702 00:34:49.142719 20914 net.cpp:106] Creating Layer Eltwise7
I0702 00:34:49.142345 32261 layer_factory.hpp:77] Creating layer BatchNorm18
I0702 00:34:49.142725 20914 net.cpp:454] Eltwise7 <- Convolution15
I0702 00:34:49.142359 32261 net.cpp:106] Creating Layer BatchNorm18
I0702 00:34:49.142733 20914 net.cpp:454] Eltwise7 <- Convolution17
I0702 00:34:49.142369 32261 net.cpp:454] BatchNorm18 <- Convolution18
I0702 00:34:49.142742 20914 net.cpp:411] Eltwise7 -> Eltwise7
I0702 00:34:49.142377 32261 net.cpp:397] BatchNorm18 -> Convolution18 (in-place)
I0702 00:34:49.142758 20914 net.cpp:150] Setting up Eltwise7
I0702 00:34:49.142765 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.142774 20914 net.cpp:165] Memory required for data: 125698176
I0702 00:34:49.142401 32261 net.cpp:150] Setting up BatchNorm18
I0702 00:34:49.142781 20914 layer_factory.hpp:77] Creating layer ReLU15
I0702 00:34:49.142410 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.142789 20914 net.cpp:106] Creating Layer ReLU15
I0702 00:34:49.142419 32261 net.cpp:165] Memory required for data: 128319616
I0702 00:34:49.142796 20914 net.cpp:454] ReLU15 <- Eltwise7
I0702 00:34:49.142432 32261 layer_factory.hpp:77] Creating layer Scale18
I0702 00:34:49.142803 20914 net.cpp:397] ReLU15 -> Eltwise7 (in-place)
I0702 00:34:49.142446 32261 net.cpp:106] Creating Layer Scale18
I0702 00:34:49.142813 20914 net.cpp:150] Setting up ReLU15
I0702 00:34:49.142454 32261 net.cpp:454] Scale18 <- Convolution18
I0702 00:34:49.142819 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.142463 32261 net.cpp:397] Scale18 -> Convolution18 (in-place)
I0702 00:34:49.142828 20914 net.cpp:165] Memory required for data: 126222464
I0702 00:34:49.142834 20914 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0702 00:34:49.142843 20914 net.cpp:106] Creating Layer Eltwise7_ReLU15_0_split
I0702 00:34:49.142849 20914 net.cpp:454] Eltwise7_ReLU15_0_split <- Eltwise7
I0702 00:34:49.142482 32261 layer_factory.hpp:77] Creating layer Scale18
I0702 00:34:49.142863 20914 net.cpp:411] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0702 00:34:49.142508 32261 net.cpp:150] Setting up Scale18
I0702 00:34:49.142877 20914 net.cpp:411] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0702 00:34:49.142518 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.142902 20914 net.cpp:150] Setting up Eltwise7_ReLU15_0_split
I0702 00:34:49.142525 32261 net.cpp:165] Memory required for data: 128843904
I0702 00:34:49.142912 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.142539 32261 layer_factory.hpp:77] Creating layer ReLU16
I0702 00:34:49.142921 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.142550 32261 net.cpp:106] Creating Layer ReLU16
I0702 00:34:49.142930 20914 net.cpp:165] Memory required for data: 127271040
I0702 00:34:49.142557 32261 net.cpp:454] ReLU16 <- Convolution18
I0702 00:34:49.142935 20914 layer_factory.hpp:77] Creating layer Convolution18
I0702 00:34:49.142565 32261 net.cpp:397] ReLU16 -> Convolution18 (in-place)
I0702 00:34:49.142959 20914 net.cpp:106] Creating Layer Convolution18
I0702 00:34:49.142971 20914 net.cpp:454] Convolution18 <- Eltwise7_ReLU15_0_split_0
I0702 00:34:49.142982 20914 net.cpp:411] Convolution18 -> Convolution18
I0702 00:34:49.142575 32261 net.cpp:150] Setting up ReLU16
I0702 00:34:49.142582 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.142590 32261 net.cpp:165] Memory required for data: 129368192
I0702 00:34:49.142597 32261 layer_factory.hpp:77] Creating layer Convolution19
I0702 00:34:49.142617 32261 net.cpp:106] Creating Layer Convolution19
I0702 00:34:49.142627 32261 net.cpp:454] Convolution19 <- Convolution18
I0702 00:34:49.142637 32261 net.cpp:411] Convolution19 -> Convolution19
I0702 00:34:49.143615 13010 net.cpp:150] Setting up Convolution18
I0702 00:34:49.143630 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.143646 13010 net.cpp:165] Memory required for data: 127795328
I0702 00:34:49.143659 13010 layer_factory.hpp:77] Creating layer BatchNorm18
I0702 00:34:49.143672 13010 net.cpp:106] Creating Layer BatchNorm18
I0702 00:34:49.143682 13010 net.cpp:454] BatchNorm18 <- Convolution18
I0702 00:34:49.143693 13010 net.cpp:397] BatchNorm18 -> Convolution18 (in-place)
I0702 00:34:49.143720 13010 net.cpp:150] Setting up BatchNorm18
I0702 00:34:49.143731 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.143739 13010 net.cpp:165] Memory required for data: 128319616
I0702 00:34:49.143754 13010 layer_factory.hpp:77] Creating layer Scale18
I0702 00:34:49.143765 13010 net.cpp:106] Creating Layer Scale18
I0702 00:34:49.143774 13010 net.cpp:454] Scale18 <- Convolution18
I0702 00:34:49.143786 13010 net.cpp:397] Scale18 -> Convolution18 (in-place)
I0702 00:34:49.143808 13010 layer_factory.hpp:77] Creating layer Scale18
I0702 00:34:49.143838 13010 net.cpp:150] Setting up Scale18
I0702 00:34:49.143849 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.143858 13010 net.cpp:165] Memory required for data: 128843904
I0702 00:34:49.143870 13010 layer_factory.hpp:77] Creating layer ReLU16
I0702 00:34:49.143879 13010 net.cpp:106] Creating Layer ReLU16
I0702 00:34:49.143887 13010 net.cpp:454] ReLU16 <- Convolution18
I0702 00:34:49.143898 13010 net.cpp:397] ReLU16 -> Convolution18 (in-place)
I0702 00:34:49.143909 13010 net.cpp:150] Setting up ReLU16
I0702 00:34:49.143918 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.143925 13010 net.cpp:165] Memory required for data: 129368192
I0702 00:34:49.143932 13010 layer_factory.hpp:77] Creating layer Convolution19
I0702 00:34:49.143956 13010 net.cpp:106] Creating Layer Convolution19
I0702 00:34:49.143966 13010 net.cpp:454] Convolution19 <- Convolution18
I0702 00:34:49.143978 13010 net.cpp:411] Convolution19 -> Convolution19
I0702 00:34:49.143455 32261 net.cpp:150] Setting up Convolution19
I0702 00:34:49.143468 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.143478 32261 net.cpp:165] Memory required for data: 129892480
I0702 00:34:49.143826 20914 net.cpp:150] Setting up Convolution18
I0702 00:34:49.143489 32261 layer_factory.hpp:77] Creating layer BatchNorm19
I0702 00:34:49.143842 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.143852 20914 net.cpp:165] Memory required for data: 127795328
I0702 00:34:49.143863 20914 layer_factory.hpp:77] Creating layer BatchNorm18
I0702 00:34:49.143880 20914 net.cpp:106] Creating Layer BatchNorm18
I0702 00:34:49.143503 32261 net.cpp:106] Creating Layer BatchNorm19
I0702 00:34:49.143889 20914 net.cpp:454] BatchNorm18 <- Convolution18
I0702 00:34:49.143512 32261 net.cpp:454] BatchNorm19 <- Convolution19
I0702 00:34:49.143899 20914 net.cpp:397] BatchNorm18 -> Convolution18 (in-place)
I0702 00:34:49.143522 32261 net.cpp:397] BatchNorm19 -> Convolution19 (in-place)
I0702 00:34:49.143925 20914 net.cpp:150] Setting up BatchNorm18
I0702 00:34:49.143936 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.143945 20914 net.cpp:165] Memory required for data: 128319616
I0702 00:34:49.143545 32261 net.cpp:150] Setting up BatchNorm19
I0702 00:34:49.143959 20914 layer_factory.hpp:77] Creating layer Scale18
I0702 00:34:49.143554 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.143563 32261 net.cpp:165] Memory required for data: 130416768
I0702 00:34:49.143972 20914 net.cpp:106] Creating Layer Scale18
I0702 00:34:49.143595 32261 layer_factory.hpp:77] Creating layer Scale19
I0702 00:34:49.143981 20914 net.cpp:454] Scale18 <- Convolution18
I0702 00:34:49.143611 32261 net.cpp:106] Creating Layer Scale19
I0702 00:34:49.143990 20914 net.cpp:397] Scale18 -> Convolution18 (in-place)
I0702 00:34:49.143621 32261 net.cpp:454] Scale19 <- Convolution19
I0702 00:34:49.144006 20914 layer_factory.hpp:77] Creating layer Scale18
I0702 00:34:49.143630 32261 net.cpp:397] Scale19 -> Convolution19 (in-place)
I0702 00:34:49.144037 20914 net.cpp:150] Setting up Scale18
I0702 00:34:49.144049 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.144065 20914 net.cpp:165] Memory required for data: 128843904
I0702 00:34:49.143648 32261 layer_factory.hpp:77] Creating layer Scale19
I0702 00:34:49.144078 20914 layer_factory.hpp:77] Creating layer ReLU16
I0702 00:34:49.143677 32261 net.cpp:150] Setting up Scale19
I0702 00:34:49.144088 20914 net.cpp:106] Creating Layer ReLU16
I0702 00:34:49.143687 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.144094 20914 net.cpp:454] ReLU16 <- Convolution18
I0702 00:34:49.143697 32261 net.cpp:165] Memory required for data: 130941056
I0702 00:34:49.144102 20914 net.cpp:397] ReLU16 -> Convolution18 (in-place)
I0702 00:34:49.143708 32261 layer_factory.hpp:77] Creating layer Eltwise8
I0702 00:34:49.144114 20914 net.cpp:150] Setting up ReLU16
I0702 00:34:49.143719 32261 net.cpp:106] Creating Layer Eltwise8
I0702 00:34:49.144119 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.143726 32261 net.cpp:454] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0702 00:34:49.144129 20914 net.cpp:165] Memory required for data: 129368192
I0702 00:34:49.144134 20914 layer_factory.hpp:77] Creating layer Convolution19
I0702 00:34:49.144160 20914 net.cpp:106] Creating Layer Convolution19
I0702 00:34:49.144170 20914 net.cpp:454] Convolution19 <- Convolution18
I0702 00:34:49.143743 32261 net.cpp:454] Eltwise8 <- Convolution19
I0702 00:34:49.144184 20914 net.cpp:411] Convolution19 -> Convolution19
I0702 00:34:49.143756 32261 net.cpp:411] Eltwise8 -> Eltwise8
I0702 00:34:49.143770 32261 net.cpp:150] Setting up Eltwise8
I0702 00:34:49.143779 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.143787 32261 net.cpp:165] Memory required for data: 131465344
I0702 00:34:49.143795 32261 layer_factory.hpp:77] Creating layer ReLU17
I0702 00:34:49.143802 32261 net.cpp:106] Creating Layer ReLU17
I0702 00:34:49.143808 32261 net.cpp:454] ReLU17 <- Eltwise8
I0702 00:34:49.143816 32261 net.cpp:397] ReLU17 -> Eltwise8 (in-place)
I0702 00:34:49.143826 32261 net.cpp:150] Setting up ReLU17
I0702 00:34:49.143832 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.143841 32261 net.cpp:165] Memory required for data: 131989632
I0702 00:34:49.143847 32261 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0702 00:34:49.143859 32261 net.cpp:106] Creating Layer Eltwise8_ReLU17_0_split
I0702 00:34:49.143867 32261 net.cpp:454] Eltwise8_ReLU17_0_split <- Eltwise8
I0702 00:34:49.143877 32261 net.cpp:411] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0702 00:34:49.143887 32261 net.cpp:411] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0702 00:34:49.143898 32261 net.cpp:150] Setting up Eltwise8_ReLU17_0_split
I0702 00:34:49.143906 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.143915 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.143923 32261 net.cpp:165] Memory required for data: 133038208
I0702 00:34:49.143929 32261 layer_factory.hpp:77] Creating layer Convolution20
I0702 00:34:49.143949 32261 net.cpp:106] Creating Layer Convolution20
I0702 00:34:49.143959 32261 net.cpp:454] Convolution20 <- Eltwise8_ReLU17_0_split_0
I0702 00:34:49.143968 32261 net.cpp:411] Convolution20 -> Convolution20
I0702 00:34:49.144819 13010 net.cpp:150] Setting up Convolution19
I0702 00:34:49.144834 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.144843 13010 net.cpp:165] Memory required for data: 129892480
I0702 00:34:49.144855 13010 layer_factory.hpp:77] Creating layer BatchNorm19
I0702 00:34:49.144875 13010 net.cpp:106] Creating Layer BatchNorm19
I0702 00:34:49.144884 13010 net.cpp:454] BatchNorm19 <- Convolution19
I0702 00:34:49.144896 13010 net.cpp:397] BatchNorm19 -> Convolution19 (in-place)
I0702 00:34:49.144923 13010 net.cpp:150] Setting up BatchNorm19
I0702 00:34:49.144933 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.144942 13010 net.cpp:165] Memory required for data: 130416768
I0702 00:34:49.144981 13010 layer_factory.hpp:77] Creating layer Scale19
I0702 00:34:49.144996 13010 net.cpp:106] Creating Layer Scale19
I0702 00:34:49.145004 13010 net.cpp:454] Scale19 <- Convolution19
I0702 00:34:49.145016 13010 net.cpp:397] Scale19 -> Convolution19 (in-place)
I0702 00:34:49.145035 13010 layer_factory.hpp:77] Creating layer Scale19
I0702 00:34:49.145063 13010 net.cpp:150] Setting up Scale19
I0702 00:34:49.145074 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.145084 13010 net.cpp:165] Memory required for data: 130941056
I0702 00:34:49.145095 13010 layer_factory.hpp:77] Creating layer Eltwise8
I0702 00:34:49.145105 13010 net.cpp:106] Creating Layer Eltwise8
I0702 00:34:49.145113 13010 net.cpp:454] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0702 00:34:49.145130 13010 net.cpp:454] Eltwise8 <- Convolution19
I0702 00:34:49.145145 13010 net.cpp:411] Eltwise8 -> Eltwise8
I0702 00:34:49.145164 13010 net.cpp:150] Setting up Eltwise8
I0702 00:34:49.145172 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.145181 13010 net.cpp:165] Memory required for data: 131465344
I0702 00:34:49.145187 13010 layer_factory.hpp:77] Creating layer ReLU17
I0702 00:34:49.145197 13010 net.cpp:106] Creating Layer ReLU17
I0702 00:34:49.145205 13010 net.cpp:454] ReLU17 <- Eltwise8
I0702 00:34:49.145213 13010 net.cpp:397] ReLU17 -> Eltwise8 (in-place)
I0702 00:34:49.145222 13010 net.cpp:150] Setting up ReLU17
I0702 00:34:49.145229 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.145237 13010 net.cpp:165] Memory required for data: 131989632
I0702 00:34:49.145243 13010 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0702 00:34:49.145252 13010 net.cpp:106] Creating Layer Eltwise8_ReLU17_0_split
I0702 00:34:49.145258 13010 net.cpp:454] Eltwise8_ReLU17_0_split <- Eltwise8
I0702 00:34:49.145267 13010 net.cpp:411] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0702 00:34:49.145277 13010 net.cpp:411] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0702 00:34:49.145289 13010 net.cpp:150] Setting up Eltwise8_ReLU17_0_split
I0702 00:34:49.145295 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.145313 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.145321 13010 net.cpp:165] Memory required for data: 133038208
I0702 00:34:49.145328 13010 layer_factory.hpp:77] Creating layer Convolution20
I0702 00:34:49.145349 13010 net.cpp:106] Creating Layer Convolution20
I0702 00:34:49.145360 13010 net.cpp:454] Convolution20 <- Eltwise8_ReLU17_0_split_0
I0702 00:34:49.145032 20914 net.cpp:150] Setting up Convolution19
I0702 00:34:49.145048 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.145058 20914 net.cpp:165] Memory required for data: 129892480
I0702 00:34:49.145071 20914 layer_factory.hpp:77] Creating layer BatchNorm19
I0702 00:34:49.145376 13010 net.cpp:411] Convolution20 -> Convolution20
I0702 00:34:49.145081 20914 net.cpp:106] Creating Layer BatchNorm19
I0702 00:34:49.145088 20914 net.cpp:454] BatchNorm19 <- Convolution19
I0702 00:34:49.145103 20914 net.cpp:397] BatchNorm19 -> Convolution19 (in-place)
I0702 00:34:49.145135 20914 net.cpp:150] Setting up BatchNorm19
I0702 00:34:49.144785 32261 net.cpp:150] Setting up Convolution20
I0702 00:34:49.145145 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.145154 20914 net.cpp:165] Memory required for data: 130416768
I0702 00:34:49.145192 20914 layer_factory.hpp:77] Creating layer Scale19
I0702 00:34:49.144800 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.144809 32261 net.cpp:165] Memory required for data: 133562496
I0702 00:34:49.144821 32261 layer_factory.hpp:77] Creating layer BatchNorm20
I0702 00:34:49.145210 20914 net.cpp:106] Creating Layer Scale19
I0702 00:34:49.144834 32261 net.cpp:106] Creating Layer BatchNorm20
I0702 00:34:49.145217 20914 net.cpp:454] Scale19 <- Convolution19
I0702 00:34:49.144843 32261 net.cpp:454] BatchNorm20 <- Convolution20
I0702 00:34:49.145231 20914 net.cpp:397] Scale19 -> Convolution19 (in-place)
I0702 00:34:49.144853 32261 net.cpp:397] BatchNorm20 -> Convolution20 (in-place)
I0702 00:34:49.145251 20914 layer_factory.hpp:77] Creating layer Scale19
I0702 00:34:49.145282 20914 net.cpp:150] Setting up Scale19
I0702 00:34:49.144878 32261 net.cpp:150] Setting up BatchNorm20
I0702 00:34:49.145294 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.145303 20914 net.cpp:165] Memory required for data: 130941056
I0702 00:34:49.144887 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.145315 20914 layer_factory.hpp:77] Creating layer Eltwise8
I0702 00:34:49.144896 32261 net.cpp:165] Memory required for data: 134086784
I0702 00:34:49.145325 20914 net.cpp:106] Creating Layer Eltwise8
I0702 00:34:49.144909 32261 layer_factory.hpp:77] Creating layer Scale20
I0702 00:34:49.145332 20914 net.cpp:454] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0702 00:34:49.144922 32261 net.cpp:106] Creating Layer Scale20
I0702 00:34:49.145349 20914 net.cpp:454] Eltwise8 <- Convolution19
I0702 00:34:49.144930 32261 net.cpp:454] Scale20 <- Convolution20
I0702 00:34:49.145365 20914 net.cpp:411] Eltwise8 -> Eltwise8
I0702 00:34:49.144939 32261 net.cpp:397] Scale20 -> Convolution20 (in-place)
I0702 00:34:49.145382 20914 net.cpp:150] Setting up Eltwise8
I0702 00:34:49.145391 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.145401 20914 net.cpp:165] Memory required for data: 131465344
I0702 00:34:49.144955 32261 layer_factory.hpp:77] Creating layer Scale20
I0702 00:34:49.145407 20914 layer_factory.hpp:77] Creating layer ReLU17
I0702 00:34:49.144982 32261 net.cpp:150] Setting up Scale20
I0702 00:34:49.145416 20914 net.cpp:106] Creating Layer ReLU17
I0702 00:34:49.144994 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.145422 20914 net.cpp:454] ReLU17 <- Eltwise8
I0702 00:34:49.145006 32261 net.cpp:165] Memory required for data: 134611072
I0702 00:34:49.145434 20914 net.cpp:397] ReLU17 -> Eltwise8 (in-place)
I0702 00:34:49.145017 32261 layer_factory.hpp:77] Creating layer ReLU18
I0702 00:34:49.145444 20914 net.cpp:150] Setting up ReLU17
I0702 00:34:49.145026 32261 net.cpp:106] Creating Layer ReLU18
I0702 00:34:49.145450 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.145033 32261 net.cpp:454] ReLU18 <- Convolution20
I0702 00:34:49.145458 20914 net.cpp:165] Memory required for data: 131989632
I0702 00:34:49.145041 32261 net.cpp:397] ReLU18 -> Convolution20 (in-place)
I0702 00:34:49.145465 20914 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0702 00:34:49.145051 32261 net.cpp:150] Setting up ReLU18
I0702 00:34:49.145473 20914 net.cpp:106] Creating Layer Eltwise8_ReLU17_0_split
I0702 00:34:49.145057 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.145480 20914 net.cpp:454] Eltwise8_ReLU17_0_split <- Eltwise8
I0702 00:34:49.145066 32261 net.cpp:165] Memory required for data: 135135360
I0702 00:34:49.145489 20914 net.cpp:411] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0702 00:34:49.145072 32261 layer_factory.hpp:77] Creating layer Convolution21
I0702 00:34:49.145500 20914 net.cpp:411] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0702 00:34:49.145511 20914 net.cpp:150] Setting up Eltwise8_ReLU17_0_split
I0702 00:34:49.145519 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.145535 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.145092 32261 net.cpp:106] Creating Layer Convolution21
I0702 00:34:49.145545 20914 net.cpp:165] Memory required for data: 133038208
I0702 00:34:49.145102 32261 net.cpp:454] Convolution21 <- Convolution20
I0702 00:34:49.145551 20914 layer_factory.hpp:77] Creating layer Convolution20
I0702 00:34:49.145115 32261 net.cpp:411] Convolution21 -> Convolution21
I0702 00:34:49.145570 20914 net.cpp:106] Creating Layer Convolution20
I0702 00:34:49.145582 20914 net.cpp:454] Convolution20 <- Eltwise8_ReLU17_0_split_0
I0702 00:34:49.145598 20914 net.cpp:411] Convolution20 -> Convolution20
I0702 00:34:49.146206 13010 net.cpp:150] Setting up Convolution20
I0702 00:34:49.146222 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.146231 13010 net.cpp:165] Memory required for data: 133562496
I0702 00:34:49.146246 13010 layer_factory.hpp:77] Creating layer BatchNorm20
I0702 00:34:49.146260 13010 net.cpp:106] Creating Layer BatchNorm20
I0702 00:34:49.146267 13010 net.cpp:454] BatchNorm20 <- Convolution20
I0702 00:34:49.146281 13010 net.cpp:397] BatchNorm20 -> Convolution20 (in-place)
I0702 00:34:49.146307 13010 net.cpp:150] Setting up BatchNorm20
I0702 00:34:49.146317 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.146332 13010 net.cpp:165] Memory required for data: 134086784
I0702 00:34:49.146347 13010 layer_factory.hpp:77] Creating layer Scale20
I0702 00:34:49.146358 13010 net.cpp:106] Creating Layer Scale20
I0702 00:34:49.146365 13010 net.cpp:454] Scale20 <- Convolution20
I0702 00:34:49.146378 13010 net.cpp:397] Scale20 -> Convolution20 (in-place)
I0702 00:34:49.146397 13010 layer_factory.hpp:77] Creating layer Scale20
I0702 00:34:49.146436 13010 net.cpp:150] Setting up Scale20
I0702 00:34:49.146448 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.146457 13010 net.cpp:165] Memory required for data: 134611072
I0702 00:34:49.146469 13010 layer_factory.hpp:77] Creating layer ReLU18
I0702 00:34:49.146479 13010 net.cpp:106] Creating Layer ReLU18
I0702 00:34:49.146486 13010 net.cpp:454] ReLU18 <- Convolution20
I0702 00:34:49.146499 13010 net.cpp:397] ReLU18 -> Convolution20 (in-place)
I0702 00:34:49.146514 13010 net.cpp:150] Setting up ReLU18
I0702 00:34:49.146522 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.146530 13010 net.cpp:165] Memory required for data: 135135360
I0702 00:34:49.146538 13010 layer_factory.hpp:77] Creating layer Convolution21
I0702 00:34:49.146562 13010 net.cpp:106] Creating Layer Convolution21
I0702 00:34:49.146574 13010 net.cpp:454] Convolution21 <- Convolution20
I0702 00:34:49.146592 13010 net.cpp:411] Convolution21 -> Convolution21
I0702 00:34:49.145932 32261 net.cpp:150] Setting up Convolution21
I0702 00:34:49.145947 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.145963 32261 net.cpp:165] Memory required for data: 135659648
I0702 00:34:49.145977 32261 layer_factory.hpp:77] Creating layer BatchNorm21
I0702 00:34:49.145988 32261 net.cpp:106] Creating Layer BatchNorm21
I0702 00:34:49.145995 32261 net.cpp:454] BatchNorm21 <- Convolution21
I0702 00:34:49.146008 32261 net.cpp:397] BatchNorm21 -> Convolution21 (in-place)
I0702 00:34:49.146031 32261 net.cpp:150] Setting up BatchNorm21
I0702 00:34:49.146040 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.146049 32261 net.cpp:165] Memory required for data: 136183936
I0702 00:34:49.146062 32261 layer_factory.hpp:77] Creating layer Scale21
I0702 00:34:49.146436 20914 net.cpp:150] Setting up Convolution20
I0702 00:34:49.146075 32261 net.cpp:106] Creating Layer Scale21
I0702 00:34:49.146082 32261 net.cpp:454] Scale21 <- Convolution21
I0702 00:34:49.146452 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.146462 20914 net.cpp:165] Memory required for data: 133562496
I0702 00:34:49.146091 32261 net.cpp:397] Scale21 -> Convolution21 (in-place)
I0702 00:34:49.146474 20914 layer_factory.hpp:77] Creating layer BatchNorm20
I0702 00:34:49.146487 20914 net.cpp:106] Creating Layer BatchNorm20
I0702 00:34:49.146495 20914 net.cpp:454] BatchNorm20 <- Convolution20
I0702 00:34:49.146504 20914 net.cpp:397] BatchNorm20 -> Convolution20 (in-place)
I0702 00:34:49.146107 32261 layer_factory.hpp:77] Creating layer Scale21
I0702 00:34:49.146531 20914 net.cpp:150] Setting up BatchNorm20
I0702 00:34:49.146137 32261 net.cpp:150] Setting up Scale21
I0702 00:34:49.146541 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.146147 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.146560 20914 net.cpp:165] Memory required for data: 134086784
I0702 00:34:49.146157 32261 net.cpp:165] Memory required for data: 136708224
I0702 00:34:49.146574 20914 layer_factory.hpp:77] Creating layer Scale20
I0702 00:34:49.146167 32261 layer_factory.hpp:77] Creating layer Eltwise9
I0702 00:34:49.146585 20914 net.cpp:106] Creating Layer Scale20
I0702 00:34:49.146594 20914 net.cpp:454] Scale20 <- Convolution20
I0702 00:34:49.146605 20914 net.cpp:397] Scale20 -> Convolution20 (in-place)
I0702 00:34:49.146621 20914 layer_factory.hpp:77] Creating layer Scale20
I0702 00:34:49.146181 32261 net.cpp:106] Creating Layer Eltwise9
I0702 00:34:49.146651 20914 net.cpp:150] Setting up Scale20
I0702 00:34:49.146190 32261 net.cpp:454] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0702 00:34:49.146661 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.146198 32261 net.cpp:454] Eltwise9 <- Convolution21
I0702 00:34:49.146672 20914 net.cpp:165] Memory required for data: 134611072
I0702 00:34:49.146208 32261 net.cpp:411] Eltwise9 -> Eltwise9
I0702 00:34:49.146682 20914 layer_factory.hpp:77] Creating layer ReLU18
I0702 00:34:49.146220 32261 net.cpp:150] Setting up Eltwise9
I0702 00:34:49.146692 20914 net.cpp:106] Creating Layer ReLU18
I0702 00:34:49.146229 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.146698 20914 net.cpp:454] ReLU18 <- Convolution20
I0702 00:34:49.146237 32261 net.cpp:165] Memory required for data: 137232512
I0702 00:34:49.146708 20914 net.cpp:397] ReLU18 -> Convolution20 (in-place)
I0702 00:34:49.146244 32261 layer_factory.hpp:77] Creating layer ReLU19
I0702 00:34:49.146718 20914 net.cpp:150] Setting up ReLU18
I0702 00:34:49.146255 32261 net.cpp:106] Creating Layer ReLU19
I0702 00:34:49.146723 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.146270 32261 net.cpp:454] ReLU19 <- Eltwise9
I0702 00:34:49.146279 32261 net.cpp:397] ReLU19 -> Eltwise9 (in-place)
I0702 00:34:49.146733 20914 net.cpp:165] Memory required for data: 135135360
I0702 00:34:49.146289 32261 net.cpp:150] Setting up ReLU19
I0702 00:34:49.146739 20914 layer_factory.hpp:77] Creating layer Convolution21
I0702 00:34:49.146766 20914 net.cpp:106] Creating Layer Convolution21
I0702 00:34:49.146777 20914 net.cpp:454] Convolution21 <- Convolution20
I0702 00:34:49.146296 32261 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.146795 20914 net.cpp:411] Convolution21 -> Convolution21
I0702 00:34:49.146304 32261 net.cpp:165] Memory required for data: 137756800
I0702 00:34:49.146311 32261 layer_factory.hpp:77] Creating layer Pooling1
I0702 00:34:49.146320 32261 net.cpp:106] Creating Layer Pooling1
I0702 00:34:49.146327 32261 net.cpp:454] Pooling1 <- Eltwise9
I0702 00:34:49.146338 32261 net.cpp:411] Pooling1 -> Pooling1
I0702 00:34:49.146447 32261 net.cpp:150] Setting up Pooling1
I0702 00:34:49.146462 32261 net.cpp:157] Top shape: 32 64 1 1 (2048)
I0702 00:34:49.146472 32261 net.cpp:165] Memory required for data: 137764992
I0702 00:34:49.146481 32261 layer_factory.hpp:77] Creating layer InnerProduct1
I0702 00:34:49.146528 32261 net.cpp:106] Creating Layer InnerProduct1
I0702 00:34:49.146541 32261 net.cpp:454] InnerProduct1 <- Pooling1
I0702 00:34:49.146558 32261 net.cpp:411] InnerProduct1 -> InnerProduct1
I0702 00:34:49.146710 32261 net.cpp:150] Setting up InnerProduct1
I0702 00:34:49.147424 13010 net.cpp:150] Setting up Convolution21
I0702 00:34:49.146725 32261 net.cpp:157] Top shape: 32 10 (320)
I0702 00:34:49.146735 32261 net.cpp:165] Memory required for data: 137766272
I0702 00:34:49.146747 32261 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0702 00:34:49.147439 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.147455 13010 net.cpp:165] Memory required for data: 135659648
I0702 00:34:49.147469 13010 layer_factory.hpp:77] Creating layer BatchNorm21
I0702 00:34:49.146793 32261 net.cpp:106] Creating Layer SoftmaxWithLoss1
I0702 00:34:49.147482 13010 net.cpp:106] Creating Layer BatchNorm21
I0702 00:34:49.147491 13010 net.cpp:454] BatchNorm21 <- Convolution21
I0702 00:34:49.146807 32261 net.cpp:454] SoftmaxWithLoss1 <- InnerProduct1
I0702 00:34:49.147501 13010 net.cpp:397] BatchNorm21 -> Convolution21 (in-place)
I0702 00:34:49.146816 32261 net.cpp:454] SoftmaxWithLoss1 <- Data2
I0702 00:34:49.146831 32261 net.cpp:411] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0702 00:34:49.147528 13010 net.cpp:150] Setting up BatchNorm21
I0702 00:34:49.147538 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.146883 32261 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0702 00:34:49.147553 13010 net.cpp:165] Memory required for data: 136183936
I0702 00:34:49.147567 13010 layer_factory.hpp:77] Creating layer Scale21
I0702 00:34:49.147579 13010 net.cpp:106] Creating Layer Scale21
I0702 00:34:49.147588 13010 net.cpp:454] Scale21 <- Convolution21
I0702 00:34:49.147598 13010 net.cpp:397] Scale21 -> Convolution21 (in-place)
I0702 00:34:49.147616 13010 layer_factory.hpp:77] Creating layer Scale21
I0702 00:34:49.147647 13010 net.cpp:150] Setting up Scale21
I0702 00:34:49.147660 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.147668 13010 net.cpp:165] Memory required for data: 136708224
I0702 00:34:49.147680 13010 layer_factory.hpp:77] Creating layer Eltwise9
I0702 00:34:49.147012 32261 net.cpp:150] Setting up SoftmaxWithLoss1
I0702 00:34:49.147691 13010 net.cpp:106] Creating Layer Eltwise9
I0702 00:34:49.147027 32261 net.cpp:157] Top shape: (1)
I0702 00:34:49.147699 13010 net.cpp:454] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0702 00:34:49.147707 13010 net.cpp:454] Eltwise9 <- Convolution21
I0702 00:34:49.147722 13010 net.cpp:411] Eltwise9 -> Eltwise9
I0702 00:34:49.147738 13010 net.cpp:150] Setting up Eltwise9
I0702 00:34:49.147040 32261 net.cpp:160]     with loss weight 1
I0702 00:34:49.147074 32261 net.cpp:165] Memory required for data: 137766276
I0702 00:34:49.147084 32261 net.cpp:226] SoftmaxWithLoss1 needs backward computation.
I0702 00:34:49.147747 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.147755 13010 net.cpp:165] Memory required for data: 137232512
I0702 00:34:49.147763 13010 layer_factory.hpp:77] Creating layer ReLU19
I0702 00:34:49.147094 32261 net.cpp:226] InnerProduct1 needs backward computation.
I0702 00:34:49.147771 13010 net.cpp:106] Creating Layer ReLU19
I0702 00:34:49.147101 32261 net.cpp:226] Pooling1 needs backward computation.
I0702 00:34:49.147778 13010 net.cpp:454] ReLU19 <- Eltwise9
I0702 00:34:49.147119 32261 net.cpp:226] ReLU19 needs backward computation.
I0702 00:34:49.147789 13010 net.cpp:397] ReLU19 -> Eltwise9 (in-place)
I0702 00:34:49.147125 32261 net.cpp:226] Eltwise9 needs backward computation.
I0702 00:34:49.147799 13010 net.cpp:150] Setting up ReLU19
I0702 00:34:49.147133 32261 net.cpp:226] Scale21 needs backward computation.
I0702 00:34:49.147805 13010 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.147140 32261 net.cpp:226] BatchNorm21 needs backward computation.
I0702 00:34:49.147814 13010 net.cpp:165] Memory required for data: 137756800
I0702 00:34:49.147145 32261 net.cpp:226] Convolution21 needs backward computation.
I0702 00:34:49.147821 13010 layer_factory.hpp:77] Creating layer Pooling1
I0702 00:34:49.147152 32261 net.cpp:226] ReLU18 needs backward computation.
I0702 00:34:49.147158 32261 net.cpp:226] Scale20 needs backward computation.
I0702 00:34:49.147831 13010 net.cpp:106] Creating Layer Pooling1
I0702 00:34:49.147164 32261 net.cpp:226] BatchNorm20 needs backward computation.
I0702 00:34:49.147837 13010 net.cpp:454] Pooling1 <- Eltwise9
I0702 00:34:49.147171 32261 net.cpp:226] Convolution20 needs backward computation.
I0702 00:34:49.147846 13010 net.cpp:411] Pooling1 -> Pooling1
I0702 00:34:49.147176 32261 net.cpp:226] Eltwise8_ReLU17_0_split needs backward computation.
I0702 00:34:49.147183 32261 net.cpp:226] ReLU17 needs backward computation.
I0702 00:34:49.147191 32261 net.cpp:226] Eltwise8 needs backward computation.
I0702 00:34:49.147197 32261 net.cpp:226] Scale19 needs backward computation.
I0702 00:34:49.147203 32261 net.cpp:226] BatchNorm19 needs backward computation.
I0702 00:34:49.147209 32261 net.cpp:226] Convolution19 needs backward computation.
I0702 00:34:49.147964 13010 net.cpp:150] Setting up Pooling1
I0702 00:34:49.147215 32261 net.cpp:226] ReLU16 needs backward computation.
I0702 00:34:49.147979 13010 net.cpp:157] Top shape: 32 64 1 1 (2048)
I0702 00:34:49.147987 13010 net.cpp:165] Memory required for data: 137764992
I0702 00:34:49.147646 20914 net.cpp:150] Setting up Convolution21
I0702 00:34:49.147222 32261 net.cpp:226] Scale18 needs backward computation.
I0702 00:34:49.147228 32261 net.cpp:226] BatchNorm18 needs backward computation.
I0702 00:34:49.147995 13010 layer_factory.hpp:77] Creating layer InnerProduct1
I0702 00:34:49.147663 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.147233 32261 net.cpp:226] Convolution18 needs backward computation.
I0702 00:34:49.147680 20914 net.cpp:165] Memory required for data: 135659648
I0702 00:34:49.147240 32261 net.cpp:226] Eltwise7_ReLU15_0_split needs backward computation.
I0702 00:34:49.148048 13010 net.cpp:106] Creating Layer InnerProduct1
I0702 00:34:49.147693 20914 layer_factory.hpp:77] Creating layer BatchNorm21
I0702 00:34:49.147246 32261 net.cpp:226] ReLU15 needs backward computation.
I0702 00:34:49.147707 20914 net.cpp:106] Creating Layer BatchNorm21
I0702 00:34:49.147253 32261 net.cpp:226] Eltwise7 needs backward computation.
I0702 00:34:49.147714 20914 net.cpp:454] BatchNorm21 <- Convolution21
I0702 00:34:49.147267 32261 net.cpp:226] Scale17 needs backward computation.
I0702 00:34:49.148064 13010 net.cpp:454] InnerProduct1 <- Pooling1
I0702 00:34:49.147723 20914 net.cpp:397] BatchNorm21 -> Convolution21 (in-place)
I0702 00:34:49.147274 32261 net.cpp:226] BatchNorm17 needs backward computation.
I0702 00:34:49.147280 32261 net.cpp:226] Convolution17 needs backward computation.
I0702 00:34:49.148078 13010 net.cpp:411] InnerProduct1 -> InnerProduct1
I0702 00:34:49.147753 20914 net.cpp:150] Setting up BatchNorm21
I0702 00:34:49.147287 32261 net.cpp:226] ReLU14 needs backward computation.
I0702 00:34:49.147763 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.147294 32261 net.cpp:226] Scale16 needs backward computation.
I0702 00:34:49.147773 20914 net.cpp:165] Memory required for data: 136183936
I0702 00:34:49.147300 32261 net.cpp:226] BatchNorm16 needs backward computation.
I0702 00:34:49.147785 20914 layer_factory.hpp:77] Creating layer Scale21
I0702 00:34:49.147801 20914 net.cpp:106] Creating Layer Scale21
I0702 00:34:49.147812 20914 net.cpp:454] Scale21 <- Convolution21
I0702 00:34:49.147305 32261 net.cpp:226] Convolution16 needs backward computation.
I0702 00:34:49.147821 20914 net.cpp:397] Scale21 -> Convolution21 (in-place)
I0702 00:34:49.147312 32261 net.cpp:226] Scale15 needs backward computation.
I0702 00:34:49.147841 20914 layer_factory.hpp:77] Creating layer Scale21
I0702 00:34:49.147318 32261 net.cpp:226] BatchNorm15 needs backward computation.
I0702 00:34:49.147325 32261 net.cpp:226] Convolution15 needs backward computation.
I0702 00:34:49.147869 20914 net.cpp:150] Setting up Scale21
I0702 00:34:49.147331 32261 net.cpp:226] Eltwise6_ReLU13_0_split needs backward computation.
I0702 00:34:49.147338 32261 net.cpp:226] ReLU13 needs backward computation.
I0702 00:34:49.148242 13010 net.cpp:150] Setting up InnerProduct1
I0702 00:34:49.147883 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.147344 32261 net.cpp:226] Eltwise6 needs backward computation.
I0702 00:34:49.147892 20914 net.cpp:165] Memory required for data: 136708224
I0702 00:34:49.147351 32261 net.cpp:226] Scale14 needs backward computation.
I0702 00:34:49.148258 13010 net.cpp:157] Top shape: 32 10 (320)
I0702 00:34:49.148267 13010 net.cpp:165] Memory required for data: 137766272
I0702 00:34:49.147903 20914 layer_factory.hpp:77] Creating layer Eltwise9
I0702 00:34:49.147357 32261 net.cpp:226] BatchNorm14 needs backward computation.
I0702 00:34:49.148283 13010 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0702 00:34:49.147914 20914 net.cpp:106] Creating Layer Eltwise9
I0702 00:34:49.147362 32261 net.cpp:226] Convolution14 needs backward computation.
I0702 00:34:49.147922 20914 net.cpp:454] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0702 00:34:49.147369 32261 net.cpp:226] ReLU12 needs backward computation.
I0702 00:34:49.147375 32261 net.cpp:226] Scale13 needs backward computation.
I0702 00:34:49.147929 20914 net.cpp:454] Eltwise9 <- Convolution21
I0702 00:34:49.147380 32261 net.cpp:226] BatchNorm13 needs backward computation.
I0702 00:34:49.148332 13010 net.cpp:106] Creating Layer SoftmaxWithLoss1
I0702 00:34:49.147938 20914 net.cpp:411] Eltwise9 -> Eltwise9
I0702 00:34:49.147387 32261 net.cpp:226] Convolution13 needs backward computation.
I0702 00:34:49.147951 20914 net.cpp:150] Setting up Eltwise9
I0702 00:34:49.147393 32261 net.cpp:226] Eltwise5_ReLU11_0_split needs backward computation.
I0702 00:34:49.147958 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.147399 32261 net.cpp:226] ReLU11 needs backward computation.
I0702 00:34:49.148346 13010 net.cpp:454] SoftmaxWithLoss1 <- InnerProduct1
I0702 00:34:49.147975 20914 net.cpp:165] Memory required for data: 137232512
I0702 00:34:49.147405 32261 net.cpp:226] Eltwise5 needs backward computation.
I0702 00:34:49.148355 13010 net.cpp:454] SoftmaxWithLoss1 <- Data2
I0702 00:34:49.147984 20914 layer_factory.hpp:77] Creating layer ReLU19
I0702 00:34:49.147413 32261 net.cpp:226] Scale12 needs backward computation.
I0702 00:34:49.147418 32261 net.cpp:226] BatchNorm12 needs backward computation.
I0702 00:34:49.148366 13010 net.cpp:411] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0702 00:34:49.147992 20914 net.cpp:106] Creating Layer ReLU19
I0702 00:34:49.148000 20914 net.cpp:454] ReLU19 <- Eltwise9
I0702 00:34:49.147424 32261 net.cpp:226] Convolution12 needs backward computation.
I0702 00:34:49.148008 20914 net.cpp:397] ReLU19 -> Eltwise9 (in-place)
I0702 00:34:49.147430 32261 net.cpp:226] ReLU10 needs backward computation.
I0702 00:34:49.148018 20914 net.cpp:150] Setting up ReLU19
I0702 00:34:49.147436 32261 net.cpp:226] Scale11 needs backward computation.
I0702 00:34:49.148427 13010 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0702 00:34:49.148025 20914 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.147442 32261 net.cpp:226] BatchNorm11 needs backward computation.
I0702 00:34:49.148033 20914 net.cpp:165] Memory required for data: 137756800
I0702 00:34:49.147455 32261 net.cpp:226] Convolution11 needs backward computation.
I0702 00:34:49.148041 20914 layer_factory.hpp:77] Creating layer Pooling1
I0702 00:34:49.147462 32261 net.cpp:226] Eltwise4_ReLU9_0_split needs backward computation.
I0702 00:34:49.148052 20914 net.cpp:106] Creating Layer Pooling1
I0702 00:34:49.147469 32261 net.cpp:226] ReLU9 needs backward computation.
I0702 00:34:49.148059 20914 net.cpp:454] Pooling1 <- Eltwise9
I0702 00:34:49.147476 32261 net.cpp:226] Eltwise4 needs backward computation.
I0702 00:34:49.148068 20914 net.cpp:411] Pooling1 -> Pooling1
I0702 00:34:49.147483 32261 net.cpp:226] Scale10 needs backward computation.
I0702 00:34:49.147490 32261 net.cpp:226] BatchNorm10 needs backward computation.
I0702 00:34:49.147495 32261 net.cpp:226] Convolution10 needs backward computation.
I0702 00:34:49.147501 32261 net.cpp:226] ReLU8 needs backward computation.
I0702 00:34:49.147508 32261 net.cpp:226] Scale9 needs backward computation.
I0702 00:34:49.147514 32261 net.cpp:226] BatchNorm9 needs backward computation.
I0702 00:34:49.148200 20914 net.cpp:150] Setting up Pooling1
I0702 00:34:49.147521 32261 net.cpp:226] Convolution9 needs backward computation.
I0702 00:34:49.148216 20914 net.cpp:157] Top shape: 32 64 1 1 (2048)
I0702 00:34:49.147527 32261 net.cpp:226] Scale8 needs backward computation.
I0702 00:34:49.147533 32261 net.cpp:226] BatchNorm8 needs backward computation.
I0702 00:34:49.148568 13010 net.cpp:150] Setting up SoftmaxWithLoss1
I0702 00:34:49.148231 20914 net.cpp:165] Memory required for data: 137764992
I0702 00:34:49.147539 32261 net.cpp:226] Convolution8 needs backward computation.
I0702 00:34:49.148238 20914 layer_factory.hpp:77] Creating layer InnerProduct1
I0702 00:34:49.147547 32261 net.cpp:226] Eltwise3_ReLU7_0_split needs backward computation.
I0702 00:34:49.148584 13010 net.cpp:157] Top shape: (1)
I0702 00:34:49.147552 32261 net.cpp:226] ReLU7 needs backward computation.
I0702 00:34:49.148593 13010 net.cpp:160]     with loss weight 1
I0702 00:34:49.147558 32261 net.cpp:226] Eltwise3 needs backward computation.
I0702 00:34:49.148627 13010 net.cpp:165] Memory required for data: 137766276
I0702 00:34:49.148298 20914 net.cpp:106] Creating Layer InnerProduct1
I0702 00:34:49.147565 32261 net.cpp:226] Scale7 needs backward computation.
I0702 00:34:49.148315 20914 net.cpp:454] InnerProduct1 <- Pooling1
I0702 00:34:49.147572 32261 net.cpp:226] BatchNorm7 needs backward computation.
I0702 00:34:49.148638 13010 net.cpp:226] SoftmaxWithLoss1 needs backward computation.
I0702 00:34:49.148326 20914 net.cpp:411] InnerProduct1 -> InnerProduct1
I0702 00:34:49.147578 32261 net.cpp:226] Convolution7 needs backward computation.
I0702 00:34:49.147584 32261 net.cpp:226] ReLU6 needs backward computation.
I0702 00:34:49.148648 13010 net.cpp:226] InnerProduct1 needs backward computation.
I0702 00:34:49.147590 32261 net.cpp:226] Scale6 needs backward computation.
I0702 00:34:49.148655 13010 net.cpp:226] Pooling1 needs backward computation.
I0702 00:34:49.147596 32261 net.cpp:226] BatchNorm6 needs backward computation.
I0702 00:34:49.148670 13010 net.cpp:226] ReLU19 needs backward computation.
I0702 00:34:49.147603 32261 net.cpp:226] Convolution6 needs backward computation.
I0702 00:34:49.148679 13010 net.cpp:226] Eltwise9 needs backward computation.
I0702 00:34:49.147608 32261 net.cpp:226] Eltwise2_ReLU5_0_split needs backward computation.
I0702 00:34:49.147615 32261 net.cpp:226] ReLU5 needs backward computation.
I0702 00:34:49.147621 32261 net.cpp:226] Eltwise2 needs backward computation.
I0702 00:34:49.147629 32261 net.cpp:226] Scale5 needs backward computation.
I0702 00:34:49.147635 32261 net.cpp:226] BatchNorm5 needs backward computation.
I0702 00:34:49.148685 13010 net.cpp:226] Scale21 needs backward computation.
I0702 00:34:49.147641 32261 net.cpp:226] Convolution5 needs backward computation.
I0702 00:34:49.148692 13010 net.cpp:226] BatchNorm21 needs backward computation.
I0702 00:34:49.147647 32261 net.cpp:226] ReLU4 needs backward computation.
I0702 00:34:49.148699 13010 net.cpp:226] Convolution21 needs backward computation.
I0702 00:34:49.148705 13010 net.cpp:226] ReLU18 needs backward computation.
I0702 00:34:49.147653 32261 net.cpp:226] Scale4 needs backward computation.
I0702 00:34:49.148710 13010 net.cpp:226] Scale20 needs backward computation.
I0702 00:34:49.148716 13010 net.cpp:226] BatchNorm20 needs backward computation.
I0702 00:34:49.147660 32261 net.cpp:226] BatchNorm4 needs backward computation.
I0702 00:34:49.148722 13010 net.cpp:226] Convolution20 needs backward computation.
I0702 00:34:49.147665 32261 net.cpp:226] Convolution4 needs backward computation.
I0702 00:34:49.148730 13010 net.cpp:226] Eltwise8_ReLU17_0_split needs backward computation.
I0702 00:34:49.147671 32261 net.cpp:226] Eltwise1_ReLU3_0_split needs backward computation.
I0702 00:34:49.147678 32261 net.cpp:226] ReLU3 needs backward computation.
I0702 00:34:49.148736 13010 net.cpp:226] ReLU17 needs backward computation.
I0702 00:34:49.147684 32261 net.cpp:226] Eltwise1 needs backward computation.
I0702 00:34:49.148741 13010 net.cpp:226] Eltwise8 needs backward computation.
I0702 00:34:49.147692 32261 net.cpp:226] Scale3 needs backward computation.
I0702 00:34:49.148748 13010 net.cpp:226] Scale19 needs backward computation.
I0702 00:34:49.147698 32261 net.cpp:226] BatchNorm3 needs backward computation.
I0702 00:34:49.148754 13010 net.cpp:226] BatchNorm19 needs backward computation.
I0702 00:34:49.148761 13010 net.cpp:226] Convolution19 needs backward computation.
I0702 00:34:49.147704 32261 net.cpp:226] Convolution3 needs backward computation.
I0702 00:34:49.148767 13010 net.cpp:226] ReLU16 needs backward computation.
I0702 00:34:49.147711 32261 net.cpp:226] ReLU2 needs backward computation.
I0702 00:34:49.147716 32261 net.cpp:226] Scale2 needs backward computation.
I0702 00:34:49.147722 32261 net.cpp:226] BatchNorm2 needs backward computation.
I0702 00:34:49.147728 32261 net.cpp:226] Convolution2 needs backward computation.
I0702 00:34:49.147735 32261 net.cpp:226] Convolution1_ReLU1_0_split needs backward computation.
I0702 00:34:49.148773 13010 net.cpp:226] Scale18 needs backward computation.
I0702 00:34:49.148517 20914 net.cpp:150] Setting up InnerProduct1
I0702 00:34:49.147742 32261 net.cpp:226] ReLU1 needs backward computation.
I0702 00:34:49.148779 13010 net.cpp:226] BatchNorm18 needs backward computation.
I0702 00:34:49.147748 32261 net.cpp:226] Scale1 needs backward computation.
I0702 00:34:49.148785 13010 net.cpp:226] Convolution18 needs backward computation.
I0702 00:34:49.148792 13010 net.cpp:226] Eltwise7_ReLU15_0_split needs backward computation.
I0702 00:34:49.148533 20914 net.cpp:157] Top shape: 32 10 (320)
I0702 00:34:49.148543 20914 net.cpp:165] Memory required for data: 137766272
I0702 00:34:49.147754 32261 net.cpp:226] BatchNorm1 needs backward computation.
I0702 00:34:49.148798 13010 net.cpp:226] ReLU15 needs backward computation.
I0702 00:34:49.148555 20914 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0702 00:34:49.147760 32261 net.cpp:226] Convolution1 needs backward computation.
I0702 00:34:49.148804 13010 net.cpp:226] Eltwise7 needs backward computation.
I0702 00:34:49.147768 32261 net.cpp:228] Data1 does not need backward computation.
I0702 00:34:49.148813 13010 net.cpp:226] Scale17 needs backward computation.
I0702 00:34:49.147773 32261 net.cpp:270] This network produces output SoftmaxWithLoss1
I0702 00:34:49.148818 13010 net.cpp:226] BatchNorm17 needs backward computation.
I0702 00:34:49.147855 32261 net.cpp:283] Network initialization done.
I0702 00:34:49.148824 13010 net.cpp:226] Convolution17 needs backward computation.
I0702 00:34:49.148830 13010 net.cpp:226] ReLU14 needs backward computation.
I0702 00:34:49.148836 13010 net.cpp:226] Scale16 needs backward computation.
I0702 00:34:49.148842 13010 net.cpp:226] BatchNorm16 needs backward computation.
I0702 00:34:49.148849 13010 net.cpp:226] Convolution16 needs backward computation.
I0702 00:34:49.148612 20914 net.cpp:106] Creating Layer SoftmaxWithLoss1
I0702 00:34:49.148855 13010 net.cpp:226] Scale15 needs backward computation.
I0702 00:34:49.148627 20914 net.cpp:454] SoftmaxWithLoss1 <- InnerProduct1
I0702 00:34:49.148861 13010 net.cpp:226] BatchNorm15 needs backward computation.
I0702 00:34:49.148634 20914 net.cpp:454] SoftmaxWithLoss1 <- Data2
I0702 00:34:49.148645 20914 net.cpp:411] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0702 00:34:49.148867 13010 net.cpp:226] Convolution15 needs backward computation.
I0702 00:34:49.148874 13010 net.cpp:226] Eltwise6_ReLU13_0_split needs backward computation.
I0702 00:34:49.148881 13010 net.cpp:226] ReLU13 needs backward computation.
I0702 00:34:49.148887 13010 net.cpp:226] Eltwise6 needs backward computation.
I0702 00:34:49.148702 20914 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0702 00:34:49.148895 13010 net.cpp:226] Scale14 needs backward computation.
I0702 00:34:49.148900 13010 net.cpp:226] BatchNorm14 needs backward computation.
I0702 00:34:49.148906 13010 net.cpp:226] Convolution14 needs backward computation.
I0702 00:34:49.148913 13010 net.cpp:226] ReLU12 needs backward computation.
I0702 00:34:49.148919 13010 net.cpp:226] Scale13 needs backward computation.
I0702 00:34:49.148926 13010 net.cpp:226] BatchNorm13 needs backward computation.
I0702 00:34:49.148931 13010 net.cpp:226] Convolution13 needs backward computation.
I0702 00:34:49.148941 13010 net.cpp:226] Eltwise5_ReLU11_0_split needs backward computation.
I0702 00:34:49.148953 13010 net.cpp:226] ReLU11 needs backward computation.
I0702 00:34:49.148960 13010 net.cpp:226] Eltwise5 needs backward computation.
I0702 00:34:49.148967 13010 net.cpp:226] Scale12 needs backward computation.
I0702 00:34:49.148974 13010 net.cpp:226] BatchNorm12 needs backward computation.
I0702 00:34:49.148979 13010 net.cpp:226] Convolution12 needs backward computation.
I0702 00:34:49.148986 13010 net.cpp:226] ReLU10 needs backward computation.
I0702 00:34:49.148993 13010 net.cpp:226] Scale11 needs backward computation.
I0702 00:34:49.148998 13010 net.cpp:226] BatchNorm11 needs backward computation.
I0702 00:34:49.149009 13010 net.cpp:226] Convolution11 needs backward computation.
I0702 00:34:49.149016 13010 net.cpp:226] Eltwise4_ReLU9_0_split needs backward computation.
I0702 00:34:49.149024 13010 net.cpp:226] ReLU9 needs backward computation.
I0702 00:34:49.149029 13010 net.cpp:226] Eltwise4 needs backward computation.
I0702 00:34:49.149037 13010 net.cpp:226] Scale10 needs backward computation.
I0702 00:34:49.149044 13010 net.cpp:226] BatchNorm10 needs backward computation.
I0702 00:34:49.149049 13010 net.cpp:226] Convolution10 needs backward computation.
I0702 00:34:49.149055 13010 net.cpp:226] ReLU8 needs backward computation.
I0702 00:34:49.149062 13010 net.cpp:226] Scale9 needs backward computation.
I0702 00:34:49.149068 13010 net.cpp:226] BatchNorm9 needs backward computation.
I0702 00:34:49.148859 20914 net.cpp:150] Setting up SoftmaxWithLoss1
I0702 00:34:49.149075 13010 net.cpp:226] Convolution9 needs backward computation.
I0702 00:34:49.149080 13010 net.cpp:226] Scale8 needs backward computation.
I0702 00:34:49.148875 20914 net.cpp:157] Top shape: (1)
I0702 00:34:49.149087 13010 net.cpp:226] BatchNorm8 needs backward computation.
I0702 00:34:49.149093 13010 net.cpp:226] Convolution8 needs backward computation.
I0702 00:34:49.149099 13010 net.cpp:226] Eltwise3_ReLU7_0_split needs backward computation.
I0702 00:34:49.149106 13010 net.cpp:226] ReLU7 needs backward computation.
I0702 00:34:49.149112 13010 net.cpp:226] Eltwise3 needs backward computation.
I0702 00:34:49.148885 20914 net.cpp:160]     with loss weight 1
I0702 00:34:49.149119 13010 net.cpp:226] Scale7 needs backward computation.
I0702 00:34:49.148921 20914 net.cpp:165] Memory required for data: 137766276
I0702 00:34:49.149125 13010 net.cpp:226] BatchNorm7 needs backward computation.
I0702 00:34:49.149132 13010 net.cpp:226] Convolution7 needs backward computation.
I0702 00:34:49.148931 20914 net.cpp:226] SoftmaxWithLoss1 needs backward computation.
I0702 00:34:49.149138 13010 net.cpp:226] ReLU6 needs backward computation.
I0702 00:34:49.148941 20914 net.cpp:226] InnerProduct1 needs backward computation.
I0702 00:34:49.148948 20914 net.cpp:226] Pooling1 needs backward computation.
I0702 00:34:49.149144 13010 net.cpp:226] Scale6 needs backward computation.
I0702 00:34:49.148964 20914 net.cpp:226] ReLU19 needs backward computation.
I0702 00:34:49.148972 20914 net.cpp:226] Eltwise9 needs backward computation.
I0702 00:34:49.149149 13010 net.cpp:226] BatchNorm6 needs backward computation.
I0702 00:34:49.149155 13010 net.cpp:226] Convolution6 needs backward computation.
I0702 00:34:49.149163 13010 net.cpp:226] Eltwise2_ReLU5_0_split needs backward computation.
I0702 00:34:49.148978 20914 net.cpp:226] Scale21 needs backward computation.
I0702 00:34:49.148984 20914 net.cpp:226] BatchNorm21 needs backward computation.
I0702 00:34:49.148990 20914 net.cpp:226] Convolution21 needs backward computation.
I0702 00:34:49.149168 13010 net.cpp:226] ReLU5 needs backward computation.
I0702 00:34:49.148998 20914 net.cpp:226] ReLU18 needs backward computation.
I0702 00:34:49.149003 20914 net.cpp:226] Scale20 needs backward computation.
I0702 00:34:49.149175 13010 net.cpp:226] Eltwise2 needs backward computation.
I0702 00:34:49.149183 13010 net.cpp:226] Scale5 needs backward computation.
I0702 00:34:49.149009 20914 net.cpp:226] BatchNorm20 needs backward computation.
I0702 00:34:49.149015 20914 net.cpp:226] Convolution20 needs backward computation.
I0702 00:34:49.149021 20914 net.cpp:226] Eltwise8_ReLU17_0_split needs backward computation.
I0702 00:34:49.149188 13010 net.cpp:226] BatchNorm5 needs backward computation.
I0702 00:34:49.149029 20914 net.cpp:226] ReLU17 needs backward computation.
I0702 00:34:49.149034 20914 net.cpp:226] Eltwise8 needs backward computation.
I0702 00:34:49.149041 20914 net.cpp:226] Scale19 needs backward computation.
I0702 00:34:49.149046 20914 net.cpp:226] BatchNorm19 needs backward computation.
I0702 00:34:49.149052 20914 net.cpp:226] Convolution19 needs backward computation.
I0702 00:34:49.149058 20914 net.cpp:226] ReLU16 needs backward computation.
I0702 00:34:49.149065 20914 net.cpp:226] Scale18 needs backward computation.
I0702 00:34:49.149071 20914 net.cpp:226] BatchNorm18 needs backward computation.
I0702 00:34:49.149076 20914 net.cpp:226] Convolution18 needs backward computation.
I0702 00:34:49.149194 13010 net.cpp:226] Convolution5 needs backward computation.
I0702 00:34:49.149083 20914 net.cpp:226] Eltwise7_ReLU15_0_split needs backward computation.
I0702 00:34:49.149089 20914 net.cpp:226] ReLU15 needs backward computation.
I0702 00:34:49.149096 20914 net.cpp:226] Eltwise7 needs backward computation.
I0702 00:34:49.149200 13010 net.cpp:226] ReLU4 needs backward computation.
I0702 00:34:49.149102 20914 net.cpp:226] Scale17 needs backward computation.
I0702 00:34:49.149206 13010 net.cpp:226] Scale4 needs backward computation.
I0702 00:34:49.149212 13010 net.cpp:226] BatchNorm4 needs backward computation.
I0702 00:34:49.149108 20914 net.cpp:226] BatchNorm17 needs backward computation.
I0702 00:34:49.149114 20914 net.cpp:226] Convolution17 needs backward computation.
I0702 00:34:49.149219 13010 net.cpp:226] Convolution4 needs backward computation.
I0702 00:34:49.149121 20914 net.cpp:226] ReLU14 needs backward computation.
I0702 00:34:49.149225 13010 net.cpp:226] Eltwise1_ReLU3_0_split needs backward computation.
I0702 00:34:49.149127 20914 net.cpp:226] Scale16 needs backward computation.
I0702 00:34:49.149231 13010 net.cpp:226] ReLU3 needs backward computation.
I0702 00:34:49.149133 20914 net.cpp:226] BatchNorm16 needs backward computation.
I0702 00:34:49.149139 20914 net.cpp:226] Convolution16 needs backward computation.
I0702 00:34:49.149237 13010 net.cpp:226] Eltwise1 needs backward computation.
I0702 00:34:49.149147 20914 net.cpp:226] Scale15 needs backward computation.
I0702 00:34:49.149245 13010 net.cpp:226] Scale3 needs backward computation.
I0702 00:34:49.149251 13010 net.cpp:226] BatchNorm3 needs backward computation.
I0702 00:34:49.149152 20914 net.cpp:226] BatchNorm15 needs backward computation.
I0702 00:34:49.149257 13010 net.cpp:226] Convolution3 needs backward computation.
I0702 00:34:49.149158 20914 net.cpp:226] Convolution15 needs backward computation.
I0702 00:34:49.149164 20914 net.cpp:226] Eltwise6_ReLU13_0_split needs backward computation.
I0702 00:34:49.149263 13010 net.cpp:226] ReLU2 needs backward computation.
I0702 00:34:49.149171 20914 net.cpp:226] ReLU13 needs backward computation.
I0702 00:34:49.149269 13010 net.cpp:226] Scale2 needs backward computation.
I0702 00:34:49.149178 20914 net.cpp:226] Eltwise6 needs backward computation.
I0702 00:34:49.149276 13010 net.cpp:226] BatchNorm2 needs backward computation.
I0702 00:34:49.149184 20914 net.cpp:226] Scale14 needs backward computation.
I0702 00:34:49.149190 20914 net.cpp:226] BatchNorm14 needs backward computation.
I0702 00:34:49.149282 13010 net.cpp:226] Convolution2 needs backward computation.
I0702 00:34:49.149195 20914 net.cpp:226] Convolution14 needs backward computation.
I0702 00:34:49.149202 20914 net.cpp:226] ReLU12 needs backward computation.
I0702 00:34:49.149209 20914 net.cpp:226] Scale13 needs backward computation.
I0702 00:34:49.149288 13010 net.cpp:226] Convolution1_ReLU1_0_split needs backward computation.
I0702 00:34:49.149214 20914 net.cpp:226] BatchNorm13 needs backward computation.
I0702 00:34:49.149296 13010 net.cpp:226] ReLU1 needs backward computation.
I0702 00:34:49.149302 13010 net.cpp:226] Scale1 needs backward computation.
I0702 00:34:49.149225 20914 net.cpp:226] Convolution13 needs backward computation.
I0702 00:34:49.149307 13010 net.cpp:226] BatchNorm1 needs backward computation.
I0702 00:34:49.149232 20914 net.cpp:226] Eltwise5_ReLU11_0_split needs backward computation.
I0702 00:34:49.149313 13010 net.cpp:226] Convolution1 needs backward computation.
I0702 00:34:49.149240 20914 net.cpp:226] ReLU11 needs backward computation.
I0702 00:34:49.149246 20914 net.cpp:226] Eltwise5 needs backward computation.
I0702 00:34:49.149322 13010 net.cpp:228] Data1 does not need backward computation.
I0702 00:34:49.149252 20914 net.cpp:226] Scale12 needs backward computation.
I0702 00:34:49.149327 13010 net.cpp:270] This network produces output SoftmaxWithLoss1
I0702 00:34:49.149260 20914 net.cpp:226] BatchNorm12 needs backward computation.
I0702 00:34:49.149416 13010 net.cpp:283] Network initialization done.
I0702 00:34:49.149266 20914 net.cpp:226] Convolution12 needs backward computation.
I0702 00:34:49.149272 20914 net.cpp:226] ReLU10 needs backward computation.
I0702 00:34:49.149278 20914 net.cpp:226] Scale11 needs backward computation.
I0702 00:34:49.149283 20914 net.cpp:226] BatchNorm11 needs backward computation.
I0702 00:34:49.149297 20914 net.cpp:226] Convolution11 needs backward computation.
I0702 00:34:49.149305 20914 net.cpp:226] Eltwise4_ReLU9_0_split needs backward computation.
I0702 00:34:49.149312 20914 net.cpp:226] ReLU9 needs backward computation.
I0702 00:34:49.149318 20914 net.cpp:226] Eltwise4 needs backward computation.
I0702 00:34:49.149325 20914 net.cpp:226] Scale10 needs backward computation.
I0702 00:34:49.149332 20914 net.cpp:226] BatchNorm10 needs backward computation.
I0702 00:34:49.149338 20914 net.cpp:226] Convolution10 needs backward computation.
I0702 00:34:49.149344 20914 net.cpp:226] ReLU8 needs backward computation.
I0702 00:34:49.149350 20914 net.cpp:226] Scale9 needs backward computation.
I0702 00:34:49.149356 20914 net.cpp:226] BatchNorm9 needs backward computation.
I0702 00:34:49.149363 20914 net.cpp:226] Convolution9 needs backward computation.
I0702 00:34:49.149372 20914 net.cpp:226] Scale8 needs backward computation.
I0702 00:34:49.149380 20914 net.cpp:226] BatchNorm8 needs backward computation.
I0702 00:34:49.149386 20914 net.cpp:226] Convolution8 needs backward computation.
I0702 00:34:49.149396 20914 net.cpp:226] Eltwise3_ReLU7_0_split needs backward computation.
I0702 00:34:49.149404 20914 net.cpp:226] ReLU7 needs backward computation.
I0702 00:34:49.149410 20914 net.cpp:226] Eltwise3 needs backward computation.
I0702 00:34:49.149416 20914 net.cpp:226] Scale7 needs backward computation.
I0702 00:34:49.149422 20914 net.cpp:226] BatchNorm7 needs backward computation.
I0702 00:34:49.149428 20914 net.cpp:226] Convolution7 needs backward computation.
I0702 00:34:49.149435 20914 net.cpp:226] ReLU6 needs backward computation.
I0702 00:34:49.149441 20914 net.cpp:226] Scale6 needs backward computation.
I0702 00:34:49.149446 20914 net.cpp:226] BatchNorm6 needs backward computation.
I0702 00:34:49.149453 20914 net.cpp:226] Convolution6 needs backward computation.
I0702 00:34:49.149459 20914 net.cpp:226] Eltwise2_ReLU5_0_split needs backward computation.
I0702 00:34:49.149466 20914 net.cpp:226] ReLU5 needs backward computation.
I0702 00:34:49.149472 20914 net.cpp:226] Eltwise2 needs backward computation.
I0702 00:34:49.149478 20914 net.cpp:226] Scale5 needs backward computation.
I0702 00:34:49.149485 20914 net.cpp:226] BatchNorm5 needs backward computation.
I0702 00:34:49.149492 20914 net.cpp:226] Convolution5 needs backward computation.
I0702 00:34:49.149497 20914 net.cpp:226] ReLU4 needs backward computation.
I0702 00:34:49.149503 20914 net.cpp:226] Scale4 needs backward computation.
I0702 00:34:49.149509 20914 net.cpp:226] BatchNorm4 needs backward computation.
I0702 00:34:49.149515 20914 net.cpp:226] Convolution4 needs backward computation.
I0702 00:34:49.149521 20914 net.cpp:226] Eltwise1_ReLU3_0_split needs backward computation.
I0702 00:34:49.149528 20914 net.cpp:226] ReLU3 needs backward computation.
I0702 00:34:49.149534 20914 net.cpp:226] Eltwise1 needs backward computation.
I0702 00:34:49.149540 20914 net.cpp:226] Scale3 needs backward computation.
I0702 00:34:49.149546 20914 net.cpp:226] BatchNorm3 needs backward computation.
I0702 00:34:49.149552 20914 net.cpp:226] Convolution3 needs backward computation.
I0702 00:34:49.149559 20914 net.cpp:226] ReLU2 needs backward computation.
I0702 00:34:49.149565 20914 net.cpp:226] Scale2 needs backward computation.
I0702 00:34:49.149571 20914 net.cpp:226] BatchNorm2 needs backward computation.
I0702 00:34:49.149577 20914 net.cpp:226] Convolution2 needs backward computation.
I0702 00:34:49.149585 20914 net.cpp:226] Convolution1_ReLU1_0_split needs backward computation.
I0702 00:34:49.149591 20914 net.cpp:226] ReLU1 needs backward computation.
I0702 00:34:49.149597 20914 net.cpp:226] Scale1 needs backward computation.
I0702 00:34:49.149603 20914 net.cpp:226] BatchNorm1 needs backward computation.
I0702 00:34:49.149610 20914 net.cpp:226] Convolution1 needs backward computation.
I0702 00:34:49.149616 20914 net.cpp:228] Data1 does not need backward computation.
I0702 00:34:49.149622 20914 net.cpp:270] This network produces output SoftmaxWithLoss1
I0702 00:34:49.149706 20914 net.cpp:283] Network initialization done.
I0702 00:34:49.149452  4664 image_data_layer.cpp:96] output data size: 32,3,32,32
I0702 00:34:49.150385  4664 net.cpp:150] Setting up Data1
I0702 00:34:49.150406  4664 net.cpp:157] Top shape: 32 3 32 32 (98304)
I0702 00:34:49.150496  4664 net.cpp:157] Top shape: 32 (32)
I0702 00:34:49.150508  4664 net.cpp:165] Memory required for data: 393344
I0702 00:34:49.150521  4664 layer_factory.hpp:77] Creating layer Convolution1
I0702 00:34:49.150557  4664 net.cpp:106] Creating Layer Convolution1
I0702 00:34:49.150568  4664 net.cpp:454] Convolution1 <- Data1
I0702 00:34:49.150593  4664 net.cpp:411] Convolution1 -> Convolution1
I0702 00:34:49.151497 32261 solver.cpp:200] Creating test net (#0) specified by net file: res20_cifar_train_test.prototxt
I0702 00:34:49.151646 32261 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I0702 00:34:49.152182  4664 net.cpp:150] Setting up Convolution1
I0702 00:34:49.152206  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.152218  4664 net.cpp:165] Memory required for data: 2490496
I0702 00:34:49.152313  4664 layer_factory.hpp:77] Creating layer BatchNorm1
I0702 00:34:49.152374  4664 net.cpp:106] Creating Layer BatchNorm1
I0702 00:34:49.152390  4664 net.cpp:454] BatchNorm1 <- Convolution1
I0702 00:34:49.152401  4664 net.cpp:397] BatchNorm1 -> Convolution1 (in-place)
I0702 00:34:49.153283 13010 solver.cpp:200] Creating test net (#0) specified by net file: res20_cifar_train_test.prototxt
I0702 00:34:49.153545 13010 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I0702 00:34:49.151726 32261 net.cpp:49] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "ImageData"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.0078125
    mirror: false
    crop_size: 32
    mean_value: 128
  }
  image_data_param {
    source: "/HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/test/label.txt"
    batch_size: 1
    shuffle: false
    new_height: 40
    new_width: 40
    is_color: true
    root_folder: "/HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/test/Img/"
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
I0702 00:34:49.153391 20914 solver.cpp:200] Creating test net (#0) specified by net file: res20_cifar_train_test.prototxt
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
I0702 00:34:49.153650 20914 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
I0702 00:34:49.153390  4664 net.cpp:150] Setting up BatchNorm1
I0702 00:34:49.153414  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.153429  4664 net.cpp:165] Memory required for data: 4587648
I0702 00:34:49.153493  4664 layer_factory.hpp:77] Creating layer Scale1
I0702 00:34:49.153551  4664 net.cpp:106] Creating Layer Scale1
I0702 00:34:49.153565  4664 net.cpp:454] Scale1 <- Convolution1
I0702 00:34:49.153580  4664 net.cpp:397] Scale1 -> Convolution1 (in-place)
I0702 00:34:49.153708  4664 layer_factory.hpp:77] Creating layer Scale1
I0702 00:34:49.153642 13010 net.cpp:49] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "ImageData"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.0078125
    mirror: false
    crop_size: 32
    mean_value: 128
  }
  image_data_param {
    source: "/HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/test/label.txt"
    batch_size: 1
    shuffle: false
    new_height: 40
    new_width: 40
    is_color: true
    root_folder: "/HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/test/Img/"
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
I0702 00:34:49.153748 20914 net.cpp:49] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "ImageData"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.0078125
    mirror: false
    crop_size: 32
    mean_value: 128
  }
  image_data_param {
    source: "/HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/test/label.txt"
    batch_size: 1
    shuffle: false
    new_height: 40
    new_width: 40
    is_color: true
    root_folder: "/HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/test/Img/"
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
  type: "ReLU"
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
I0702 00:34:49.156987  4664 net.cpp:150] Setting up Scale1
I0702 00:34:49.157011  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.157022  4664 net.cpp:165] Memory required for data: 6684800
I0702 00:34:49.157037  4664 layer_factory.hpp:77] Creating layer ReLU1
I0702 00:34:49.157099  4664 net.cpp:106] Creating Layer ReLU1
I0702 00:34:49.157114  4664 net.cpp:454] ReLU1 <- Convolution1
I0702 00:34:49.157129  4664 net.cpp:397] ReLU1 -> Convolution1 (in-place)
I0702 00:34:49.157142  4664 net.cpp:150] Setting up ReLU1
I0702 00:34:49.157150  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.157158  4664 net.cpp:165] Memory required for data: 8781952
I0702 00:34:49.157166  4664 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0702 00:34:49.157217  4664 net.cpp:106] Creating Layer Convolution1_ReLU1_0_split
I0702 00:34:49.157232  4664 net.cpp:454] Convolution1_ReLU1_0_split <- Convolution1
I0702 00:34:49.157241  4664 net.cpp:411] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0702 00:34:49.157265  4664 net.cpp:411] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0702 00:34:49.157281  4664 net.cpp:150] Setting up Convolution1_ReLU1_0_split
I0702 00:34:49.157291  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.157301  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.157310  4664 net.cpp:165] Memory required for data: 12976256
I0702 00:34:49.157316  4664 layer_factory.hpp:77] Creating layer Convolution2
I0702 00:34:49.157338  4664 net.cpp:106] Creating Layer Convolution2
I0702 00:34:49.157346  4664 net.cpp:454] Convolution2 <- Convolution1_ReLU1_0_split_0
I0702 00:34:49.157358  4664 net.cpp:411] Convolution2 -> Convolution2
I0702 00:34:49.157541  4664 net.cpp:150] Setting up Convolution2
I0702 00:34:49.157557  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.157567  4664 net.cpp:165] Memory required for data: 15073408
I0702 00:34:49.157583  4664 layer_factory.hpp:77] Creating layer BatchNorm2
I0702 00:34:49.157598  4664 net.cpp:106] Creating Layer BatchNorm2
I0702 00:34:49.157606  4664 net.cpp:454] BatchNorm2 <- Convolution2
I0702 00:34:49.157616  4664 net.cpp:397] BatchNorm2 -> Convolution2 (in-place)
I0702 00:34:49.157645  4664 net.cpp:150] Setting up BatchNorm2
I0702 00:34:49.157654  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.157662  4664 net.cpp:165] Memory required for data: 17170560
I0702 00:34:49.157676  4664 layer_factory.hpp:77] Creating layer Scale2
I0702 00:34:49.157691  4664 net.cpp:106] Creating Layer Scale2
I0702 00:34:49.157698  4664 net.cpp:454] Scale2 <- Convolution2
I0702 00:34:49.157707  4664 net.cpp:397] Scale2 -> Convolution2 (in-place)
I0702 00:34:49.157726  4664 layer_factory.hpp:77] Creating layer Scale2
I0702 00:34:49.157761  4664 net.cpp:150] Setting up Scale2
I0702 00:34:49.157773  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.157780  4664 net.cpp:165] Memory required for data: 19267712
I0702 00:34:49.157793  4664 layer_factory.hpp:77] Creating layer ReLU2
I0702 00:34:49.157802  4664 net.cpp:106] Creating Layer ReLU2
I0702 00:34:49.157809  4664 net.cpp:454] ReLU2 <- Convolution2
I0702 00:34:49.157820  4664 net.cpp:397] ReLU2 -> Convolution2 (in-place)
I0702 00:34:49.157830  4664 net.cpp:150] Setting up ReLU2
I0702 00:34:49.157837  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.157845  4664 net.cpp:165] Memory required for data: 21364864
I0702 00:34:49.157852  4664 layer_factory.hpp:77] Creating layer Convolution3
I0702 00:34:49.157873  4664 net.cpp:106] Creating Layer Convolution3
I0702 00:34:49.157882  4664 net.cpp:454] Convolution3 <- Convolution2
I0702 00:34:49.157894  4664 net.cpp:411] Convolution3 -> Convolution3
I0702 00:34:49.158022  4664 net.cpp:150] Setting up Convolution3
I0702 00:34:49.158035  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.158048  4664 net.cpp:165] Memory required for data: 23462016
I0702 00:34:49.158061  4664 layer_factory.hpp:77] Creating layer BatchNorm3
I0702 00:34:49.158071  4664 net.cpp:106] Creating Layer BatchNorm3
I0702 00:34:49.158080  4664 net.cpp:454] BatchNorm3 <- Convolution3
I0702 00:34:49.158092  4664 net.cpp:397] BatchNorm3 -> Convolution3 (in-place)
I0702 00:34:49.158116  4664 net.cpp:150] Setting up BatchNorm3
I0702 00:34:49.158123  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.158133  4664 net.cpp:165] Memory required for data: 25559168
I0702 00:34:49.158152  4664 layer_factory.hpp:77] Creating layer Scale3
I0702 00:34:49.158164  4664 net.cpp:106] Creating Layer Scale3
I0702 00:34:49.158171  4664 net.cpp:454] Scale3 <- Convolution3
I0702 00:34:49.158183  4664 net.cpp:397] Scale3 -> Convolution3 (in-place)
I0702 00:34:49.158200  4664 layer_factory.hpp:77] Creating layer Scale3
I0702 00:34:49.158233  4664 net.cpp:150] Setting up Scale3
I0702 00:34:49.158243  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.158254  4664 net.cpp:165] Memory required for data: 27656320
I0702 00:34:49.158267  4664 layer_factory.hpp:77] Creating layer Eltwise1
I0702 00:34:49.158330  4664 net.cpp:106] Creating Layer Eltwise1
I0702 00:34:49.158344  4664 net.cpp:454] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0702 00:34:49.158354  4664 net.cpp:454] Eltwise1 <- Convolution3
I0702 00:34:49.158363  4664 net.cpp:411] Eltwise1 -> Eltwise1
I0702 00:34:49.159162  4664 net.cpp:150] Setting up Eltwise1
I0702 00:34:49.159183  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.159195  4664 net.cpp:165] Memory required for data: 29753472
I0702 00:34:49.159204  4664 layer_factory.hpp:77] Creating layer ReLU3
I0702 00:34:49.159216  4664 net.cpp:106] Creating Layer ReLU3
I0702 00:34:49.159224  4664 net.cpp:454] ReLU3 <- Eltwise1
I0702 00:34:49.159235  4664 net.cpp:397] ReLU3 -> Eltwise1 (in-place)
I0702 00:34:49.159247  4664 net.cpp:150] Setting up ReLU3
I0702 00:34:49.159253  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.159262  4664 net.cpp:165] Memory required for data: 31850624
I0702 00:34:49.159268  4664 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0702 00:34:49.159283  4664 net.cpp:106] Creating Layer Eltwise1_ReLU3_0_split
I0702 00:34:49.159291  4664 net.cpp:454] Eltwise1_ReLU3_0_split <- Eltwise1
I0702 00:34:49.159301  4664 net.cpp:411] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0702 00:34:49.159314  4664 net.cpp:411] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0702 00:34:49.159327  4664 net.cpp:150] Setting up Eltwise1_ReLU3_0_split
I0702 00:34:49.159333  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.159343  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.159350  4664 net.cpp:165] Memory required for data: 36044928
I0702 00:34:49.159356  4664 layer_factory.hpp:77] Creating layer Convolution4
I0702 00:34:49.159379  4664 net.cpp:106] Creating Layer Convolution4
I0702 00:34:49.159389  4664 net.cpp:454] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0702 00:34:49.159399  4664 net.cpp:411] Convolution4 -> Convolution4
I0702 00:34:49.159529  4664 net.cpp:150] Setting up Convolution4
I0702 00:34:49.159543  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.159554  4664 net.cpp:165] Memory required for data: 38142080
I0702 00:34:49.159566  4664 layer_factory.hpp:77] Creating layer BatchNorm4
I0702 00:34:49.159577  4664 net.cpp:106] Creating Layer BatchNorm4
I0702 00:34:49.159584  4664 net.cpp:454] BatchNorm4 <- Convolution4
I0702 00:34:49.159597  4664 net.cpp:397] BatchNorm4 -> Convolution4 (in-place)
I0702 00:34:49.159624  4664 net.cpp:150] Setting up BatchNorm4
I0702 00:34:49.159631  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.159641  4664 net.cpp:165] Memory required for data: 40239232
I0702 00:34:49.159657  4664 layer_factory.hpp:77] Creating layer Scale4
I0702 00:34:49.159669  4664 net.cpp:106] Creating Layer Scale4
I0702 00:34:49.159677  4664 net.cpp:454] Scale4 <- Convolution4
I0702 00:34:49.159685  4664 net.cpp:397] Scale4 -> Convolution4 (in-place)
I0702 00:34:49.159708  4664 layer_factory.hpp:77] Creating layer Scale4
I0702 00:34:49.159745  4664 net.cpp:150] Setting up Scale4
I0702 00:34:49.159756  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.159765  4664 net.cpp:165] Memory required for data: 42336384
I0702 00:34:49.159776  4664 layer_factory.hpp:77] Creating layer ReLU4
I0702 00:34:49.159788  4664 net.cpp:106] Creating Layer ReLU4
I0702 00:34:49.159795  4664 net.cpp:454] ReLU4 <- Convolution4
I0702 00:34:49.159804  4664 net.cpp:397] ReLU4 -> Convolution4 (in-place)
I0702 00:34:49.159814  4664 net.cpp:150] Setting up ReLU4
I0702 00:34:49.159821  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.159829  4664 net.cpp:165] Memory required for data: 44433536
I0702 00:34:49.159835  4664 layer_factory.hpp:77] Creating layer Convolution5
I0702 00:34:49.159852  4664 net.cpp:106] Creating Layer Convolution5
I0702 00:34:49.159863  4664 net.cpp:454] Convolution5 <- Convolution4
I0702 00:34:49.159874  4664 net.cpp:411] Convolution5 -> Convolution5
I0702 00:34:49.160001  4664 net.cpp:150] Setting up Convolution5
I0702 00:34:49.160022  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.160032  4664 net.cpp:165] Memory required for data: 46530688
I0702 00:34:49.160044  4664 layer_factory.hpp:77] Creating layer BatchNorm5
I0702 00:34:49.160058  4664 net.cpp:106] Creating Layer BatchNorm5
I0702 00:34:49.160065  4664 net.cpp:454] BatchNorm5 <- Convolution5
I0702 00:34:49.160074  4664 net.cpp:397] BatchNorm5 -> Convolution5 (in-place)
I0702 00:34:49.160102  4664 net.cpp:150] Setting up BatchNorm5
I0702 00:34:49.160111  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.160120  4664 net.cpp:165] Memory required for data: 48627840
I0702 00:34:49.160140  4664 layer_factory.hpp:77] Creating layer Scale5
I0702 00:34:49.160152  4664 net.cpp:106] Creating Layer Scale5
I0702 00:34:49.160159  4664 net.cpp:454] Scale5 <- Convolution5
I0702 00:34:49.160171  4664 net.cpp:397] Scale5 -> Convolution5 (in-place)
I0702 00:34:49.160187  4664 layer_factory.hpp:77] Creating layer Scale5
I0702 00:34:49.160219  4664 net.cpp:150] Setting up Scale5
I0702 00:34:49.160229  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.160245  4664 net.cpp:165] Memory required for data: 50724992
I0702 00:34:49.160259  4664 layer_factory.hpp:77] Creating layer Eltwise2
I0702 00:34:49.160269  4664 net.cpp:106] Creating Layer Eltwise2
I0702 00:34:49.160275  4664 net.cpp:454] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0702 00:34:49.160284  4664 net.cpp:454] Eltwise2 <- Convolution5
I0702 00:34:49.160292  4664 net.cpp:411] Eltwise2 -> Eltwise2
I0702 00:34:49.160305  4664 net.cpp:150] Setting up Eltwise2
I0702 00:34:49.160312  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.160320  4664 net.cpp:165] Memory required for data: 52822144
I0702 00:34:49.160327  4664 layer_factory.hpp:77] Creating layer ReLU5
I0702 00:34:49.160336  4664 net.cpp:106] Creating Layer ReLU5
I0702 00:34:49.160342  4664 net.cpp:454] ReLU5 <- Eltwise2
I0702 00:34:49.160351  4664 net.cpp:397] ReLU5 -> Eltwise2 (in-place)
I0702 00:34:49.160360  4664 net.cpp:150] Setting up ReLU5
I0702 00:34:49.160367  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.160375  4664 net.cpp:165] Memory required for data: 54919296
I0702 00:34:49.160382  4664 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0702 00:34:49.160392  4664 net.cpp:106] Creating Layer Eltwise2_ReLU5_0_split
I0702 00:34:49.160398  4664 net.cpp:454] Eltwise2_ReLU5_0_split <- Eltwise2
I0702 00:34:49.160410  4664 net.cpp:411] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0702 00:34:49.160423  4664 net.cpp:411] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0702 00:34:49.160434  4664 net.cpp:150] Setting up Eltwise2_ReLU5_0_split
I0702 00:34:49.160439  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.160449  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.160456  4664 net.cpp:165] Memory required for data: 59113600
I0702 00:34:49.160462  4664 layer_factory.hpp:77] Creating layer Convolution6
I0702 00:34:49.160480  4664 net.cpp:106] Creating Layer Convolution6
I0702 00:34:49.160490  4664 net.cpp:454] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0702 00:34:49.160501  4664 net.cpp:411] Convolution6 -> Convolution6
I0702 00:34:49.160619  4664 net.cpp:150] Setting up Convolution6
I0702 00:34:49.160631  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.160640  4664 net.cpp:165] Memory required for data: 61210752
I0702 00:34:49.160652  4664 layer_factory.hpp:77] Creating layer BatchNorm6
I0702 00:34:49.160665  4664 net.cpp:106] Creating Layer BatchNorm6
I0702 00:34:49.160672  4664 net.cpp:454] BatchNorm6 <- Convolution6
I0702 00:34:49.160681  4664 net.cpp:397] BatchNorm6 -> Convolution6 (in-place)
I0702 00:34:49.160707  4664 net.cpp:150] Setting up BatchNorm6
I0702 00:34:49.160717  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.160727  4664 net.cpp:165] Memory required for data: 63307904
I0702 00:34:49.160738  4664 layer_factory.hpp:77] Creating layer Scale6
I0702 00:34:49.160754  4664 net.cpp:106] Creating Layer Scale6
I0702 00:34:49.160768  4664 net.cpp:454] Scale6 <- Convolution6
I0702 00:34:49.160778  4664 net.cpp:397] Scale6 -> Convolution6 (in-place)
I0702 00:34:49.160794  4664 layer_factory.hpp:77] Creating layer Scale6
I0702 00:34:49.160827  4664 net.cpp:150] Setting up Scale6
I0702 00:34:49.160837  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.160846  4664 net.cpp:165] Memory required for data: 65405056
I0702 00:34:49.160857  4664 layer_factory.hpp:77] Creating layer ReLU6
I0702 00:34:49.160867  4664 net.cpp:106] Creating Layer ReLU6
I0702 00:34:49.160874  4664 net.cpp:454] ReLU6 <- Convolution6
I0702 00:34:49.160883  4664 net.cpp:397] ReLU6 -> Convolution6 (in-place)
I0702 00:34:49.160893  4664 net.cpp:150] Setting up ReLU6
I0702 00:34:49.160900  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.160912  4664 net.cpp:165] Memory required for data: 67502208
I0702 00:34:49.160917  4664 layer_factory.hpp:77] Creating layer Convolution7
I0702 00:34:49.160935  4664 net.cpp:106] Creating Layer Convolution7
I0702 00:34:49.160943  4664 net.cpp:454] Convolution7 <- Convolution6
I0702 00:34:49.160962  4664 net.cpp:411] Convolution7 -> Convolution7
I0702 00:34:49.161082  4664 net.cpp:150] Setting up Convolution7
I0702 00:34:49.161095  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.161104  4664 net.cpp:165] Memory required for data: 69599360
I0702 00:34:49.161116  4664 layer_factory.hpp:77] Creating layer BatchNorm7
I0702 00:34:49.161126  4664 net.cpp:106] Creating Layer BatchNorm7
I0702 00:34:49.161134  4664 net.cpp:454] BatchNorm7 <- Convolution7
I0702 00:34:49.161145  4664 net.cpp:397] BatchNorm7 -> Convolution7 (in-place)
I0702 00:34:49.161171  4664 net.cpp:150] Setting up BatchNorm7
I0702 00:34:49.161180  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.161195  4664 net.cpp:165] Memory required for data: 71696512
I0702 00:34:49.161209  4664 layer_factory.hpp:77] Creating layer Scale7
I0702 00:34:49.161224  4664 net.cpp:106] Creating Layer Scale7
I0702 00:34:49.161231  4664 net.cpp:454] Scale7 <- Convolution7
I0702 00:34:49.161240  4664 net.cpp:397] Scale7 -> Convolution7 (in-place)
I0702 00:34:49.161257  4664 layer_factory.hpp:77] Creating layer Scale7
I0702 00:34:49.161288  4664 net.cpp:150] Setting up Scale7
I0702 00:34:49.161298  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.161306  4664 net.cpp:165] Memory required for data: 73793664
I0702 00:34:49.161319  4664 layer_factory.hpp:77] Creating layer Eltwise3
I0702 00:34:49.161329  4664 net.cpp:106] Creating Layer Eltwise3
I0702 00:34:49.161335  4664 net.cpp:454] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0702 00:34:49.161342  4664 net.cpp:454] Eltwise3 <- Convolution7
I0702 00:34:49.161355  4664 net.cpp:411] Eltwise3 -> Eltwise3
I0702 00:34:49.161367  4664 net.cpp:150] Setting up Eltwise3
I0702 00:34:49.161375  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.161383  4664 net.cpp:165] Memory required for data: 75890816
I0702 00:34:49.161389  4664 layer_factory.hpp:77] Creating layer ReLU7
I0702 00:34:49.161398  4664 net.cpp:106] Creating Layer ReLU7
I0702 00:34:49.161406  4664 net.cpp:454] ReLU7 <- Eltwise3
I0702 00:34:49.161413  4664 net.cpp:397] ReLU7 -> Eltwise3 (in-place)
I0702 00:34:49.161423  4664 net.cpp:150] Setting up ReLU7
I0702 00:34:49.161429  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.161438  4664 net.cpp:165] Memory required for data: 77987968
I0702 00:34:49.161444  4664 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0702 00:34:49.161453  4664 net.cpp:106] Creating Layer Eltwise3_ReLU7_0_split
I0702 00:34:49.161459  4664 net.cpp:454] Eltwise3_ReLU7_0_split <- Eltwise3
I0702 00:34:49.161468  4664 net.cpp:411] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0702 00:34:49.161479  4664 net.cpp:411] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0702 00:34:49.161490  4664 net.cpp:150] Setting up Eltwise3_ReLU7_0_split
I0702 00:34:49.161496  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.161505  4664 net.cpp:157] Top shape: 32 16 32 32 (524288)
I0702 00:34:49.161520  4664 net.cpp:165] Memory required for data: 82182272
I0702 00:34:49.161527  4664 layer_factory.hpp:77] Creating layer Convolution8
I0702 00:34:49.161545  4664 net.cpp:106] Creating Layer Convolution8
I0702 00:34:49.161552  4664 net.cpp:454] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0702 00:34:49.161566  4664 net.cpp:411] Convolution8 -> Convolution8
I0702 00:34:49.161650  4664 net.cpp:150] Setting up Convolution8
I0702 00:34:49.161664  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.161676  4664 net.cpp:165] Memory required for data: 83230848
I0702 00:34:49.161689  4664 layer_factory.hpp:77] Creating layer BatchNorm8
I0702 00:34:49.161700  4664 net.cpp:106] Creating Layer BatchNorm8
I0702 00:34:49.161706  4664 net.cpp:454] BatchNorm8 <- Convolution8
I0702 00:34:49.161715  4664 net.cpp:397] BatchNorm8 -> Convolution8 (in-place)
I0702 00:34:49.161739  4664 net.cpp:150] Setting up BatchNorm8
I0702 00:34:49.161746  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.161756  4664 net.cpp:165] Memory required for data: 84279424
I0702 00:34:49.161768  4664 layer_factory.hpp:77] Creating layer Scale8
I0702 00:34:49.161778  4664 net.cpp:106] Creating Layer Scale8
I0702 00:34:49.161784  4664 net.cpp:454] Scale8 <- Convolution8
I0702 00:34:49.161797  4664 net.cpp:397] Scale8 -> Convolution8 (in-place)
I0702 00:34:49.161813  4664 layer_factory.hpp:77] Creating layer Scale8
I0702 00:34:49.161840  4664 net.cpp:150] Setting up Scale8
I0702 00:34:49.161850  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.161859  4664 net.cpp:165] Memory required for data: 85328000
I0702 00:34:49.161870  4664 layer_factory.hpp:77] Creating layer Convolution9
I0702 00:34:49.161891  4664 net.cpp:106] Creating Layer Convolution9
I0702 00:34:49.161900  4664 net.cpp:454] Convolution9 <- Eltwise3_ReLU7_0_split_1
I0702 00:34:49.161911  4664 net.cpp:411] Convolution9 -> Convolution9
I0702 00:34:49.162086  4664 net.cpp:150] Setting up Convolution9
I0702 00:34:49.162099  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.162109  4664 net.cpp:165] Memory required for data: 86376576
I0702 00:34:49.162120  4664 layer_factory.hpp:77] Creating layer BatchNorm9
I0702 00:34:49.162132  4664 net.cpp:106] Creating Layer BatchNorm9
I0702 00:34:49.162138  4664 net.cpp:454] BatchNorm9 <- Convolution9
I0702 00:34:49.162150  4664 net.cpp:397] BatchNorm9 -> Convolution9 (in-place)
I0702 00:34:49.162178  4664 net.cpp:150] Setting up BatchNorm9
I0702 00:34:49.162186  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.162195  4664 net.cpp:165] Memory required for data: 87425152
I0702 00:34:49.162211  4664 layer_factory.hpp:77] Creating layer Scale9
I0702 00:34:49.162222  4664 net.cpp:106] Creating Layer Scale9
I0702 00:34:49.162230  4664 net.cpp:454] Scale9 <- Convolution9
I0702 00:34:49.162237  4664 net.cpp:397] Scale9 -> Convolution9 (in-place)
I0702 00:34:49.162253  4664 layer_factory.hpp:77] Creating layer Scale9
I0702 00:34:49.162279  4664 net.cpp:150] Setting up Scale9
I0702 00:34:49.162289  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.162297  4664 net.cpp:165] Memory required for data: 88473728
I0702 00:34:49.162309  4664 layer_factory.hpp:77] Creating layer ReLU8
I0702 00:34:49.162318  4664 net.cpp:106] Creating Layer ReLU8
I0702 00:34:49.162328  4664 net.cpp:454] ReLU8 <- Convolution9
I0702 00:34:49.162336  4664 net.cpp:397] ReLU8 -> Convolution9 (in-place)
I0702 00:34:49.162346  4664 net.cpp:150] Setting up ReLU8
I0702 00:34:49.162353  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.162361  4664 net.cpp:165] Memory required for data: 89522304
I0702 00:34:49.162367  4664 layer_factory.hpp:77] Creating layer Convolution10
I0702 00:34:49.162389  4664 net.cpp:106] Creating Layer Convolution10
I0702 00:34:49.162396  4664 net.cpp:454] Convolution10 <- Convolution9
I0702 00:34:49.162407  4664 net.cpp:411] Convolution10 -> Convolution10
I0702 00:34:49.162664  4664 net.cpp:150] Setting up Convolution10
I0702 00:34:49.162678  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.162693  4664 net.cpp:165] Memory required for data: 90570880
I0702 00:34:49.162719  4664 layer_factory.hpp:77] Creating layer BatchNorm10
I0702 00:34:49.162734  4664 net.cpp:106] Creating Layer BatchNorm10
I0702 00:34:49.162742  4664 net.cpp:454] BatchNorm10 <- Convolution10
I0702 00:34:49.162752  4664 net.cpp:397] BatchNorm10 -> Convolution10 (in-place)
I0702 00:34:49.162778  4664 net.cpp:150] Setting up BatchNorm10
I0702 00:34:49.162788  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.162796  4664 net.cpp:165] Memory required for data: 91619456
I0702 00:34:49.162811  4664 layer_factory.hpp:77] Creating layer Scale10
I0702 00:34:49.162823  4664 net.cpp:106] Creating Layer Scale10
I0702 00:34:49.162830  4664 net.cpp:454] Scale10 <- Convolution10
I0702 00:34:49.162839  4664 net.cpp:397] Scale10 -> Convolution10 (in-place)
I0702 00:34:49.162855  4664 layer_factory.hpp:77] Creating layer Scale10
I0702 00:34:49.162883  4664 net.cpp:150] Setting up Scale10
I0702 00:34:49.162894  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.162902  4664 net.cpp:165] Memory required for data: 92668032
I0702 00:34:49.162914  4664 layer_factory.hpp:77] Creating layer Eltwise4
I0702 00:34:49.162923  4664 net.cpp:106] Creating Layer Eltwise4
I0702 00:34:49.162930  4664 net.cpp:454] Eltwise4 <- Convolution8
I0702 00:34:49.162938  4664 net.cpp:454] Eltwise4 <- Convolution10
I0702 00:34:49.162959  4664 net.cpp:411] Eltwise4 -> Eltwise4
I0702 00:34:49.162976  4664 net.cpp:150] Setting up Eltwise4
I0702 00:34:49.162984  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.162992  4664 net.cpp:165] Memory required for data: 93716608
I0702 00:34:49.162999  4664 layer_factory.hpp:77] Creating layer ReLU9
I0702 00:34:49.163008  4664 net.cpp:106] Creating Layer ReLU9
I0702 00:34:49.163015  4664 net.cpp:454] ReLU9 <- Eltwise4
I0702 00:34:49.163027  4664 net.cpp:397] ReLU9 -> Eltwise4 (in-place)
I0702 00:34:49.163036  4664 net.cpp:150] Setting up ReLU9
I0702 00:34:49.163043  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.163051  4664 net.cpp:165] Memory required for data: 94765184
I0702 00:34:49.163058  4664 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0702 00:34:49.163066  4664 net.cpp:106] Creating Layer Eltwise4_ReLU9_0_split
I0702 00:34:49.163074  4664 net.cpp:454] Eltwise4_ReLU9_0_split <- Eltwise4
I0702 00:34:49.163081  4664 net.cpp:411] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0702 00:34:49.163092  4664 net.cpp:411] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0702 00:34:49.163103  4664 net.cpp:150] Setting up Eltwise4_ReLU9_0_split
I0702 00:34:49.163110  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.163118  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.163126  4664 net.cpp:165] Memory required for data: 96862336
I0702 00:34:49.163132  4664 layer_factory.hpp:77] Creating layer Convolution11
I0702 00:34:49.163149  4664 net.cpp:106] Creating Layer Convolution11
I0702 00:34:49.163159  4664 net.cpp:454] Convolution11 <- Eltwise4_ReLU9_0_split_0
I0702 00:34:49.163172  4664 net.cpp:411] Convolution11 -> Convolution11
I0702 00:34:49.163424  4664 net.cpp:150] Setting up Convolution11
I0702 00:34:49.163436  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.163445  4664 net.cpp:165] Memory required for data: 97910912
I0702 00:34:49.163457  4664 layer_factory.hpp:77] Creating layer BatchNorm11
I0702 00:34:49.163468  4664 net.cpp:106] Creating Layer BatchNorm11
I0702 00:34:49.163475  4664 net.cpp:454] BatchNorm11 <- Convolution11
I0702 00:34:49.163487  4664 net.cpp:397] BatchNorm11 -> Convolution11 (in-place)
I0702 00:34:49.163511  4664 net.cpp:150] Setting up BatchNorm11
I0702 00:34:49.163520  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.163528  4664 net.cpp:165] Memory required for data: 98959488
I0702 00:34:49.163542  4664 layer_factory.hpp:77] Creating layer Scale11
I0702 00:34:49.163554  4664 net.cpp:106] Creating Layer Scale11
I0702 00:34:49.163569  4664 net.cpp:454] Scale11 <- Convolution11
I0702 00:34:49.163579  4664 net.cpp:397] Scale11 -> Convolution11 (in-place)
I0702 00:34:49.163596  4664 layer_factory.hpp:77] Creating layer Scale11
I0702 00:34:49.163625  4664 net.cpp:150] Setting up Scale11
I0702 00:34:49.163635  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.163642  4664 net.cpp:165] Memory required for data: 100008064
I0702 00:34:49.163655  4664 layer_factory.hpp:77] Creating layer ReLU10
I0702 00:34:49.163664  4664 net.cpp:106] Creating Layer ReLU10
I0702 00:34:49.163671  4664 net.cpp:454] ReLU10 <- Convolution11
I0702 00:34:49.163682  4664 net.cpp:397] ReLU10 -> Convolution11 (in-place)
I0702 00:34:49.163693  4664 net.cpp:150] Setting up ReLU10
I0702 00:34:49.163699  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.163709  4664 net.cpp:165] Memory required for data: 101056640
I0702 00:34:49.163717  4664 layer_factory.hpp:77] Creating layer Convolution12
I0702 00:34:49.163736  4664 net.cpp:106] Creating Layer Convolution12
I0702 00:34:49.163745  4664 net.cpp:454] Convolution12 <- Convolution11
I0702 00:34:49.163759  4664 net.cpp:411] Convolution12 -> Convolution12
I0702 00:34:49.164019  4664 net.cpp:150] Setting up Convolution12
I0702 00:34:49.164032  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.164044  4664 net.cpp:165] Memory required for data: 102105216
I0702 00:34:49.164057  4664 layer_factory.hpp:77] Creating layer BatchNorm12
I0702 00:34:49.164067  4664 net.cpp:106] Creating Layer BatchNorm12
I0702 00:34:49.164073  4664 net.cpp:454] BatchNorm12 <- Convolution12
I0702 00:34:49.164085  4664 net.cpp:397] BatchNorm12 -> Convolution12 (in-place)
I0702 00:34:49.164110  4664 net.cpp:150] Setting up BatchNorm12
I0702 00:34:49.164119  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.164129  4664 net.cpp:165] Memory required for data: 103153792
I0702 00:34:49.164141  4664 layer_factory.hpp:77] Creating layer Scale12
I0702 00:34:49.164151  4664 net.cpp:106] Creating Layer Scale12
I0702 00:34:49.164158  4664 net.cpp:454] Scale12 <- Convolution12
I0702 00:34:49.164170  4664 net.cpp:397] Scale12 -> Convolution12 (in-place)
I0702 00:34:49.164186  4664 layer_factory.hpp:77] Creating layer Scale12
I0702 00:34:49.164213  4664 net.cpp:150] Setting up Scale12
I0702 00:34:49.164223  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.164232  4664 net.cpp:165] Memory required for data: 104202368
I0702 00:34:49.164243  4664 layer_factory.hpp:77] Creating layer Eltwise5
I0702 00:34:49.164253  4664 net.cpp:106] Creating Layer Eltwise5
I0702 00:34:49.164260  4664 net.cpp:454] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0702 00:34:49.164268  4664 net.cpp:454] Eltwise5 <- Convolution12
I0702 00:34:49.164279  4664 net.cpp:411] Eltwise5 -> Eltwise5
I0702 00:34:49.164292  4664 net.cpp:150] Setting up Eltwise5
I0702 00:34:49.164299  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.164307  4664 net.cpp:165] Memory required for data: 105250944
I0702 00:34:49.164314  4664 layer_factory.hpp:77] Creating layer ReLU11
I0702 00:34:49.164322  4664 net.cpp:106] Creating Layer ReLU11
I0702 00:34:49.164330  4664 net.cpp:454] ReLU11 <- Eltwise5
I0702 00:34:49.164340  4664 net.cpp:397] ReLU11 -> Eltwise5 (in-place)
I0702 00:34:49.164350  4664 net.cpp:150] Setting up ReLU11
I0702 00:34:49.164357  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.164366  4664 net.cpp:165] Memory required for data: 106299520
I0702 00:34:49.164371  4664 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0702 00:34:49.164381  4664 net.cpp:106] Creating Layer Eltwise5_ReLU11_0_split
I0702 00:34:49.164386  4664 net.cpp:454] Eltwise5_ReLU11_0_split <- Eltwise5
I0702 00:34:49.164396  4664 net.cpp:411] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0702 00:34:49.164407  4664 net.cpp:411] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0702 00:34:49.164417  4664 net.cpp:150] Setting up Eltwise5_ReLU11_0_split
I0702 00:34:49.164424  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.164439  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.164448  4664 net.cpp:165] Memory required for data: 108396672
I0702 00:34:49.164455  4664 layer_factory.hpp:77] Creating layer Convolution13
I0702 00:34:49.164474  4664 net.cpp:106] Creating Layer Convolution13
I0702 00:34:49.164482  4664 net.cpp:454] Convolution13 <- Eltwise5_ReLU11_0_split_0
I0702 00:34:49.164495  4664 net.cpp:411] Convolution13 -> Convolution13
I0702 00:34:49.164746  4664 net.cpp:150] Setting up Convolution13
I0702 00:34:49.164762  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.164772  4664 net.cpp:165] Memory required for data: 109445248
I0702 00:34:49.164783  4664 layer_factory.hpp:77] Creating layer BatchNorm13
I0702 00:34:49.164793  4664 net.cpp:106] Creating Layer BatchNorm13
I0702 00:34:49.164800  4664 net.cpp:454] BatchNorm13 <- Convolution13
I0702 00:34:49.164813  4664 net.cpp:397] BatchNorm13 -> Convolution13 (in-place)
I0702 00:34:49.164839  4664 net.cpp:150] Setting up BatchNorm13
I0702 00:34:49.164847  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.164856  4664 net.cpp:165] Memory required for data: 110493824
I0702 00:34:49.164870  4664 layer_factory.hpp:77] Creating layer Scale13
I0702 00:34:49.164882  4664 net.cpp:106] Creating Layer Scale13
I0702 00:34:49.164889  4664 net.cpp:454] Scale13 <- Convolution13
I0702 00:34:49.164898  4664 net.cpp:397] Scale13 -> Convolution13 (in-place)
I0702 00:34:49.164914  4664 layer_factory.hpp:77] Creating layer Scale13
I0702 00:34:49.164942  4664 net.cpp:150] Setting up Scale13
I0702 00:34:49.164958  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.164968  4664 net.cpp:165] Memory required for data: 111542400
I0702 00:34:49.164979  4664 layer_factory.hpp:77] Creating layer ReLU12
I0702 00:34:49.164988  4664 net.cpp:106] Creating Layer ReLU12
I0702 00:34:49.164995  4664 net.cpp:454] ReLU12 <- Convolution13
I0702 00:34:49.165007  4664 net.cpp:397] ReLU12 -> Convolution13 (in-place)
I0702 00:34:49.165019  4664 net.cpp:150] Setting up ReLU12
I0702 00:34:49.165025  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.165033  4664 net.cpp:165] Memory required for data: 112590976
I0702 00:34:49.165040  4664 layer_factory.hpp:77] Creating layer Convolution14
I0702 00:34:49.165057  4664 net.cpp:106] Creating Layer Convolution14
I0702 00:34:49.165067  4664 net.cpp:454] Convolution14 <- Convolution13
I0702 00:34:49.165081  4664 net.cpp:411] Convolution14 -> Convolution14
I0702 00:34:49.165338  4664 net.cpp:150] Setting up Convolution14
I0702 00:34:49.165350  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.165359  4664 net.cpp:165] Memory required for data: 113639552
I0702 00:34:49.165371  4664 layer_factory.hpp:77] Creating layer BatchNorm14
I0702 00:34:49.165390  4664 net.cpp:106] Creating Layer BatchNorm14
I0702 00:34:49.165398  4664 net.cpp:454] BatchNorm14 <- Convolution14
I0702 00:34:49.165410  4664 net.cpp:397] BatchNorm14 -> Convolution14 (in-place)
I0702 00:34:49.165433  4664 net.cpp:150] Setting up BatchNorm14
I0702 00:34:49.165442  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.165452  4664 net.cpp:165] Memory required for data: 114688128
I0702 00:34:49.165464  4664 layer_factory.hpp:77] Creating layer Scale14
I0702 00:34:49.165477  4664 net.cpp:106] Creating Layer Scale14
I0702 00:34:49.165484  4664 net.cpp:454] Scale14 <- Convolution14
I0702 00:34:49.165493  4664 net.cpp:397] Scale14 -> Convolution14 (in-place)
I0702 00:34:49.165509  4664 layer_factory.hpp:77] Creating layer Scale14
I0702 00:34:49.165536  4664 net.cpp:150] Setting up Scale14
I0702 00:34:49.165546  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.165555  4664 net.cpp:165] Memory required for data: 115736704
I0702 00:34:49.165566  4664 layer_factory.hpp:77] Creating layer Eltwise6
I0702 00:34:49.165576  4664 net.cpp:106] Creating Layer Eltwise6
I0702 00:34:49.165583  4664 net.cpp:454] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0702 00:34:49.165591  4664 net.cpp:454] Eltwise6 <- Convolution14
I0702 00:34:49.165611  4664 net.cpp:411] Eltwise6 -> Eltwise6
I0702 00:34:49.165623  4664 net.cpp:150] Setting up Eltwise6
I0702 00:34:49.165630  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.165639  4664 net.cpp:165] Memory required for data: 116785280
I0702 00:34:49.165647  4664 layer_factory.hpp:77] Creating layer ReLU13
I0702 00:34:49.165655  4664 net.cpp:106] Creating Layer ReLU13
I0702 00:34:49.165661  4664 net.cpp:454] ReLU13 <- Eltwise6
I0702 00:34:49.165669  4664 net.cpp:397] ReLU13 -> Eltwise6 (in-place)
I0702 00:34:49.165679  4664 net.cpp:150] Setting up ReLU13
I0702 00:34:49.165685  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.165697  4664 net.cpp:165] Memory required for data: 117833856
I0702 00:34:49.165704  4664 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0702 00:34:49.165712  4664 net.cpp:106] Creating Layer Eltwise6_ReLU13_0_split
I0702 00:34:49.165719  4664 net.cpp:454] Eltwise6_ReLU13_0_split <- Eltwise6
I0702 00:34:49.165727  4664 net.cpp:411] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0702 00:34:49.165738  4664 net.cpp:411] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0702 00:34:49.165750  4664 net.cpp:150] Setting up Eltwise6_ReLU13_0_split
I0702 00:34:49.165756  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.165765  4664 net.cpp:157] Top shape: 32 32 16 16 (262144)
I0702 00:34:49.165772  4664 net.cpp:165] Memory required for data: 119931008
I0702 00:34:49.165778  4664 layer_factory.hpp:77] Creating layer Convolution15
I0702 00:34:49.165801  4664 net.cpp:106] Creating Layer Convolution15
I0702 00:34:49.165810  4664 net.cpp:454] Convolution15 <- Eltwise6_ReLU13_0_split_0
I0702 00:34:49.165822  4664 net.cpp:411] Convolution15 -> Convolution15
I0702 00:34:49.165930  4664 net.cpp:150] Setting up Convolution15
I0702 00:34:49.165942  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.165957  4664 net.cpp:165] Memory required for data: 120455296
I0702 00:34:49.165971  4664 layer_factory.hpp:77] Creating layer BatchNorm15
I0702 00:34:49.165984  4664 net.cpp:106] Creating Layer BatchNorm15
I0702 00:34:49.165992  4664 net.cpp:454] BatchNorm15 <- Convolution15
I0702 00:34:49.166002  4664 net.cpp:397] BatchNorm15 -> Convolution15 (in-place)
I0702 00:34:49.166023  4664 net.cpp:150] Setting up BatchNorm15
I0702 00:34:49.166030  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.166039  4664 net.cpp:165] Memory required for data: 120979584
I0702 00:34:49.166055  4664 layer_factory.hpp:77] Creating layer Scale15
I0702 00:34:49.166065  4664 net.cpp:106] Creating Layer Scale15
I0702 00:34:49.166072  4664 net.cpp:454] Scale15 <- Convolution15
I0702 00:34:49.166081  4664 net.cpp:397] Scale15 -> Convolution15 (in-place)
I0702 00:34:49.166100  4664 layer_factory.hpp:77] Creating layer Scale15
I0702 00:34:49.166123  4664 net.cpp:150] Setting up Scale15
I0702 00:34:49.166133  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.166144  4664 net.cpp:165] Memory required for data: 121503872
I0702 00:34:49.166155  4664 layer_factory.hpp:77] Creating layer Convolution16
I0702 00:34:49.166179  4664 net.cpp:106] Creating Layer Convolution16
I0702 00:34:49.166189  4664 net.cpp:454] Convolution16 <- Eltwise6_ReLU13_0_split_1
I0702 00:34:49.166200  4664 net.cpp:411] Convolution16 -> Convolution16
I0702 00:34:49.166636  4664 net.cpp:150] Setting up Convolution16
I0702 00:34:49.166649  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.166659  4664 net.cpp:165] Memory required for data: 122028160
I0702 00:34:49.166671  4664 layer_factory.hpp:77] Creating layer BatchNorm16
I0702 00:34:49.166682  4664 net.cpp:106] Creating Layer BatchNorm16
I0702 00:34:49.166688  4664 net.cpp:454] BatchNorm16 <- Convolution16
I0702 00:34:49.166700  4664 net.cpp:397] BatchNorm16 -> Convolution16 (in-place)
I0702 00:34:49.166723  4664 net.cpp:150] Setting up BatchNorm16
I0702 00:34:49.166733  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.166744  4664 net.cpp:165] Memory required for data: 122552448
I0702 00:34:49.166764  4664 layer_factory.hpp:77] Creating layer Scale16
I0702 00:34:49.166775  4664 net.cpp:106] Creating Layer Scale16
I0702 00:34:49.166782  4664 net.cpp:454] Scale16 <- Convolution16
I0702 00:34:49.166795  4664 net.cpp:397] Scale16 -> Convolution16 (in-place)
I0702 00:34:49.166811  4664 layer_factory.hpp:77] Creating layer Scale16
I0702 00:34:49.166839  4664 net.cpp:150] Setting up Scale16
I0702 00:34:49.166849  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.166858  4664 net.cpp:165] Memory required for data: 123076736
I0702 00:34:49.166869  4664 layer_factory.hpp:77] Creating layer ReLU14
I0702 00:34:49.166879  4664 net.cpp:106] Creating Layer ReLU14
I0702 00:34:49.166887  4664 net.cpp:454] ReLU14 <- Convolution16
I0702 00:34:49.166898  4664 net.cpp:397] ReLU14 -> Convolution16 (in-place)
I0702 00:34:49.166908  4664 net.cpp:150] Setting up ReLU14
I0702 00:34:49.166915  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.166923  4664 net.cpp:165] Memory required for data: 123601024
I0702 00:34:49.166929  4664 layer_factory.hpp:77] Creating layer Convolution17
I0702 00:34:49.166950  4664 net.cpp:106] Creating Layer Convolution17
I0702 00:34:49.166965  4664 net.cpp:454] Convolution17 <- Convolution16
I0702 00:34:49.166980  4664 net.cpp:411] Convolution17 -> Convolution17
I0702 00:34:49.167794  4664 net.cpp:150] Setting up Convolution17
I0702 00:34:49.167809  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.167822  4664 net.cpp:165] Memory required for data: 124125312
I0702 00:34:49.167835  4664 layer_factory.hpp:77] Creating layer BatchNorm17
I0702 00:34:49.167847  4664 net.cpp:106] Creating Layer BatchNorm17
I0702 00:34:49.167857  4664 net.cpp:454] BatchNorm17 <- Convolution17
I0702 00:34:49.167868  4664 net.cpp:397] BatchNorm17 -> Convolution17 (in-place)
I0702 00:34:49.167889  4664 net.cpp:150] Setting up BatchNorm17
I0702 00:34:49.167898  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.167906  4664 net.cpp:165] Memory required for data: 124649600
I0702 00:34:49.167920  4664 layer_factory.hpp:77] Creating layer Scale17
I0702 00:34:49.167932  4664 net.cpp:106] Creating Layer Scale17
I0702 00:34:49.167938  4664 net.cpp:454] Scale17 <- Convolution17
I0702 00:34:49.167948  4664 net.cpp:397] Scale17 -> Convolution17 (in-place)
I0702 00:34:49.167971  4664 layer_factory.hpp:77] Creating layer Scale17
I0702 00:34:49.167994  4664 net.cpp:150] Setting up Scale17
I0702 00:34:49.168004  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.168014  4664 net.cpp:165] Memory required for data: 125173888
I0702 00:34:49.168025  4664 layer_factory.hpp:77] Creating layer Eltwise7
I0702 00:34:49.168036  4664 net.cpp:106] Creating Layer Eltwise7
I0702 00:34:49.168043  4664 net.cpp:454] Eltwise7 <- Convolution15
I0702 00:34:49.168051  4664 net.cpp:454] Eltwise7 <- Convolution17
I0702 00:34:49.168062  4664 net.cpp:411] Eltwise7 -> Eltwise7
I0702 00:34:49.168074  4664 net.cpp:150] Setting up Eltwise7
I0702 00:34:49.168081  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.168090  4664 net.cpp:165] Memory required for data: 125698176
I0702 00:34:49.168097  4664 layer_factory.hpp:77] Creating layer ReLU15
I0702 00:34:49.168105  4664 net.cpp:106] Creating Layer ReLU15
I0702 00:34:49.168118  4664 net.cpp:454] ReLU15 <- Eltwise7
I0702 00:34:49.168128  4664 net.cpp:397] ReLU15 -> Eltwise7 (in-place)
I0702 00:34:49.168138  4664 net.cpp:150] Setting up ReLU15
I0702 00:34:49.168145  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.168157  4664 net.cpp:165] Memory required for data: 126222464
I0702 00:34:49.168164  4664 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0702 00:34:49.168174  4664 net.cpp:106] Creating Layer Eltwise7_ReLU15_0_split
I0702 00:34:49.168181  4664 net.cpp:454] Eltwise7_ReLU15_0_split <- Eltwise7
I0702 00:34:49.168190  4664 net.cpp:411] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0702 00:34:49.168201  4664 net.cpp:411] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0702 00:34:49.168226  4664 net.cpp:150] Setting up Eltwise7_ReLU15_0_split
I0702 00:34:49.168232  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.168241  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.168249  4664 net.cpp:165] Memory required for data: 127271040
I0702 00:34:49.168256  4664 layer_factory.hpp:77] Creating layer Convolution18
I0702 00:34:49.168274  4664 net.cpp:106] Creating Layer Convolution18
I0702 00:34:49.168282  4664 net.cpp:454] Convolution18 <- Eltwise7_ReLU15_0_split_0
I0702 00:34:49.168293  4664 net.cpp:411] Convolution18 -> Convolution18
I0702 00:34:49.169123  4664 net.cpp:150] Setting up Convolution18
I0702 00:34:49.169137  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.169147  4664 net.cpp:165] Memory required for data: 127795328
I0702 00:34:49.169159  4664 layer_factory.hpp:77] Creating layer BatchNorm18
I0702 00:34:49.169170  4664 net.cpp:106] Creating Layer BatchNorm18
I0702 00:34:49.169178  4664 net.cpp:454] BatchNorm18 <- Convolution18
I0702 00:34:49.169190  4664 net.cpp:397] BatchNorm18 -> Convolution18 (in-place)
I0702 00:34:49.169214  4664 net.cpp:150] Setting up BatchNorm18
I0702 00:34:49.169222  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.169231  4664 net.cpp:165] Memory required for data: 128319616
I0702 00:34:49.169245  4664 layer_factory.hpp:77] Creating layer Scale18
I0702 00:34:49.169255  4664 net.cpp:106] Creating Layer Scale18
I0702 00:34:49.169262  4664 net.cpp:454] Scale18 <- Convolution18
I0702 00:34:49.169275  4664 net.cpp:397] Scale18 -> Convolution18 (in-place)
I0702 00:34:49.169291  4664 layer_factory.hpp:77] Creating layer Scale18
I0702 00:34:49.169317  4664 net.cpp:150] Setting up Scale18
I0702 00:34:49.169327  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.169337  4664 net.cpp:165] Memory required for data: 128843904
I0702 00:34:49.169348  4664 layer_factory.hpp:77] Creating layer ReLU16
I0702 00:34:49.169358  4664 net.cpp:106] Creating Layer ReLU16
I0702 00:34:49.169364  4664 net.cpp:454] ReLU16 <- Convolution18
I0702 00:34:49.169375  4664 net.cpp:397] ReLU16 -> Convolution18 (in-place)
I0702 00:34:49.169389  4664 net.cpp:150] Setting up ReLU16
I0702 00:34:49.169394  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.169404  4664 net.cpp:165] Memory required for data: 129368192
I0702 00:34:49.169409  4664 layer_factory.hpp:77] Creating layer Convolution19
I0702 00:34:49.169432  4664 net.cpp:106] Creating Layer Convolution19
I0702 00:34:49.169440  4664 net.cpp:454] Convolution19 <- Convolution18
I0702 00:34:49.169451  4664 net.cpp:411] Convolution19 -> Convolution19
I0702 00:34:49.170264  4664 net.cpp:150] Setting up Convolution19
I0702 00:34:49.170277  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.170290  4664 net.cpp:165] Memory required for data: 129892480
I0702 00:34:49.170302  4664 layer_factory.hpp:77] Creating layer BatchNorm19
I0702 00:34:49.170313  4664 net.cpp:106] Creating Layer BatchNorm19
I0702 00:34:49.170320  4664 net.cpp:454] BatchNorm19 <- Convolution19
I0702 00:34:49.170331  4664 net.cpp:397] BatchNorm19 -> Convolution19 (in-place)
I0702 00:34:49.170354  4664 net.cpp:150] Setting up BatchNorm19
I0702 00:34:49.170364  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.170372  4664 net.cpp:165] Memory required for data: 130416768
I0702 00:34:49.170405  4664 layer_factory.hpp:77] Creating layer Scale19
I0702 00:34:49.170419  4664 net.cpp:106] Creating Layer Scale19
I0702 00:34:49.170426  4664 net.cpp:454] Scale19 <- Convolution19
I0702 00:34:49.170439  4664 net.cpp:397] Scale19 -> Convolution19 (in-place)
I0702 00:34:49.170457  4664 layer_factory.hpp:77] Creating layer Scale19
I0702 00:34:49.170481  4664 net.cpp:150] Setting up Scale19
I0702 00:34:49.170490  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.170497  4664 net.cpp:165] Memory required for data: 130941056
I0702 00:34:49.170509  4664 layer_factory.hpp:77] Creating layer Eltwise8
I0702 00:34:49.170521  4664 net.cpp:106] Creating Layer Eltwise8
I0702 00:34:49.170529  4664 net.cpp:454] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0702 00:34:49.170543  4664 net.cpp:454] Eltwise8 <- Convolution19
I0702 00:34:49.170553  4664 net.cpp:411] Eltwise8 -> Eltwise8
I0702 00:34:49.170572  4664 net.cpp:150] Setting up Eltwise8
I0702 00:34:49.170578  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.170586  4664 net.cpp:165] Memory required for data: 131465344
I0702 00:34:49.170593  4664 layer_factory.hpp:77] Creating layer ReLU17
I0702 00:34:49.170604  4664 net.cpp:106] Creating Layer ReLU17
I0702 00:34:49.170611  4664 net.cpp:454] ReLU17 <- Eltwise8
I0702 00:34:49.170619  4664 net.cpp:397] ReLU17 -> Eltwise8 (in-place)
I0702 00:34:49.170629  4664 net.cpp:150] Setting up ReLU17
I0702 00:34:49.170636  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.170644  4664 net.cpp:165] Memory required for data: 131989632
I0702 00:34:49.170651  4664 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0702 00:34:49.170660  4664 net.cpp:106] Creating Layer Eltwise8_ReLU17_0_split
I0702 00:34:49.170666  4664 net.cpp:454] Eltwise8_ReLU17_0_split <- Eltwise8
I0702 00:34:49.170680  4664 net.cpp:411] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0702 00:34:49.170692  4664 net.cpp:411] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0702 00:34:49.170703  4664 net.cpp:150] Setting up Eltwise8_ReLU17_0_split
I0702 00:34:49.170711  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.170719  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.170727  4664 net.cpp:165] Memory required for data: 133038208
I0702 00:34:49.170734  4664 layer_factory.hpp:77] Creating layer Convolution20
I0702 00:34:49.170758  4664 net.cpp:106] Creating Layer Convolution20
I0702 00:34:49.170771  4664 net.cpp:454] Convolution20 <- Eltwise8_ReLU17_0_split_0
I0702 00:34:49.170783  4664 net.cpp:411] Convolution20 -> Convolution20
I0702 00:34:49.171600  4664 net.cpp:150] Setting up Convolution20
I0702 00:34:49.171617  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.171627  4664 net.cpp:165] Memory required for data: 133562496
I0702 00:34:49.171638  4664 layer_factory.hpp:77] Creating layer BatchNorm20
I0702 00:34:49.171649  4664 net.cpp:106] Creating Layer BatchNorm20
I0702 00:34:49.171656  4664 net.cpp:454] BatchNorm20 <- Convolution20
I0702 00:34:49.171669  4664 net.cpp:397] BatchNorm20 -> Convolution20 (in-place)
I0702 00:34:49.171692  4664 net.cpp:150] Setting up BatchNorm20
I0702 00:34:49.171701  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.171710  4664 net.cpp:165] Memory required for data: 134086784
I0702 00:34:49.171723  4664 layer_factory.hpp:77] Creating layer Scale20
I0702 00:34:49.171736  4664 net.cpp:106] Creating Layer Scale20
I0702 00:34:49.171744  4664 net.cpp:454] Scale20 <- Convolution20
I0702 00:34:49.171752  4664 net.cpp:397] Scale20 -> Convolution20 (in-place)
I0702 00:34:49.171769  4664 layer_factory.hpp:77] Creating layer Scale20
I0702 00:34:49.171797  4664 net.cpp:150] Setting up Scale20
I0702 00:34:49.171808  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.171816  4664 net.cpp:165] Memory required for data: 134611072
I0702 00:34:49.171828  4664 layer_factory.hpp:77] Creating layer ReLU18
I0702 00:34:49.171838  4664 net.cpp:106] Creating Layer ReLU18
I0702 00:34:49.171844  4664 net.cpp:454] ReLU18 <- Convolution20
I0702 00:34:49.171854  4664 net.cpp:397] ReLU18 -> Convolution20 (in-place)
I0702 00:34:49.171864  4664 net.cpp:150] Setting up ReLU18
I0702 00:34:49.171871  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.171880  4664 net.cpp:165] Memory required for data: 135135360
I0702 00:34:49.171885  4664 layer_factory.hpp:77] Creating layer Convolution21
I0702 00:34:49.171908  4664 net.cpp:106] Creating Layer Convolution21
I0702 00:34:49.171916  4664 net.cpp:454] Convolution21 <- Convolution20
I0702 00:34:49.171927  4664 net.cpp:411] Convolution21 -> Convolution21
I0702 00:34:49.172746  4664 net.cpp:150] Setting up Convolution21
I0702 00:34:49.172761  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.172780  4664 net.cpp:165] Memory required for data: 135659648
I0702 00:34:49.172791  4664 layer_factory.hpp:77] Creating layer BatchNorm21
I0702 00:34:49.172802  4664 net.cpp:106] Creating Layer BatchNorm21
I0702 00:34:49.172809  4664 net.cpp:454] BatchNorm21 <- Convolution21
I0702 00:34:49.172821  4664 net.cpp:397] BatchNorm21 -> Convolution21 (in-place)
I0702 00:34:49.172843  4664 net.cpp:150] Setting up BatchNorm21
I0702 00:34:49.172852  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.172863  4664 net.cpp:165] Memory required for data: 136183936
I0702 00:34:49.172875  4664 layer_factory.hpp:77] Creating layer Scale21
I0702 00:34:49.172886  4664 net.cpp:106] Creating Layer Scale21
I0702 00:34:49.172893  4664 net.cpp:454] Scale21 <- Convolution21
I0702 00:34:49.172904  4664 net.cpp:397] Scale21 -> Convolution21 (in-place)
I0702 00:34:49.172921  4664 layer_factory.hpp:77] Creating layer Scale21
I0702 00:34:49.172950  4664 net.cpp:150] Setting up Scale21
I0702 00:34:49.172966  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.172976  4664 net.cpp:165] Memory required for data: 136708224
I0702 00:34:49.172986  4664 layer_factory.hpp:77] Creating layer Eltwise9
I0702 00:34:49.172997  4664 net.cpp:106] Creating Layer Eltwise9
I0702 00:34:49.173004  4664 net.cpp:454] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0702 00:34:49.173012  4664 net.cpp:454] Eltwise9 <- Convolution21
I0702 00:34:49.173024  4664 net.cpp:411] Eltwise9 -> Eltwise9
I0702 00:34:49.173038  4664 net.cpp:150] Setting up Eltwise9
I0702 00:34:49.173044  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.173053  4664 net.cpp:165] Memory required for data: 137232512
I0702 00:34:49.173060  4664 layer_factory.hpp:77] Creating layer ReLU19
I0702 00:34:49.173069  4664 net.cpp:106] Creating Layer ReLU19
I0702 00:34:49.173075  4664 net.cpp:454] ReLU19 <- Eltwise9
I0702 00:34:49.173087  4664 net.cpp:397] ReLU19 -> Eltwise9 (in-place)
I0702 00:34:49.173097  4664 net.cpp:150] Setting up ReLU19
I0702 00:34:49.173104  4664 net.cpp:157] Top shape: 32 64 8 8 (131072)
I0702 00:34:49.173112  4664 net.cpp:165] Memory required for data: 137756800
I0702 00:34:49.173118  4664 layer_factory.hpp:77] Creating layer Pooling1
I0702 00:34:49.173127  4664 net.cpp:106] Creating Layer Pooling1
I0702 00:34:49.173135  4664 net.cpp:454] Pooling1 <- Eltwise9
I0702 00:34:49.173143  4664 net.cpp:411] Pooling1 -> Pooling1
I0702 00:34:49.173269  4664 net.cpp:150] Setting up Pooling1
I0702 00:34:49.173283  4664 net.cpp:157] Top shape: 32 64 1 1 (2048)
I0702 00:34:49.173296  4664 net.cpp:165] Memory required for data: 137764992
I0702 00:34:49.173305  4664 layer_factory.hpp:77] Creating layer InnerProduct1
I0702 00:34:49.173355  4664 net.cpp:106] Creating Layer InnerProduct1
I0702 00:34:49.173369  4664 net.cpp:454] InnerProduct1 <- Pooling1
I0702 00:34:49.173384  4664 net.cpp:411] InnerProduct1 -> InnerProduct1
I0702 00:34:49.173563  4664 net.cpp:150] Setting up InnerProduct1
I0702 00:34:49.173578  4664 net.cpp:157] Top shape: 32 10 (320)
I0702 00:34:49.173588  4664 net.cpp:165] Memory required for data: 137766272
I0702 00:34:49.173602  4664 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0702 00:34:49.173653  4664 net.cpp:106] Creating Layer SoftmaxWithLoss1
I0702 00:34:49.173667  4664 net.cpp:454] SoftmaxWithLoss1 <- InnerProduct1
I0702 00:34:49.173676  4664 net.cpp:454] SoftmaxWithLoss1 <- Data2
I0702 00:34:49.173688  4664 net.cpp:411] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0702 00:34:49.173743  4664 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0702 00:34:49.173894  4664 net.cpp:150] Setting up SoftmaxWithLoss1
I0702 00:34:49.173909  4664 net.cpp:157] Top shape: (1)
I0702 00:34:49.173919  4664 net.cpp:160]     with loss weight 1
I0702 00:34:49.173959  4664 net.cpp:165] Memory required for data: 137766276
I0702 00:34:49.173969  4664 net.cpp:226] SoftmaxWithLoss1 needs backward computation.
I0702 00:34:49.173979  4664 net.cpp:226] InnerProduct1 needs backward computation.
I0702 00:34:49.173986  4664 net.cpp:226] Pooling1 needs backward computation.
I0702 00:34:49.174003  4664 net.cpp:226] ReLU19 needs backward computation.
I0702 00:34:49.174010  4664 net.cpp:226] Eltwise9 needs backward computation.
I0702 00:34:49.174017  4664 net.cpp:226] Scale21 needs backward computation.
I0702 00:34:49.174023  4664 net.cpp:226] BatchNorm21 needs backward computation.
I0702 00:34:49.174029  4664 net.cpp:226] Convolution21 needs backward computation.
I0702 00:34:49.174036  4664 net.cpp:226] ReLU18 needs backward computation.
I0702 00:34:49.174042  4664 net.cpp:226] Scale20 needs backward computation.
I0702 00:34:49.174049  4664 net.cpp:226] BatchNorm20 needs backward computation.
I0702 00:34:49.174055  4664 net.cpp:226] Convolution20 needs backward computation.
I0702 00:34:49.174062  4664 net.cpp:226] Eltwise8_ReLU17_0_split needs backward computation.
I0702 00:34:49.174068  4664 net.cpp:226] ReLU17 needs backward computation.
I0702 00:34:49.174075  4664 net.cpp:226] Eltwise8 needs backward computation.
I0702 00:34:49.174082  4664 net.cpp:226] Scale19 needs backward computation.
I0702 00:34:49.174088  4664 net.cpp:226] BatchNorm19 needs backward computation.
I0702 00:34:49.174094  4664 net.cpp:226] Convolution19 needs backward computation.
I0702 00:34:49.174101  4664 net.cpp:226] ReLU16 needs backward computation.
I0702 00:34:49.174108  4664 net.cpp:226] Scale18 needs backward computation.
I0702 00:34:49.174113  4664 net.cpp:226] BatchNorm18 needs backward computation.
I0702 00:34:49.174119  4664 net.cpp:226] Convolution18 needs backward computation.
I0702 00:34:49.174125  4664 net.cpp:226] Eltwise7_ReLU15_0_split needs backward computation.
I0702 00:34:49.174132  4664 net.cpp:226] ReLU15 needs backward computation.
I0702 00:34:49.174139  4664 net.cpp:226] Eltwise7 needs backward computation.
I0702 00:34:49.174145  4664 net.cpp:226] Scale17 needs backward computation.
I0702 00:34:49.174151  4664 net.cpp:226] BatchNorm17 needs backward computation.
I0702 00:34:49.174158  4664 net.cpp:226] Convolution17 needs backward computation.
I0702 00:34:49.174165  4664 net.cpp:226] ReLU14 needs backward computation.
I0702 00:34:49.174170  4664 net.cpp:226] Scale16 needs backward computation.
I0702 00:34:49.174176  4664 net.cpp:226] BatchNorm16 needs backward computation.
I0702 00:34:49.174182  4664 net.cpp:226] Convolution16 needs backward computation.
I0702 00:34:49.174190  4664 net.cpp:226] Scale15 needs backward computation.
I0702 00:34:49.174196  4664 net.cpp:226] BatchNorm15 needs backward computation.
I0702 00:34:49.174201  4664 net.cpp:226] Convolution15 needs backward computation.
I0702 00:34:49.174208  4664 net.cpp:226] Eltwise6_ReLU13_0_split needs backward computation.
I0702 00:34:49.174214  4664 net.cpp:226] ReLU13 needs backward computation.
I0702 00:34:49.174221  4664 net.cpp:226] Eltwise6 needs backward computation.
I0702 00:34:49.174227  4664 net.cpp:226] Scale14 needs backward computation.
I0702 00:34:49.174233  4664 net.cpp:226] BatchNorm14 needs backward computation.
I0702 00:34:49.174239  4664 net.cpp:226] Convolution14 needs backward computation.
I0702 00:34:49.174247  4664 net.cpp:226] ReLU12 needs backward computation.
I0702 00:34:49.174252  4664 net.cpp:226] Scale13 needs backward computation.
I0702 00:34:49.174258  4664 net.cpp:226] BatchNorm13 needs backward computation.
I0702 00:34:49.174264  4664 net.cpp:226] Convolution13 needs backward computation.
I0702 00:34:49.174273  4664 net.cpp:226] Eltwise5_ReLU11_0_split needs backward computation.
I0702 00:34:49.174280  4664 net.cpp:226] ReLU11 needs backward computation.
I0702 00:34:49.174286  4664 net.cpp:226] Eltwise5 needs backward computation.
I0702 00:34:49.174293  4664 net.cpp:226] Scale12 needs backward computation.
I0702 00:34:49.174299  4664 net.cpp:226] BatchNorm12 needs backward computation.
I0702 00:34:49.174305  4664 net.cpp:226] Convolution12 needs backward computation.
I0702 00:34:49.174312  4664 net.cpp:226] ReLU10 needs backward computation.
I0702 00:34:49.174319  4664 net.cpp:226] Scale11 needs backward computation.
I0702 00:34:49.174324  4664 net.cpp:226] BatchNorm11 needs backward computation.
I0702 00:34:49.174336  4664 net.cpp:226] Convolution11 needs backward computation.
I0702 00:34:49.174343  4664 net.cpp:226] Eltwise4_ReLU9_0_split needs backward computation.
I0702 00:34:49.174350  4664 net.cpp:226] ReLU9 needs backward computation.
I0702 00:34:49.174357  4664 net.cpp:226] Eltwise4 needs backward computation.
I0702 00:34:49.174365  4664 net.cpp:226] Scale10 needs backward computation.
I0702 00:34:49.174371  4664 net.cpp:226] BatchNorm10 needs backward computation.
I0702 00:34:49.174376  4664 net.cpp:226] Convolution10 needs backward computation.
I0702 00:34:49.174392  4664 net.cpp:226] ReLU8 needs backward computation.
I0702 00:34:49.174398  4664 net.cpp:226] Scale9 needs backward computation.
I0702 00:34:49.174404  4664 net.cpp:226] BatchNorm9 needs backward computation.
I0702 00:34:49.174410  4664 net.cpp:226] Convolution9 needs backward computation.
I0702 00:34:49.174417  4664 net.cpp:226] Scale8 needs backward computation.
I0702 00:34:49.174423  4664 net.cpp:226] BatchNorm8 needs backward computation.
I0702 00:34:49.174429  4664 net.cpp:226] Convolution8 needs backward computation.
I0702 00:34:49.174437  4664 net.cpp:226] Eltwise3_ReLU7_0_split needs backward computation.
I0702 00:34:49.174443  4664 net.cpp:226] ReLU7 needs backward computation.
I0702 00:34:49.174449  4664 net.cpp:226] Eltwise3 needs backward computation.
I0702 00:34:49.174456  4664 net.cpp:226] Scale7 needs backward computation.
I0702 00:34:49.174463  4664 net.cpp:226] BatchNorm7 needs backward computation.
I0702 00:34:49.174468  4664 net.cpp:226] Convolution7 needs backward computation.
I0702 00:34:49.174475  4664 net.cpp:226] ReLU6 needs backward computation.
I0702 00:34:49.174481  4664 net.cpp:226] Scale6 needs backward computation.
I0702 00:34:49.174487  4664 net.cpp:226] BatchNorm6 needs backward computation.
I0702 00:34:49.174492  4664 net.cpp:226] Convolution6 needs backward computation.
I0702 00:34:49.174499  4664 net.cpp:226] Eltwise2_ReLU5_0_split needs backward computation.
I0702 00:34:49.174505  4664 net.cpp:226] ReLU5 needs backward computation.
I0702 00:34:49.174512  4664 net.cpp:226] Eltwise2 needs backward computation.
I0702 00:34:49.174520  4664 net.cpp:226] Scale5 needs backward computation.
I0702 00:34:49.174525  4664 net.cpp:226] BatchNorm5 needs backward computation.
I0702 00:34:49.174531  4664 net.cpp:226] Convolution5 needs backward computation.
I0702 00:34:49.174537  4664 net.cpp:226] ReLU4 needs backward computation.
I0702 00:34:49.174543  4664 net.cpp:226] Scale4 needs backward computation.
I0702 00:34:49.174549  4664 net.cpp:226] BatchNorm4 needs backward computation.
I0702 00:34:49.174556  4664 net.cpp:226] Convolution4 needs backward computation.
I0702 00:34:49.174562  4664 net.cpp:226] Eltwise1_ReLU3_0_split needs backward computation.
I0702 00:34:49.174568  4664 net.cpp:226] ReLU3 needs backward computation.
I0702 00:34:49.174576  4664 net.cpp:226] Eltwise1 needs backward computation.
I0702 00:34:49.174582  4664 net.cpp:226] Scale3 needs backward computation.
I0702 00:34:49.174588  4664 net.cpp:226] BatchNorm3 needs backward computation.
I0702 00:34:49.174594  4664 net.cpp:226] Convolution3 needs backward computation.
I0702 00:34:49.174600  4664 net.cpp:226] ReLU2 needs backward computation.
I0702 00:34:49.174607  4664 net.cpp:226] Scale2 needs backward computation.
I0702 00:34:49.174613  4664 net.cpp:226] BatchNorm2 needs backward computation.
I0702 00:34:49.174619  4664 net.cpp:226] Convolution2 needs backward computation.
I0702 00:34:49.174626  4664 net.cpp:226] Convolution1_ReLU1_0_split needs backward computation.
I0702 00:34:49.174633  4664 net.cpp:226] ReLU1 needs backward computation.
I0702 00:34:49.174640  4664 net.cpp:226] Scale1 needs backward computation.
I0702 00:34:49.174646  4664 net.cpp:226] BatchNorm1 needs backward computation.
I0702 00:34:49.174652  4664 net.cpp:226] Convolution1 needs backward computation.
I0702 00:34:49.174659  4664 net.cpp:228] Data1 does not need backward computation.
I0702 00:34:49.174665  4664 net.cpp:270] This network produces output SoftmaxWithLoss1
I0702 00:34:49.174742  4664 net.cpp:283] Network initialization done.
I0702 00:34:49.178025  4664 solver.cpp:200] Creating test net (#0) specified by net file: res20_cifar_train_test.prototxt
I0702 00:34:49.178169  4664 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I0702 00:34:49.178247  4664 net.cpp:49] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "ImageData"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.0078125
    mirror: false
    crop_size: 32
    mean_value: 128
  }
  image_data_param {
    source: "/HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/test/label.txt"
    batch_size: 1
    shuffle: false
    new_height: 40
    new_width: 40
    is_color: true
    root_folder: "/HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/test/Img/"
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution9"
  top: "Convolution9"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Convolution10"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "Accuracy1"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "Accuracy1"
  include {
    phase: TEST
  }
}
I0702 00:34:49.153323 32261 layer_factory.hpp:77] Creating layer Data1
I0702 00:34:49.153354 32261 net.cpp:106] Creating Layer Data1
I0702 00:34:49.153367 32261 net.cpp:411] Data1 -> Data1
I0702 00:34:49.153386 32261 net.cpp:411] Data1 -> Data2
I0702 00:34:49.180150 32261 image_data_layer.cpp:49] 2 MPI_Barrier 0
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "Accuracy1"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "Accuracy1"
  include {
    phase: TEST
  }
}
I0702 00:34:49.155359 13010 layer_factory.hpp:77] Creating layer Data1
I0702 00:34:49.155395 13010 net.cpp:106] Creating Layer Data1
I0702 00:34:49.155419 13010 net.cpp:411] Data1 -> Data1
I0702 00:34:49.155443 13010 net.cpp:411] Data1 -> Data2
I0702 00:34:49.180841 13010 image_data_layer.cpp:49] 3 MPI_Barrier 0
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "Accuracy1"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "Accuracy1"
  include {
    phase: TEST
  }
}
I0702 00:34:49.155483 20914 layer_factory.hpp:77] Creating layer Data1
I0702 00:34:49.155517 20914 net.cpp:106] Creating Layer Data1
I0702 00:34:49.155534 20914 net.cpp:411] Data1 -> Data1
I0702 00:34:49.155552 20914 net.cpp:411] Data1 -> Data2
I0702 00:34:49.180472 20914 image_data_layer.cpp:49] 0 MPI_Barrier 0
I0702 00:34:49.180487 20914 image_data_layer.cpp:51] 0: Opening file /HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/test/label.txt
I0702 00:34:49.206130 20914 image_data_layer.cpp:58] List loaded
I0702 00:34:49.206457 20914 image_data_layer.cpp:49] 0 MPI_Barrier 1
I0702 00:34:49.215392 20914 image_data_layer.cpp:49] 0 MPI_Barrier 2
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution11"
  top: "Convolution11"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution12"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Eltwise5"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution16"
  top: "Convolution16"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Convolution17"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution18"
  top: "Convolution18"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution19"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution20"
  top: "Convolution20"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution21"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise9"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "Accuracy1"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "Data2"
  top: "Accuracy1"
  include {
    phase: TEST
  }
}
I0702 00:34:49.179849  4664 layer_factory.hpp:77] Creating layer Data1
I0702 00:34:49.179880  4664 net.cpp:106] Creating Layer Data1
I0702 00:34:49.179893  4664 net.cpp:411] Data1 -> Data1
I0702 00:34:49.179909  4664 net.cpp:411] Data1 -> Data2
I0702 00:34:49.179937  4664 image_data_layer.cpp:49] 1 MPI_Barrier 0
I0702 00:34:49.205925  4664 image_data_layer.cpp:49] 1 MPI_Barrier 1
I0702 00:34:49.205936  4664 image_data_layer.cpp:51] 1: Opening file /HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/test/label.txt
I0702 00:34:49.214501  4664 image_data_layer.cpp:58] List loaded
I0702 00:34:49.214861  4664 image_data_layer.cpp:49] 1 MPI_Barrier 2
I0702 00:34:49.224081 20914 image_data_layer.cpp:49] 0 MPI_Barrier 3
I0702 00:34:49.224092 20914 image_data_layer.cpp:69] 0: A total of 10000 images.
I0702 00:34:49.206136 32261 image_data_layer.cpp:49] 2 MPI_Barrier 1
I0702 00:34:49.215064 32261 image_data_layer.cpp:49] 2 MPI_Barrier 2
I0702 00:34:49.215075 32261 image_data_layer.cpp:51] 2: Opening file /HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/test/label.txt
I0702 00:34:49.223390 32261 image_data_layer.cpp:58] List loaded
I0702 00:34:49.223753 32261 image_data_layer.cpp:49] 2 MPI_Barrier 3
I0702 00:34:49.223773 32261 image_data_layer.cpp:69] 2: A total of 10000 images.
I0702 00:34:49.206827 13010 image_data_layer.cpp:49] 3 MPI_Barrier 1
I0702 00:34:49.215760 13010 image_data_layer.cpp:49] 3 MPI_Barrier 2
I0702 00:34:49.224439 13010 image_data_layer.cpp:49] 3 MPI_Barrier 3
I0702 00:34:49.224448 13010 image_data_layer.cpp:51] 3: Opening file /HOME/sysu_sc_ll/WORKSPACE/wenyp/0314/cifar-10/test/label.txt
I0702 00:34:49.233434 13010 image_data_layer.cpp:58] List loaded
I0702 00:34:49.233649 13010 image_data_layer.cpp:69] 3: A total of 10000 images.
I0702 00:34:49.223547  4664 image_data_layer.cpp:49] 1 MPI_Barrier 3
I0702 00:34:49.223561  4664 image_data_layer.cpp:69] 1: A total of 10000 images.
I0702 00:34:49.366333 20914 image_data_layer.cpp:96] output data size: 1,3,32,32
I0702 00:34:49.366406 20914 net.cpp:150] Setting up Data1
I0702 00:34:49.366422 20914 net.cpp:157] Top shape: 1 3 32 32 (3072)
I0702 00:34:49.366434 20914 net.cpp:157] Top shape: 1 (1)
I0702 00:34:49.365883  4664 image_data_layer.cpp:96] output data size: 1,3,32,32
I0702 00:34:49.366443 20914 net.cpp:165] Memory required for data: 12292
I0702 00:34:49.366452 20914 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0702 00:34:49.366483 20914 net.cpp:106] Creating Layer Data2_Data1_1_split
I0702 00:34:49.366492 20914 net.cpp:454] Data2_Data1_1_split <- Data2
I0702 00:34:49.365950  4664 net.cpp:150] Setting up Data1
I0702 00:34:49.366502 20914 net.cpp:411] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0702 00:34:49.366515 20914 net.cpp:411] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0702 00:34:49.366529 20914 net.cpp:150] Setting up Data2_Data1_1_split
I0702 00:34:49.366152 32261 image_data_layer.cpp:96] output data size: 1,3,32,32
I0702 00:34:49.365984  4664 net.cpp:157] Top shape: 1 3 32 32 (3072)
I0702 00:34:49.366536 20914 net.cpp:157] Top shape: 1 (1)
I0702 00:34:49.366221 32261 net.cpp:150] Setting up Data1
I0702 00:34:49.365998  4664 net.cpp:157] Top shape: 1 (1)
I0702 00:34:49.366545 20914 net.cpp:157] Top shape: 1 (1)
I0702 00:34:49.366554 20914 net.cpp:165] Memory required for data: 12300
I0702 00:34:49.366560 20914 layer_factory.hpp:77] Creating layer Convolution1
I0702 00:34:49.366577 20914 net.cpp:106] Creating Layer Convolution1
I0702 00:34:49.366014  4664 net.cpp:165] Memory required for data: 12292
I0702 00:34:49.366024  4664 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0702 00:34:49.366238 32261 net.cpp:157] Top shape: 1 3 32 32 (3072)
I0702 00:34:49.366037  4664 net.cpp:106] Creating Layer Data2_Data1_1_split
I0702 00:34:49.366585 20914 net.cpp:454] Convolution1 <- Data1
I0702 00:34:49.366595 20914 net.cpp:411] Convolution1 -> Convolution1
I0702 00:34:49.366044  4664 net.cpp:454] Data2_Data1_1_split <- Data2
I0702 00:34:49.366055  4664 net.cpp:411] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0702 00:34:49.366292 32261 net.cpp:157] Top shape: 1 (1)
I0702 00:34:49.366302 32261 net.cpp:165] Memory required for data: 12292
I0702 00:34:49.366310 32261 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0702 00:34:49.366324 32261 net.cpp:106] Creating Layer Data2_Data1_1_split
I0702 00:34:49.366070  4664 net.cpp:411] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0702 00:34:49.366084  4664 net.cpp:150] Setting up Data2_Data1_1_split
I0702 00:34:49.366092  4664 net.cpp:157] Top shape: 1 (1)
I0702 00:34:49.366700 20914 net.cpp:150] Setting up Convolution1
I0702 00:34:49.366106  4664 net.cpp:157] Top shape: 1 (1)
I0702 00:34:49.366113  4664 net.cpp:165] Memory required for data: 12300
I0702 00:34:49.366331 32261 net.cpp:454] Data2_Data1_1_split <- Data2
I0702 00:34:49.366119  4664 layer_factory.hpp:77] Creating layer Convolution1
I0702 00:34:49.366715 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.366732 20914 net.cpp:165] Memory required for data: 77836
I0702 00:34:49.366341 32261 net.cpp:411] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0702 00:34:49.366355 32261 net.cpp:411] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0702 00:34:49.366369 32261 net.cpp:150] Setting up Data2_Data1_1_split
I0702 00:34:49.366144  4664 net.cpp:106] Creating Layer Convolution1
I0702 00:34:49.366377 32261 net.cpp:157] Top shape: 1 (1)
I0702 00:34:49.366154  4664 net.cpp:454] Convolution1 <- Data1
I0702 00:34:49.366168  4664 net.cpp:411] Convolution1 -> Convolution1
I0702 00:34:49.366750 20914 layer_factory.hpp:77] Creating layer BatchNorm1
I0702 00:34:49.366760 20914 net.cpp:106] Creating Layer BatchNorm1
I0702 00:34:49.366767 20914 net.cpp:454] BatchNorm1 <- Convolution1
I0702 00:34:49.366386 32261 net.cpp:157] Top shape: 1 (1)
I0702 00:34:49.366780 20914 net.cpp:397] BatchNorm1 -> Convolution1 (in-place)
I0702 00:34:49.366394 32261 net.cpp:165] Memory required for data: 12300
I0702 00:34:49.366250  4664 net.cpp:150] Setting up Convolution1
I0702 00:34:49.366813 20914 net.cpp:150] Setting up BatchNorm1
I0702 00:34:49.366401 32261 layer_factory.hpp:77] Creating layer Convolution1
I0702 00:34:49.366823 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.366832 20914 net.cpp:165] Memory required for data: 143372
I0702 00:34:49.366425 32261 net.cpp:106] Creating Layer Convolution1
I0702 00:34:49.366852 20914 layer_factory.hpp:77] Creating layer Scale1
I0702 00:34:49.366436 32261 net.cpp:454] Convolution1 <- Data1
I0702 00:34:49.366262  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.366272  4664 net.cpp:165] Memory required for data: 77836
I0702 00:34:49.366864 20914 net.cpp:106] Creating Layer Scale1
I0702 00:34:49.366446 32261 net.cpp:411] Convolution1 -> Convolution1
I0702 00:34:49.366288  4664 layer_factory.hpp:77] Creating layer BatchNorm1
I0702 00:34:49.366871 20914 net.cpp:454] Scale1 <- Convolution1
I0702 00:34:49.366303  4664 net.cpp:106] Creating Layer BatchNorm1
I0702 00:34:49.366885 20914 net.cpp:397] Scale1 -> Convolution1 (in-place)
I0702 00:34:49.366310  4664 net.cpp:454] BatchNorm1 <- Convolution1
I0702 00:34:49.366909 20914 layer_factory.hpp:77] Creating layer Scale1
I0702 00:34:49.366542 32261 net.cpp:150] Setting up Convolution1
I0702 00:34:49.366554 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.366564 32261 net.cpp:165] Memory required for data: 77836
I0702 00:34:49.366320  4664 net.cpp:397] BatchNorm1 -> Convolution1 (in-place)
I0702 00:34:49.366348  4664 net.cpp:150] Setting up BatchNorm1
I0702 00:34:49.366356  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.366950 20914 net.cpp:150] Setting up Scale1
I0702 00:34:49.366365  4664 net.cpp:165] Memory required for data: 143372
I0702 00:34:49.366580 32261 layer_factory.hpp:77] Creating layer BatchNorm1
I0702 00:34:49.366382  4664 layer_factory.hpp:77] Creating layer Scale1
I0702 00:34:49.366961 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.366971 20914 net.cpp:165] Memory required for data: 208908
I0702 00:34:49.366592 32261 net.cpp:106] Creating Layer BatchNorm1
I0702 00:34:49.366399  4664 net.cpp:106] Creating Layer Scale1
I0702 00:34:49.366983 20914 layer_factory.hpp:77] Creating layer ReLU1
I0702 00:34:49.366602 32261 net.cpp:454] BatchNorm1 <- Convolution1
I0702 00:34:49.366407  4664 net.cpp:454] Scale1 <- Convolution1
I0702 00:34:49.367012 20914 net.cpp:106] Creating Layer ReLU1
I0702 00:34:49.366616 32261 net.cpp:397] BatchNorm1 -> Convolution1 (in-place)
I0702 00:34:49.367022 20914 net.cpp:454] ReLU1 <- Convolution1
I0702 00:34:49.367031 20914 net.cpp:397] ReLU1 -> Convolution1 (in-place)
I0702 00:34:49.367043 20914 net.cpp:150] Setting up ReLU1
I0702 00:34:49.366416  4664 net.cpp:397] Scale1 -> Convolution1 (in-place)
I0702 00:34:49.367049 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.366434  4664 layer_factory.hpp:77] Creating layer Scale1
I0702 00:34:49.367058 20914 net.cpp:165] Memory required for data: 274444
I0702 00:34:49.366644 32261 net.cpp:150] Setting up BatchNorm1
I0702 00:34:49.366469  4664 net.cpp:150] Setting up Scale1
I0702 00:34:49.367065 20914 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0702 00:34:49.366653 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.366663 32261 net.cpp:165] Memory required for data: 143372
I0702 00:34:49.366479  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.366488  4664 net.cpp:165] Memory required for data: 208908
I0702 00:34:49.366680 32261 layer_factory.hpp:77] Creating layer Scale1
I0702 00:34:49.366500  4664 layer_factory.hpp:77] Creating layer ReLU1
I0702 00:34:49.367086 20914 net.cpp:106] Creating Layer Convolution1_ReLU1_0_split
I0702 00:34:49.366696 32261 net.cpp:106] Creating Layer Scale1
I0702 00:34:49.366509  4664 net.cpp:106] Creating Layer ReLU1
I0702 00:34:49.366705 32261 net.cpp:454] Scale1 <- Convolution1
I0702 00:34:49.366516  4664 net.cpp:454] ReLU1 <- Convolution1
I0702 00:34:49.367094 20914 net.cpp:454] Convolution1_ReLU1_0_split <- Convolution1
I0702 00:34:49.367103 20914 net.cpp:411] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0702 00:34:49.367115 20914 net.cpp:411] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0702 00:34:49.367128 20914 net.cpp:150] Setting up Convolution1_ReLU1_0_split
I0702 00:34:49.366716 32261 net.cpp:397] Scale1 -> Convolution1 (in-place)
I0702 00:34:49.367135 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367144 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.366735 32261 layer_factory.hpp:77] Creating layer Scale1
I0702 00:34:49.366528  4664 net.cpp:397] ReLU1 -> Convolution1 (in-place)
I0702 00:34:49.366539  4664 net.cpp:150] Setting up ReLU1
I0702 00:34:49.367151 20914 net.cpp:165] Memory required for data: 405516
I0702 00:34:49.367158 20914 layer_factory.hpp:77] Creating layer Convolution2
I0702 00:34:49.366544  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367183 20914 net.cpp:106] Creating Layer Convolution2
I0702 00:34:49.367194 20914 net.cpp:454] Convolution2 <- Convolution1_ReLU1_0_split_0
I0702 00:34:49.366554  4664 net.cpp:165] Memory required for data: 274444
I0702 00:34:49.367206 20914 net.cpp:411] Convolution2 -> Convolution2
I0702 00:34:49.366770 32261 net.cpp:150] Setting up Scale1
I0702 00:34:49.366559  4664 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0702 00:34:49.366780 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.366578  4664 net.cpp:106] Creating Layer Convolution1_ReLU1_0_split
I0702 00:34:49.366789 32261 net.cpp:165] Memory required for data: 208908
I0702 00:34:49.366585  4664 net.cpp:454] Convolution1_ReLU1_0_split <- Convolution1
I0702 00:34:49.366801 32261 layer_factory.hpp:77] Creating layer ReLU1
I0702 00:34:49.366595  4664 net.cpp:411] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0702 00:34:49.366813 32261 net.cpp:106] Creating Layer ReLU1
I0702 00:34:49.366607  4664 net.cpp:411] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0702 00:34:49.366822 32261 net.cpp:454] ReLU1 <- Convolution1
I0702 00:34:49.366619  4664 net.cpp:150] Setting up Convolution1_ReLU1_0_split
I0702 00:34:49.366829 32261 net.cpp:397] ReLU1 -> Convolution1 (in-place)
I0702 00:34:49.366840 32261 net.cpp:150] Setting up ReLU1
I0702 00:34:49.366847 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.366855 32261 net.cpp:165] Memory required for data: 274444
I0702 00:34:49.366861 32261 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0702 00:34:49.366628  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.366883 32261 net.cpp:106] Creating Layer Convolution1_ReLU1_0_split
I0702 00:34:49.366637  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.366889 32261 net.cpp:454] Convolution1_ReLU1_0_split <- Convolution1
I0702 00:34:49.366645  4664 net.cpp:165] Memory required for data: 405516
I0702 00:34:49.366652  4664 layer_factory.hpp:77] Creating layer Convolution2
I0702 00:34:49.366900 32261 net.cpp:411] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0702 00:34:49.366672  4664 net.cpp:106] Creating Layer Convolution2
I0702 00:34:49.366680  4664 net.cpp:454] Convolution2 <- Convolution1_ReLU1_0_split_0
I0702 00:34:49.366691  4664 net.cpp:411] Convolution2 -> Convolution2
I0702 00:34:49.367362 20914 net.cpp:150] Setting up Convolution2
I0702 00:34:49.366914 32261 net.cpp:411] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0702 00:34:49.366829  4664 net.cpp:150] Setting up Convolution2
I0702 00:34:49.366928 32261 net.cpp:150] Setting up Convolution1_ReLU1_0_split
I0702 00:34:49.367377 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367388 20914 net.cpp:165] Memory required for data: 471052
I0702 00:34:49.367401 20914 layer_factory.hpp:77] Creating layer BatchNorm2
I0702 00:34:49.366935 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.366945 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.366843  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.366951 32261 net.cpp:165] Memory required for data: 405516
I0702 00:34:49.366853  4664 net.cpp:165] Memory required for data: 471052
I0702 00:34:49.367416 20914 net.cpp:106] Creating Layer BatchNorm2
I0702 00:34:49.367424 20914 net.cpp:454] BatchNorm2 <- Convolution2
I0702 00:34:49.366958 32261 layer_factory.hpp:77] Creating layer Convolution2
I0702 00:34:49.367439 20914 net.cpp:397] BatchNorm2 -> Convolution2 (in-place)
I0702 00:34:49.366976 32261 net.cpp:106] Creating Layer Convolution2
I0702 00:34:49.366986 32261 net.cpp:454] Convolution2 <- Convolution1_ReLU1_0_split_0
I0702 00:34:49.366868  4664 layer_factory.hpp:77] Creating layer BatchNorm2
I0702 00:34:49.366997 32261 net.cpp:411] Convolution2 -> Convolution2
I0702 00:34:49.366883  4664 net.cpp:106] Creating Layer BatchNorm2
I0702 00:34:49.366890  4664 net.cpp:454] BatchNorm2 <- Convolution2
I0702 00:34:49.367471 20914 net.cpp:150] Setting up BatchNorm2
I0702 00:34:49.366900  4664 net.cpp:397] BatchNorm2 -> Convolution2 (in-place)
I0702 00:34:49.367481 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367491 20914 net.cpp:165] Memory required for data: 536588
I0702 00:34:49.367127 32261 net.cpp:150] Setting up Convolution2
I0702 00:34:49.367141 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.366931  4664 net.cpp:150] Setting up BatchNorm2
I0702 00:34:49.366943  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367504 20914 layer_factory.hpp:77] Creating layer Scale2
I0702 00:34:49.367149 32261 net.cpp:165] Memory required for data: 471052
I0702 00:34:49.366958  4664 net.cpp:165] Memory required for data: 536588
I0702 00:34:49.367163 32261 layer_factory.hpp:77] Creating layer BatchNorm2
I0702 00:34:49.366976  4664 layer_factory.hpp:77] Creating layer Scale2
I0702 00:34:49.367521 20914 net.cpp:106] Creating Layer Scale2
I0702 00:34:49.367529 20914 net.cpp:454] Scale2 <- Convolution2
I0702 00:34:49.367539 20914 net.cpp:397] Scale2 -> Convolution2 (in-place)
I0702 00:34:49.367559 20914 layer_factory.hpp:77] Creating layer Scale2
I0702 00:34:49.367858 13010 image_data_layer.cpp:96] output data size: 1,3,32,32
I0702 00:34:49.367180 32261 net.cpp:106] Creating Layer BatchNorm2
I0702 00:34:49.366986  4664 net.cpp:106] Creating Layer Scale2
I0702 00:34:49.367189 32261 net.cpp:454] BatchNorm2 <- Convolution2
I0702 00:34:49.366993  4664 net.cpp:454] Scale2 <- Convolution2
I0702 00:34:49.367594 20914 net.cpp:150] Setting up Scale2
I0702 00:34:49.367606 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367202 32261 net.cpp:397] BatchNorm2 -> Convolution2 (in-place)
I0702 00:34:49.367008  4664 net.cpp:397] Scale2 -> Convolution2 (in-place)
I0702 00:34:49.367225 32261 net.cpp:150] Setting up BatchNorm2
I0702 00:34:49.367029  4664 layer_factory.hpp:77] Creating layer Scale2
I0702 00:34:49.367616 20914 net.cpp:165] Memory required for data: 602124
I0702 00:34:49.367234 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367933 13010 net.cpp:150] Setting up Data1
I0702 00:34:49.367244 32261 net.cpp:165] Memory required for data: 536588
I0702 00:34:49.367070  4664 net.cpp:150] Setting up Scale2
I0702 00:34:49.367949 13010 net.cpp:157] Top shape: 1 3 32 32 (3072)
I0702 00:34:49.367630 20914 layer_factory.hpp:77] Creating layer ReLU2
I0702 00:34:49.367638 20914 net.cpp:106] Creating Layer ReLU2
I0702 00:34:49.367082  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367959 13010 net.cpp:157] Top shape: 1 (1)
I0702 00:34:49.367645 20914 net.cpp:454] ReLU2 <- Convolution2
I0702 00:34:49.367657 20914 net.cpp:397] ReLU2 -> Convolution2 (in-place)
I0702 00:34:49.367668 20914 net.cpp:150] Setting up ReLU2
I0702 00:34:49.367266 32261 layer_factory.hpp:77] Creating layer Scale2
I0702 00:34:49.367092  4664 net.cpp:165] Memory required for data: 602124
I0702 00:34:49.367969 13010 net.cpp:165] Memory required for data: 12292
I0702 00:34:49.367676 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367683 20914 net.cpp:165] Memory required for data: 667660
I0702 00:34:49.367691 20914 layer_factory.hpp:77] Creating layer Convolution3
I0702 00:34:49.367280 32261 net.cpp:106] Creating Layer Scale2
I0702 00:34:49.367105  4664 layer_factory.hpp:77] Creating layer ReLU2
I0702 00:34:49.367712 20914 net.cpp:106] Creating Layer Convolution3
I0702 00:34:49.367724 20914 net.cpp:454] Convolution3 <- Convolution2
I0702 00:34:49.367288 32261 net.cpp:454] Scale2 <- Convolution2
I0702 00:34:49.367115  4664 net.cpp:106] Creating Layer ReLU2
I0702 00:34:49.367736 20914 net.cpp:411] Convolution3 -> Convolution3
I0702 00:34:49.367296 32261 net.cpp:397] Scale2 -> Convolution2 (in-place)
I0702 00:34:49.367121  4664 net.cpp:454] ReLU2 <- Convolution2
I0702 00:34:49.367314 32261 layer_factory.hpp:77] Creating layer Scale2
I0702 00:34:49.367977 13010 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I0702 00:34:49.367348 32261 net.cpp:150] Setting up Scale2
I0702 00:34:49.368010 13010 net.cpp:106] Creating Layer Data2_Data1_1_split
I0702 00:34:49.368018 13010 net.cpp:454] Data2_Data1_1_split <- Data2
I0702 00:34:49.367358 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368028 13010 net.cpp:411] Data2_Data1_1_split -> Data2_Data1_1_split_0
I0702 00:34:49.368044 13010 net.cpp:411] Data2_Data1_1_split -> Data2_Data1_1_split_1
I0702 00:34:49.367130  4664 net.cpp:397] ReLU2 -> Convolution2 (in-place)
I0702 00:34:49.368058 13010 net.cpp:150] Setting up Data2_Data1_1_split
I0702 00:34:49.367139  4664 net.cpp:150] Setting up ReLU2
I0702 00:34:49.367146  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367154  4664 net.cpp:165] Memory required for data: 667660
I0702 00:34:49.368067 13010 net.cpp:157] Top shape: 1 (1)
I0702 00:34:49.367367 32261 net.cpp:165] Memory required for data: 602124
I0702 00:34:49.367161  4664 layer_factory.hpp:77] Creating layer Convolution3
I0702 00:34:49.368077 13010 net.cpp:157] Top shape: 1 (1)
I0702 00:34:49.367379 32261 layer_factory.hpp:77] Creating layer ReLU2
I0702 00:34:49.367183  4664 net.cpp:106] Creating Layer Convolution3
I0702 00:34:49.368084 13010 net.cpp:165] Memory required for data: 12300
I0702 00:34:49.367388 32261 net.cpp:106] Creating Layer ReLU2
I0702 00:34:49.367195  4664 net.cpp:454] Convolution3 <- Convolution2
I0702 00:34:49.368090 13010 layer_factory.hpp:77] Creating layer Convolution1
I0702 00:34:49.367394 32261 net.cpp:454] ReLU2 <- Convolution2
I0702 00:34:49.367210  4664 net.cpp:411] Convolution3 -> Convolution3
I0702 00:34:49.368108 13010 net.cpp:106] Creating Layer Convolution1
I0702 00:34:49.367406 32261 net.cpp:397] ReLU2 -> Convolution2 (in-place)
I0702 00:34:49.368116 13010 net.cpp:454] Convolution1 <- Data1
I0702 00:34:49.367416 32261 net.cpp:150] Setting up ReLU2
I0702 00:34:49.367424 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367431 32261 net.cpp:165] Memory required for data: 667660
I0702 00:34:49.367437 32261 layer_factory.hpp:77] Creating layer Convolution3
I0702 00:34:49.367455 32261 net.cpp:106] Creating Layer Convolution3
I0702 00:34:49.367465 32261 net.cpp:454] Convolution3 <- Convolution2
I0702 00:34:49.367341  4664 net.cpp:150] Setting up Convolution3
I0702 00:34:49.368127 13010 net.cpp:411] Convolution1 -> Convolution1
I0702 00:34:49.367877 20914 net.cpp:150] Setting up Convolution3
I0702 00:34:49.367478 32261 net.cpp:411] Convolution3 -> Convolution3
I0702 00:34:49.367895 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367907 20914 net.cpp:165] Memory required for data: 733196
I0702 00:34:49.367354  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368252 13010 net.cpp:150] Setting up Convolution1
I0702 00:34:49.367370  4664 net.cpp:165] Memory required for data: 733196
I0702 00:34:49.368270 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367605 32261 net.cpp:150] Setting up Convolution3
I0702 00:34:49.368280 13010 net.cpp:165] Memory required for data: 77836
I0702 00:34:49.367918 20914 layer_factory.hpp:77] Creating layer BatchNorm3
I0702 00:34:49.367383  4664 layer_factory.hpp:77] Creating layer BatchNorm3
I0702 00:34:49.367617 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367394  4664 net.cpp:106] Creating Layer BatchNorm3
I0702 00:34:49.367401  4664 net.cpp:454] BatchNorm3 <- Convolution3
I0702 00:34:49.368295 13010 layer_factory.hpp:77] Creating layer BatchNorm1
I0702 00:34:49.367626 32261 net.cpp:165] Memory required for data: 733196
I0702 00:34:49.367413  4664 net.cpp:397] BatchNorm3 -> Convolution3 (in-place)
I0702 00:34:49.368309 13010 net.cpp:106] Creating Layer BatchNorm1
I0702 00:34:49.367933 20914 net.cpp:106] Creating Layer BatchNorm3
I0702 00:34:49.367939 20914 net.cpp:454] BatchNorm3 <- Convolution3
I0702 00:34:49.367949 20914 net.cpp:397] BatchNorm3 -> Convolution3 (in-place)
I0702 00:34:49.367638 32261 layer_factory.hpp:77] Creating layer BatchNorm3
I0702 00:34:49.368316 13010 net.cpp:454] BatchNorm1 <- Convolution1
I0702 00:34:49.367979 20914 net.cpp:150] Setting up BatchNorm3
I0702 00:34:49.367987 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367996 20914 net.cpp:165] Memory required for data: 798732
I0702 00:34:49.367650 32261 net.cpp:106] Creating Layer BatchNorm3
I0702 00:34:49.367439  4664 net.cpp:150] Setting up BatchNorm3
I0702 00:34:49.367450  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368331 13010 net.cpp:397] BatchNorm1 -> Convolution1 (in-place)
I0702 00:34:49.368013 20914 layer_factory.hpp:77] Creating layer Scale3
I0702 00:34:49.367656 32261 net.cpp:454] BatchNorm3 <- Convolution3
I0702 00:34:49.367460  4664 net.cpp:165] Memory required for data: 798732
I0702 00:34:49.368041 20914 net.cpp:106] Creating Layer Scale3
I0702 00:34:49.367480  4664 layer_factory.hpp:77] Creating layer Scale3
I0702 00:34:49.368369 13010 net.cpp:150] Setting up BatchNorm1
I0702 00:34:49.368050 20914 net.cpp:454] Scale3 <- Convolution3
I0702 00:34:49.368381 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368060 20914 net.cpp:397] Scale3 -> Convolution3 (in-place)
I0702 00:34:49.367668 32261 net.cpp:397] BatchNorm3 -> Convolution3 (in-place)
I0702 00:34:49.368391 13010 net.cpp:165] Memory required for data: 143372
I0702 00:34:49.368077 20914 layer_factory.hpp:77] Creating layer Scale3
I0702 00:34:49.367697 32261 net.cpp:150] Setting up BatchNorm3
I0702 00:34:49.367492  4664 net.cpp:106] Creating Layer Scale3
I0702 00:34:49.368423 13010 layer_factory.hpp:77] Creating layer Scale1
I0702 00:34:49.367705 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367499  4664 net.cpp:454] Scale3 <- Convolution3
I0702 00:34:49.368131 20914 net.cpp:150] Setting up Scale3
I0702 00:34:49.367717 32261 net.cpp:165] Memory required for data: 798732
I0702 00:34:49.367512  4664 net.cpp:397] Scale3 -> Convolution3 (in-place)
I0702 00:34:49.367734 32261 layer_factory.hpp:77] Creating layer Scale3
I0702 00:34:49.367532  4664 layer_factory.hpp:77] Creating layer Scale3
I0702 00:34:49.368441 13010 net.cpp:106] Creating Layer Scale1
I0702 00:34:49.367749 32261 net.cpp:106] Creating Layer Scale3
I0702 00:34:49.368450 13010 net.cpp:454] Scale1 <- Convolution1
I0702 00:34:49.367758 32261 net.cpp:454] Scale3 <- Convolution3
I0702 00:34:49.368463 13010 net.cpp:397] Scale1 -> Convolution1 (in-place)
I0702 00:34:49.367581  4664 net.cpp:150] Setting up Scale3
I0702 00:34:49.368484 13010 layer_factory.hpp:77] Creating layer Scale1
I0702 00:34:49.368144 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368154 20914 net.cpp:165] Memory required for data: 864268
I0702 00:34:49.368165 20914 layer_factory.hpp:77] Creating layer Eltwise1
I0702 00:34:49.368175 20914 net.cpp:106] Creating Layer Eltwise1
I0702 00:34:49.367594  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367766 32261 net.cpp:397] Scale3 -> Convolution3 (in-place)
I0702 00:34:49.367609  4664 net.cpp:165] Memory required for data: 864268
I0702 00:34:49.367782 32261 layer_factory.hpp:77] Creating layer Scale3
I0702 00:34:49.367621  4664 layer_factory.hpp:77] Creating layer Eltwise1
I0702 00:34:49.368521 13010 net.cpp:150] Setting up Scale1
I0702 00:34:49.368182 20914 net.cpp:454] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0702 00:34:49.368191 20914 net.cpp:454] Eltwise1 <- Convolution3
I0702 00:34:49.367827 32261 net.cpp:150] Setting up Scale3
I0702 00:34:49.367633  4664 net.cpp:106] Creating Layer Eltwise1
I0702 00:34:49.368533 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368199 20914 net.cpp:411] Eltwise1 -> Eltwise1
I0702 00:34:49.368213 20914 net.cpp:150] Setting up Eltwise1
I0702 00:34:49.367838 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367641  4664 net.cpp:454] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0702 00:34:49.368542 13010 net.cpp:165] Memory required for data: 208908
I0702 00:34:49.368227 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368235 20914 net.cpp:165] Memory required for data: 929804
I0702 00:34:49.368242 20914 layer_factory.hpp:77] Creating layer ReLU3
I0702 00:34:49.368252 20914 net.cpp:106] Creating Layer ReLU3
I0702 00:34:49.367847 32261 net.cpp:165] Memory required for data: 864268
I0702 00:34:49.367648  4664 net.cpp:454] Eltwise1 <- Convolution3
I0702 00:34:49.368558 13010 layer_factory.hpp:77] Creating layer ReLU1
I0702 00:34:49.368258 20914 net.cpp:454] ReLU3 <- Eltwise1
I0702 00:34:49.367859 32261 layer_factory.hpp:77] Creating layer Eltwise1
I0702 00:34:49.368569 13010 net.cpp:106] Creating Layer ReLU1
I0702 00:34:49.368268 20914 net.cpp:397] ReLU3 -> Eltwise1 (in-place)
I0702 00:34:49.367871 32261 net.cpp:106] Creating Layer Eltwise1
I0702 00:34:49.368577 13010 net.cpp:454] ReLU1 <- Convolution1
I0702 00:34:49.368278 20914 net.cpp:150] Setting up ReLU3
I0702 00:34:49.367658  4664 net.cpp:411] Eltwise1 -> Eltwise1
I0702 00:34:49.367671  4664 net.cpp:150] Setting up Eltwise1
I0702 00:34:49.368284 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367679  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368293 20914 net.cpp:165] Memory required for data: 995340
I0702 00:34:49.367877 32261 net.cpp:454] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0702 00:34:49.367687  4664 net.cpp:165] Memory required for data: 929804
I0702 00:34:49.367693  4664 layer_factory.hpp:77] Creating layer ReLU3
I0702 00:34:49.368585 13010 net.cpp:397] ReLU1 -> Convolution1 (in-place)
I0702 00:34:49.368299 20914 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0702 00:34:49.367885 32261 net.cpp:454] Eltwise1 <- Convolution3
I0702 00:34:49.367702  4664 net.cpp:106] Creating Layer ReLU3
I0702 00:34:49.368597 13010 net.cpp:150] Setting up ReLU1
I0702 00:34:49.368315 20914 net.cpp:106] Creating Layer Eltwise1_ReLU3_0_split
I0702 00:34:49.368324 20914 net.cpp:454] Eltwise1_ReLU3_0_split <- Eltwise1
I0702 00:34:49.368333 20914 net.cpp:411] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0702 00:34:49.367897 32261 net.cpp:411] Eltwise1 -> Eltwise1
I0702 00:34:49.367709  4664 net.cpp:454] ReLU3 <- Eltwise1
I0702 00:34:49.368602 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368345 20914 net.cpp:411] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0702 00:34:49.367911 32261 net.cpp:150] Setting up Eltwise1
I0702 00:34:49.367717  4664 net.cpp:397] ReLU3 -> Eltwise1 (in-place)
I0702 00:34:49.368611 13010 net.cpp:165] Memory required for data: 274444
I0702 00:34:49.368357 20914 net.cpp:150] Setting up Eltwise1_ReLU3_0_split
I0702 00:34:49.368363 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367919 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367727  4664 net.cpp:150] Setting up ReLU3
I0702 00:34:49.368618 13010 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I0702 00:34:49.368372 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368381 20914 net.cpp:165] Memory required for data: 1126412
I0702 00:34:49.367928 32261 net.cpp:165] Memory required for data: 929804
I0702 00:34:49.367733  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368638 13010 net.cpp:106] Creating Layer Convolution1_ReLU1_0_split
I0702 00:34:49.368387 20914 layer_factory.hpp:77] Creating layer Convolution4
I0702 00:34:49.367935 32261 layer_factory.hpp:77] Creating layer ReLU3
I0702 00:34:49.367741  4664 net.cpp:165] Memory required for data: 995340
I0702 00:34:49.368646 13010 net.cpp:454] Convolution1_ReLU1_0_split <- Convolution1
I0702 00:34:49.367944 32261 net.cpp:106] Creating Layer ReLU3
I0702 00:34:49.367748  4664 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0702 00:34:49.368661 13010 net.cpp:411] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I0702 00:34:49.367950 32261 net.cpp:454] ReLU3 <- Eltwise1
I0702 00:34:49.368679 13010 net.cpp:411] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I0702 00:34:49.367959 32261 net.cpp:397] ReLU3 -> Eltwise1 (in-place)
I0702 00:34:49.368692 13010 net.cpp:150] Setting up Convolution1_ReLU1_0_split
I0702 00:34:49.367969 32261 net.cpp:150] Setting up ReLU3
I0702 00:34:49.368700 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368412 20914 net.cpp:106] Creating Layer Convolution4
I0702 00:34:49.368424 20914 net.cpp:454] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0702 00:34:49.368436 20914 net.cpp:411] Convolution4 -> Convolution4
I0702 00:34:49.367975 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367983 32261 net.cpp:165] Memory required for data: 995340
I0702 00:34:49.367764  4664 net.cpp:106] Creating Layer Eltwise1_ReLU3_0_split
I0702 00:34:49.367990 32261 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0702 00:34:49.367774  4664 net.cpp:454] Eltwise1_ReLU3_0_split <- Eltwise1
I0702 00:34:49.368710 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368000 32261 net.cpp:106] Creating Layer Eltwise1_ReLU3_0_split
I0702 00:34:49.367784  4664 net.cpp:411] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0702 00:34:49.367795  4664 net.cpp:411] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0702 00:34:49.368717 13010 net.cpp:165] Memory required for data: 405516
I0702 00:34:49.368006 32261 net.cpp:454] Eltwise1_ReLU3_0_split <- Eltwise1
I0702 00:34:49.367807  4664 net.cpp:150] Setting up Eltwise1_ReLU3_0_split
I0702 00:34:49.368724 13010 layer_factory.hpp:77] Creating layer Convolution2
I0702 00:34:49.367815  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368746 13010 net.cpp:106] Creating Layer Convolution2
I0702 00:34:49.367823  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368757 13010 net.cpp:454] Convolution2 <- Convolution1_ReLU1_0_split_0
I0702 00:34:49.367831  4664 net.cpp:165] Memory required for data: 1126412
I0702 00:34:49.368769 13010 net.cpp:411] Convolution2 -> Convolution2
I0702 00:34:49.368016 32261 net.cpp:411] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0702 00:34:49.367838  4664 layer_factory.hpp:77] Creating layer Convolution4
I0702 00:34:49.368026 32261 net.cpp:411] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0702 00:34:49.367861  4664 net.cpp:106] Creating Layer Convolution4
I0702 00:34:49.368036 32261 net.cpp:150] Setting up Eltwise1_ReLU3_0_split
I0702 00:34:49.367873  4664 net.cpp:454] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0702 00:34:49.368043 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.367884  4664 net.cpp:411] Convolution4 -> Convolution4
I0702 00:34:49.368902 13010 net.cpp:150] Setting up Convolution2
I0702 00:34:49.368057 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368916 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368064 32261 net.cpp:165] Memory required for data: 1126412
I0702 00:34:49.368926 13010 net.cpp:165] Memory required for data: 471052
I0702 00:34:49.368072 32261 layer_factory.hpp:77] Creating layer Convolution4
I0702 00:34:49.368017  4664 net.cpp:150] Setting up Convolution4
I0702 00:34:49.368088 32261 net.cpp:106] Creating Layer Convolution4
I0702 00:34:49.368031  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368098 32261 net.cpp:454] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0702 00:34:49.368048  4664 net.cpp:165] Memory required for data: 1191948
I0702 00:34:49.368111 32261 net.cpp:411] Convolution4 -> Convolution4
I0702 00:34:49.368062  4664 layer_factory.hpp:77] Creating layer BatchNorm4
I0702 00:34:49.368940 13010 layer_factory.hpp:77] Creating layer BatchNorm2
I0702 00:34:49.368573 20914 net.cpp:150] Setting up Convolution4
I0702 00:34:49.368588 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368603 20914 net.cpp:165] Memory required for data: 1191948
I0702 00:34:49.368959 13010 net.cpp:106] Creating Layer BatchNorm2
I0702 00:34:49.368616 20914 layer_factory.hpp:77] Creating layer BatchNorm4
I0702 00:34:49.368630 20914 net.cpp:106] Creating Layer BatchNorm4
I0702 00:34:49.368237 32261 net.cpp:150] Setting up Convolution4
I0702 00:34:49.368074  4664 net.cpp:106] Creating Layer BatchNorm4
I0702 00:34:49.368082  4664 net.cpp:454] BatchNorm4 <- Convolution4
I0702 00:34:49.368970 13010 net.cpp:454] BatchNorm2 <- Convolution2
I0702 00:34:49.368638 20914 net.cpp:454] BatchNorm4 <- Convolution4
I0702 00:34:49.368646 20914 net.cpp:397] BatchNorm4 -> Convolution4 (in-place)
I0702 00:34:49.368248 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368093  4664 net.cpp:397] BatchNorm4 -> Convolution4 (in-place)
I0702 00:34:49.368983 13010 net.cpp:397] BatchNorm2 -> Convolution2 (in-place)
I0702 00:34:49.368674 20914 net.cpp:150] Setting up BatchNorm4
I0702 00:34:49.368682 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368691 20914 net.cpp:165] Memory required for data: 1257484
I0702 00:34:49.368265 32261 net.cpp:165] Memory required for data: 1191948
I0702 00:34:49.368708 20914 layer_factory.hpp:77] Creating layer Scale4
I0702 00:34:49.368278 32261 layer_factory.hpp:77] Creating layer BatchNorm4
I0702 00:34:49.368119  4664 net.cpp:150] Setting up BatchNorm4
I0702 00:34:49.368722 20914 net.cpp:106] Creating Layer Scale4
I0702 00:34:49.368289 32261 net.cpp:106] Creating Layer BatchNorm4
I0702 00:34:49.368129  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368139  4664 net.cpp:165] Memory required for data: 1257484
I0702 00:34:49.369010 13010 net.cpp:150] Setting up BatchNorm2
I0702 00:34:49.368729 20914 net.cpp:454] Scale4 <- Convolution4
I0702 00:34:49.368296 32261 net.cpp:454] BatchNorm4 <- Convolution4
I0702 00:34:49.368155  4664 layer_factory.hpp:77] Creating layer Scale4
I0702 00:34:49.369021 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368738 20914 net.cpp:397] Scale4 -> Convolution4 (in-place)
I0702 00:34:49.368307 32261 net.cpp:397] BatchNorm4 -> Convolution4 (in-place)
I0702 00:34:49.368166  4664 net.cpp:106] Creating Layer Scale4
I0702 00:34:49.369030 13010 net.cpp:165] Memory required for data: 536588
I0702 00:34:49.368772 20914 layer_factory.hpp:77] Creating layer Scale4
I0702 00:34:49.368173  4664 net.cpp:454] Scale4 <- Convolution4
I0702 00:34:49.369047 13010 layer_factory.hpp:77] Creating layer Scale2
I0702 00:34:49.368182  4664 net.cpp:397] Scale4 -> Convolution4 (in-place)
I0702 00:34:49.369060 13010 net.cpp:106] Creating Layer Scale2
I0702 00:34:49.368337 32261 net.cpp:150] Setting up BatchNorm4
I0702 00:34:49.369068 13010 net.cpp:454] Scale2 <- Convolution2
I0702 00:34:49.368346 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369077 13010 net.cpp:397] Scale2 -> Convolution2 (in-place)
I0702 00:34:49.368818 20914 net.cpp:150] Setting up Scale4
I0702 00:34:49.368357 32261 net.cpp:165] Memory required for data: 1257484
I0702 00:34:49.369094 13010 layer_factory.hpp:77] Creating layer Scale2
I0702 00:34:49.368829 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368839 20914 net.cpp:165] Memory required for data: 1323020
I0702 00:34:49.368371 32261 layer_factory.hpp:77] Creating layer Scale4
I0702 00:34:49.368198  4664 layer_factory.hpp:77] Creating layer Scale4
I0702 00:34:49.368850 20914 layer_factory.hpp:77] Creating layer ReLU4
I0702 00:34:49.368865 20914 net.cpp:106] Creating Layer ReLU4
I0702 00:34:49.368384 32261 net.cpp:106] Creating Layer Scale4
I0702 00:34:49.368237  4664 net.cpp:150] Setting up Scale4
I0702 00:34:49.368875 20914 net.cpp:454] ReLU4 <- Convolution4
I0702 00:34:49.368885 20914 net.cpp:397] ReLU4 -> Convolution4 (in-place)
I0702 00:34:49.368391 32261 net.cpp:454] Scale4 <- Convolution4
I0702 00:34:49.368248  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368894 20914 net.cpp:150] Setting up ReLU4
I0702 00:34:49.368402 32261 net.cpp:397] Scale4 -> Convolution4 (in-place)
I0702 00:34:49.368257  4664 net.cpp:165] Memory required for data: 1323020
I0702 00:34:49.368901 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368911 20914 net.cpp:165] Memory required for data: 1388556
I0702 00:34:49.368916 20914 layer_factory.hpp:77] Creating layer Convolution5
I0702 00:34:49.368420 32261 layer_factory.hpp:77] Creating layer Scale4
I0702 00:34:49.368269  4664 layer_factory.hpp:77] Creating layer ReLU4
I0702 00:34:49.368451 32261 net.cpp:150] Setting up Scale4
I0702 00:34:49.368279  4664 net.cpp:106] Creating Layer ReLU4
I0702 00:34:49.369130 13010 net.cpp:150] Setting up Scale2
I0702 00:34:49.368935 20914 net.cpp:106] Creating Layer Convolution5
I0702 00:34:49.368461 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368286  4664 net.cpp:454] ReLU4 <- Convolution4
I0702 00:34:49.369143 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368954 20914 net.cpp:454] Convolution5 <- Convolution4
I0702 00:34:49.368470 32261 net.cpp:165] Memory required for data: 1323020
I0702 00:34:49.369151 13010 net.cpp:165] Memory required for data: 602124
I0702 00:34:49.368968 20914 net.cpp:411] Convolution5 -> Convolution5
I0702 00:34:49.368481 32261 layer_factory.hpp:77] Creating layer ReLU4
I0702 00:34:49.369163 13010 layer_factory.hpp:77] Creating layer ReLU2
I0702 00:34:49.369173 13010 net.cpp:106] Creating Layer ReLU2
I0702 00:34:49.369181 13010 net.cpp:454] ReLU2 <- Convolution2
I0702 00:34:49.369194 13010 net.cpp:397] ReLU2 -> Convolution2 (in-place)
I0702 00:34:49.369208 13010 net.cpp:150] Setting up ReLU2
I0702 00:34:49.369217 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369225 13010 net.cpp:165] Memory required for data: 667660
I0702 00:34:49.369232 13010 layer_factory.hpp:77] Creating layer Convolution3
I0702 00:34:49.369253 13010 net.cpp:106] Creating Layer Convolution3
I0702 00:34:49.369264 13010 net.cpp:454] Convolution3 <- Convolution2
I0702 00:34:49.368494 32261 net.cpp:106] Creating Layer ReLU4
I0702 00:34:49.368502 32261 net.cpp:454] ReLU4 <- Convolution4
I0702 00:34:49.368511 32261 net.cpp:397] ReLU4 -> Convolution4 (in-place)
I0702 00:34:49.368521 32261 net.cpp:150] Setting up ReLU4
I0702 00:34:49.368527 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368535 32261 net.cpp:165] Memory required for data: 1388556
I0702 00:34:49.368542 32261 layer_factory.hpp:77] Creating layer Convolution5
I0702 00:34:49.369102 20914 net.cpp:150] Setting up Convolution5
I0702 00:34:49.368558 32261 net.cpp:106] Creating Layer Convolution5
I0702 00:34:49.368576 32261 net.cpp:454] Convolution5 <- Convolution4
I0702 00:34:49.369278 13010 net.cpp:411] Convolution3 -> Convolution3
I0702 00:34:49.368587 32261 net.cpp:411] Convolution5 -> Convolution5
I0702 00:34:49.369423 13010 net.cpp:150] Setting up Convolution3
I0702 00:34:49.368712 32261 net.cpp:150] Setting up Convolution5
I0702 00:34:49.369438 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369115 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369125 20914 net.cpp:165] Memory required for data: 1454092
I0702 00:34:49.369448 13010 net.cpp:165] Memory required for data: 733196
I0702 00:34:49.369137 20914 layer_factory.hpp:77] Creating layer BatchNorm5
I0702 00:34:49.369460 13010 layer_factory.hpp:77] Creating layer BatchNorm3
I0702 00:34:49.369155 20914 net.cpp:106] Creating Layer BatchNorm5
I0702 00:34:49.369165 20914 net.cpp:454] BatchNorm5 <- Convolution5
I0702 00:34:49.369174 20914 net.cpp:397] BatchNorm5 -> Convolution5 (in-place)
I0702 00:34:49.369206 20914 net.cpp:150] Setting up BatchNorm5
I0702 00:34:49.368724 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368733 32261 net.cpp:165] Memory required for data: 1454092
I0702 00:34:49.369216 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368746 32261 layer_factory.hpp:77] Creating layer BatchNorm5
I0702 00:34:49.368758 32261 net.cpp:106] Creating Layer BatchNorm5
I0702 00:34:49.368765 32261 net.cpp:454] BatchNorm5 <- Convolution5
I0702 00:34:49.369473 13010 net.cpp:106] Creating Layer BatchNorm3
I0702 00:34:49.368774 32261 net.cpp:397] BatchNorm5 -> Convolution5 (in-place)
I0702 00:34:49.369482 13010 net.cpp:454] BatchNorm3 <- Convolution3
I0702 00:34:49.369241 20914 net.cpp:165] Memory required for data: 1519628
I0702 00:34:49.368801 32261 net.cpp:150] Setting up BatchNorm5
I0702 00:34:49.369496 13010 net.cpp:397] BatchNorm3 -> Convolution3 (in-place)
I0702 00:34:49.369264 20914 layer_factory.hpp:77] Creating layer Scale5
I0702 00:34:49.368810 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369527 13010 net.cpp:150] Setting up BatchNorm3
I0702 00:34:49.369277 20914 net.cpp:106] Creating Layer Scale5
I0702 00:34:49.369284 20914 net.cpp:454] Scale5 <- Convolution5
I0702 00:34:49.368819 32261 net.cpp:165] Memory required for data: 1519628
I0702 00:34:49.369537 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369299 20914 net.cpp:397] Scale5 -> Convolution5 (in-place)
I0702 00:34:49.368839 32261 layer_factory.hpp:77] Creating layer Scale5
I0702 00:34:49.369554 13010 net.cpp:165] Memory required for data: 798732
I0702 00:34:49.369319 20914 layer_factory.hpp:77] Creating layer Scale5
I0702 00:34:49.368851 32261 net.cpp:106] Creating Layer Scale5
I0702 00:34:49.369571 13010 layer_factory.hpp:77] Creating layer Scale3
I0702 00:34:49.368862 32261 net.cpp:454] Scale5 <- Convolution5
I0702 00:34:49.369586 13010 net.cpp:106] Creating Layer Scale3
I0702 00:34:49.369355 20914 net.cpp:150] Setting up Scale5
I0702 00:34:49.369596 13010 net.cpp:454] Scale3 <- Convolution3
I0702 00:34:49.369604 13010 net.cpp:397] Scale3 -> Convolution3 (in-place)
I0702 00:34:49.369367 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369377 20914 net.cpp:165] Memory required for data: 1585164
I0702 00:34:49.369388 20914 layer_factory.hpp:77] Creating layer Eltwise2
I0702 00:34:49.369403 20914 net.cpp:106] Creating Layer Eltwise2
I0702 00:34:49.369621 13010 layer_factory.hpp:77] Creating layer Scale3
I0702 00:34:49.369412 20914 net.cpp:454] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0702 00:34:49.369668 13010 net.cpp:150] Setting up Scale3
I0702 00:34:49.368871 32261 net.cpp:397] Scale5 -> Convolution5 (in-place)
I0702 00:34:49.369679 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368888 32261 layer_factory.hpp:77] Creating layer Scale5
I0702 00:34:49.369688 13010 net.cpp:165] Memory required for data: 864268
I0702 00:34:49.368917 32261 net.cpp:150] Setting up Scale5
I0702 00:34:49.369700 13010 layer_factory.hpp:77] Creating layer Eltwise1
I0702 00:34:49.369421 20914 net.cpp:454] Eltwise2 <- Convolution5
I0702 00:34:49.368927 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369712 13010 net.cpp:106] Creating Layer Eltwise1
I0702 00:34:49.369431 20914 net.cpp:411] Eltwise2 -> Eltwise2
I0702 00:34:49.369444 20914 net.cpp:150] Setting up Eltwise2
I0702 00:34:49.369451 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369459 20914 net.cpp:165] Memory required for data: 1650700
I0702 00:34:49.369467 20914 layer_factory.hpp:77] Creating layer ReLU5
I0702 00:34:49.368937 32261 net.cpp:165] Memory required for data: 1585164
I0702 00:34:49.369719 13010 net.cpp:454] Eltwise1 <- Convolution1_ReLU1_0_split_1
I0702 00:34:49.369474 20914 net.cpp:106] Creating Layer ReLU5
I0702 00:34:49.369482 20914 net.cpp:454] ReLU5 <- Eltwise2
I0702 00:34:49.368950 32261 layer_factory.hpp:77] Creating layer Eltwise2
I0702 00:34:49.369727 13010 net.cpp:454] Eltwise1 <- Convolution3
I0702 00:34:49.369489 20914 net.cpp:397] ReLU5 -> Eltwise2 (in-place)
I0702 00:34:49.369501 20914 net.cpp:150] Setting up ReLU5
I0702 00:34:49.368962 32261 net.cpp:106] Creating Layer Eltwise2
I0702 00:34:49.369741 13010 net.cpp:411] Eltwise1 -> Eltwise1
I0702 00:34:49.369509 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369518 20914 net.cpp:165] Memory required for data: 1716236
I0702 00:34:49.368968 32261 net.cpp:454] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0702 00:34:49.369758 13010 net.cpp:150] Setting up Eltwise1
I0702 00:34:49.369524 20914 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0702 00:34:49.369534 20914 net.cpp:106] Creating Layer Eltwise2_ReLU5_0_split
I0702 00:34:49.368978 32261 net.cpp:454] Eltwise2 <- Convolution5
I0702 00:34:49.369767 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369541 20914 net.cpp:454] Eltwise2_ReLU5_0_split <- Eltwise2
I0702 00:34:49.368986 32261 net.cpp:411] Eltwise2 -> Eltwise2
I0702 00:34:49.369557 20914 net.cpp:411] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0702 00:34:49.368999 32261 net.cpp:150] Setting up Eltwise2
I0702 00:34:49.369573 20914 net.cpp:411] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0702 00:34:49.369587 20914 net.cpp:150] Setting up Eltwise2_ReLU5_0_split
I0702 00:34:49.369007 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369776 13010 net.cpp:165] Memory required for data: 929804
I0702 00:34:49.369594 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369020 32261 net.cpp:165] Memory required for data: 1650700
I0702 00:34:49.369782 13010 layer_factory.hpp:77] Creating layer ReLU3
I0702 00:34:49.369603 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369611 20914 net.cpp:165] Memory required for data: 1847308
I0702 00:34:49.369027 32261 layer_factory.hpp:77] Creating layer ReLU5
I0702 00:34:49.369792 13010 net.cpp:106] Creating Layer ReLU3
I0702 00:34:49.369617 20914 layer_factory.hpp:77] Creating layer Convolution6
I0702 00:34:49.369036 32261 net.cpp:106] Creating Layer ReLU5
I0702 00:34:49.369798 13010 net.cpp:454] ReLU3 <- Eltwise1
I0702 00:34:49.369639 20914 net.cpp:106] Creating Layer Convolution6
I0702 00:34:49.369042 32261 net.cpp:454] ReLU5 <- Eltwise2
I0702 00:34:49.369807 13010 net.cpp:397] ReLU3 -> Eltwise1 (in-place)
I0702 00:34:49.369650 20914 net.cpp:454] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0702 00:34:49.369050 32261 net.cpp:397] ReLU5 -> Eltwise2 (in-place)
I0702 00:34:49.369817 13010 net.cpp:150] Setting up ReLU3
I0702 00:34:49.369663 20914 net.cpp:411] Convolution6 -> Convolution6
I0702 00:34:49.369060 32261 net.cpp:150] Setting up ReLU5
I0702 00:34:49.369823 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369067 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369832 13010 net.cpp:165] Memory required for data: 995340
I0702 00:34:49.369076 32261 net.cpp:165] Memory required for data: 1716236
I0702 00:34:49.369838 13010 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I0702 00:34:49.369081 32261 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0702 00:34:49.369848 13010 net.cpp:106] Creating Layer Eltwise1_ReLU3_0_split
I0702 00:34:49.369855 13010 net.cpp:454] Eltwise1_ReLU3_0_split <- Eltwise1
I0702 00:34:49.369864 13010 net.cpp:411] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I0702 00:34:49.369874 13010 net.cpp:411] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I0702 00:34:49.369886 13010 net.cpp:150] Setting up Eltwise1_ReLU3_0_split
I0702 00:34:49.369894 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369912 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369921 13010 net.cpp:165] Memory required for data: 1126412
I0702 00:34:49.369928 13010 layer_factory.hpp:77] Creating layer Convolution4
I0702 00:34:49.369091 32261 net.cpp:106] Creating Layer Eltwise2_ReLU5_0_split
I0702 00:34:49.369096 32261 net.cpp:454] Eltwise2_ReLU5_0_split <- Eltwise2
I0702 00:34:49.369105 32261 net.cpp:411] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0702 00:34:49.369115 32261 net.cpp:411] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0702 00:34:49.369951 13010 net.cpp:106] Creating Layer Convolution4
I0702 00:34:49.369128 32261 net.cpp:150] Setting up Eltwise2_ReLU5_0_split
I0702 00:34:49.369961 13010 net.cpp:454] Convolution4 <- Eltwise1_ReLU3_0_split_0
I0702 00:34:49.369138 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369973 13010 net.cpp:411] Convolution4 -> Convolution4
I0702 00:34:49.369146 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370100 13010 net.cpp:150] Setting up Convolution4
I0702 00:34:49.369794 20914 net.cpp:150] Setting up Convolution6
I0702 00:34:49.369154 32261 net.cpp:165] Memory required for data: 1847308
I0702 00:34:49.370115 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369809 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369820 20914 net.cpp:165] Memory required for data: 1912844
I0702 00:34:49.369832 20914 layer_factory.hpp:77] Creating layer BatchNorm6
I0702 00:34:49.369160 32261 layer_factory.hpp:77] Creating layer Convolution6
I0702 00:34:49.370124 13010 net.cpp:165] Memory required for data: 1191948
I0702 00:34:49.369848 20914 net.cpp:106] Creating Layer BatchNorm6
I0702 00:34:49.369179 32261 net.cpp:106] Creating Layer Convolution6
I0702 00:34:49.370136 13010 layer_factory.hpp:77] Creating layer BatchNorm4
I0702 00:34:49.369856 20914 net.cpp:454] BatchNorm6 <- Convolution6
I0702 00:34:49.369189 32261 net.cpp:454] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0702 00:34:49.370149 13010 net.cpp:106] Creating Layer BatchNorm4
I0702 00:34:49.369873 20914 net.cpp:397] BatchNorm6 -> Convolution6 (in-place)
I0702 00:34:49.369204 32261 net.cpp:411] Convolution6 -> Convolution6
I0702 00:34:49.369902 20914 net.cpp:150] Setting up BatchNorm6
I0702 00:34:49.369334 32261 net.cpp:150] Setting up Convolution6
I0702 00:34:49.369349 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370157 13010 net.cpp:454] BatchNorm4 <- Convolution4
I0702 00:34:49.369913 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369357 32261 net.cpp:165] Memory required for data: 1912844
I0702 00:34:49.370172 13010 net.cpp:397] BatchNorm4 -> Convolution4 (in-place)
I0702 00:34:49.369932 20914 net.cpp:165] Memory required for data: 1978380
I0702 00:34:49.369372 32261 layer_factory.hpp:77] Creating layer BatchNorm6
I0702 00:34:49.370204 13010 net.cpp:150] Setting up BatchNorm4
I0702 00:34:49.369947 20914 layer_factory.hpp:77] Creating layer Scale6
I0702 00:34:49.369385 32261 net.cpp:106] Creating Layer BatchNorm6
I0702 00:34:49.370214 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369961 20914 net.cpp:106] Creating Layer Scale6
I0702 00:34:49.369968 20914 net.cpp:454] Scale6 <- Convolution6
I0702 00:34:49.369391 32261 net.cpp:454] BatchNorm6 <- Convolution6
I0702 00:34:49.370230 13010 net.cpp:165] Memory required for data: 1257484
I0702 00:34:49.369977 20914 net.cpp:397] Scale6 -> Convolution6 (in-place)
I0702 00:34:49.369400 32261 net.cpp:397] BatchNorm6 -> Convolution6 (in-place)
I0702 00:34:49.370244 13010 layer_factory.hpp:77] Creating layer Scale4
I0702 00:34:49.369994 20914 layer_factory.hpp:77] Creating layer Scale6
I0702 00:34:49.369427 32261 net.cpp:150] Setting up BatchNorm6
I0702 00:34:49.370257 13010 net.cpp:106] Creating Layer Scale4
I0702 00:34:49.370033 20914 net.cpp:150] Setting up Scale6
I0702 00:34:49.370265 13010 net.cpp:454] Scale4 <- Convolution4
I0702 00:34:49.370276 13010 net.cpp:397] Scale4 -> Convolution4 (in-place)
I0702 00:34:49.370044 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370054 20914 net.cpp:165] Memory required for data: 2043916
I0702 00:34:49.370065 20914 layer_factory.hpp:77] Creating layer ReLU6
I0702 00:34:49.370074 20914 net.cpp:106] Creating Layer ReLU6
I0702 00:34:49.369436 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370296 13010 layer_factory.hpp:77] Creating layer Scale4
I0702 00:34:49.369452 32261 net.cpp:165] Memory required for data: 1978380
I0702 00:34:49.370329 13010 net.cpp:150] Setting up Scale4
I0702 00:34:49.370081 20914 net.cpp:454] ReLU6 <- Convolution6
I0702 00:34:49.369467 32261 layer_factory.hpp:77] Creating layer Scale6
I0702 00:34:49.370342 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369480 32261 net.cpp:106] Creating Layer Scale6
I0702 00:34:49.370349 13010 net.cpp:165] Memory required for data: 1323020
I0702 00:34:49.369488 32261 net.cpp:454] Scale6 <- Convolution6
I0702 00:34:49.370362 13010 layer_factory.hpp:77] Creating layer ReLU4
I0702 00:34:49.370096 20914 net.cpp:397] ReLU6 -> Convolution6 (in-place)
I0702 00:34:49.370110 20914 net.cpp:150] Setting up ReLU6
I0702 00:34:49.369498 32261 net.cpp:397] Scale6 -> Convolution6 (in-place)
I0702 00:34:49.370374 13010 net.cpp:106] Creating Layer ReLU4
I0702 00:34:49.370116 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370126 20914 net.cpp:165] Memory required for data: 2109452
I0702 00:34:49.370131 20914 layer_factory.hpp:77] Creating layer Convolution7
I0702 00:34:49.369513 32261 layer_factory.hpp:77] Creating layer Scale6
I0702 00:34:49.370383 13010 net.cpp:454] ReLU4 <- Convolution4
I0702 00:34:49.370151 20914 net.cpp:106] Creating Layer Convolution7
I0702 00:34:49.370160 20914 net.cpp:454] Convolution7 <- Convolution6
I0702 00:34:49.369549 32261 net.cpp:150] Setting up Scale6
I0702 00:34:49.370391 13010 net.cpp:397] ReLU4 -> Convolution4 (in-place)
I0702 00:34:49.370177 20914 net.cpp:411] Convolution7 -> Convolution7
I0702 00:34:49.369560 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370416 13010 net.cpp:150] Setting up ReLU4
I0702 00:34:49.369570 32261 net.cpp:165] Memory required for data: 2043916
I0702 00:34:49.370425 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369580 32261 layer_factory.hpp:77] Creating layer ReLU6
I0702 00:34:49.370434 13010 net.cpp:165] Memory required for data: 1388556
I0702 00:34:49.369591 32261 net.cpp:106] Creating Layer ReLU6
I0702 00:34:49.370441 13010 layer_factory.hpp:77] Creating layer Convolution5
I0702 00:34:49.369598 32261 net.cpp:454] ReLU6 <- Convolution6
I0702 00:34:49.369609 32261 net.cpp:397] ReLU6 -> Convolution6 (in-place)
I0702 00:34:49.369621 32261 net.cpp:150] Setting up ReLU6
I0702 00:34:49.369627 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369637 32261 net.cpp:165] Memory required for data: 2109452
I0702 00:34:49.369643 32261 layer_factory.hpp:77] Creating layer Convolution7
I0702 00:34:49.370462 13010 net.cpp:106] Creating Layer Convolution5
I0702 00:34:49.369659 32261 net.cpp:106] Creating Layer Convolution7
I0702 00:34:49.370481 13010 net.cpp:454] Convolution5 <- Convolution4
I0702 00:34:49.369668 32261 net.cpp:454] Convolution7 <- Convolution6
I0702 00:34:49.370493 13010 net.cpp:411] Convolution5 -> Convolution5
I0702 00:34:49.369681 32261 net.cpp:411] Convolution7 -> Convolution7
I0702 00:34:49.370625 13010 net.cpp:150] Setting up Convolution5
I0702 00:34:49.370637 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370647 13010 net.cpp:165] Memory required for data: 1454092
I0702 00:34:49.370658 13010 layer_factory.hpp:77] Creating layer BatchNorm5
I0702 00:34:49.370317 20914 net.cpp:150] Setting up Convolution7
I0702 00:34:49.370332 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370342 20914 net.cpp:165] Memory required for data: 2174988
I0702 00:34:49.370353 20914 layer_factory.hpp:77] Creating layer BatchNorm7
I0702 00:34:49.369804 32261 net.cpp:150] Setting up Convolution7
I0702 00:34:49.370673 13010 net.cpp:106] Creating Layer BatchNorm5
I0702 00:34:49.370373 20914 net.cpp:106] Creating Layer BatchNorm7
I0702 00:34:49.369817 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370682 13010 net.cpp:454] BatchNorm5 <- Convolution5
I0702 00:34:49.370383 20914 net.cpp:454] BatchNorm7 <- Convolution7
I0702 00:34:49.370393 20914 net.cpp:397] BatchNorm7 -> Convolution7 (in-place)
I0702 00:34:49.369829 32261 net.cpp:165] Memory required for data: 2174988
I0702 00:34:49.370692 13010 net.cpp:397] BatchNorm5 -> Convolution5 (in-place)
I0702 00:34:49.370421 20914 net.cpp:150] Setting up BatchNorm7
I0702 00:34:49.369840 32261 layer_factory.hpp:77] Creating layer BatchNorm7
I0702 00:34:49.370431 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369858 32261 net.cpp:106] Creating Layer BatchNorm7
I0702 00:34:49.370448 20914 net.cpp:165] Memory required for data: 2240524
I0702 00:34:49.369866 32261 net.cpp:454] BatchNorm7 <- Convolution7
I0702 00:34:49.370720 13010 net.cpp:150] Setting up BatchNorm5
I0702 00:34:49.370462 20914 layer_factory.hpp:77] Creating layer Scale7
I0702 00:34:49.369876 32261 net.cpp:397] BatchNorm7 -> Convolution7 (in-place)
I0702 00:34:49.370731 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370740 13010 net.cpp:165] Memory required for data: 1519628
I0702 00:34:49.370474 20914 net.cpp:106] Creating Layer Scale7
I0702 00:34:49.370481 20914 net.cpp:454] Scale7 <- Convolution7
I0702 00:34:49.369904 32261 net.cpp:150] Setting up BatchNorm7
I0702 00:34:49.370764 13010 layer_factory.hpp:77] Creating layer Scale5
I0702 00:34:49.369912 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370779 13010 net.cpp:106] Creating Layer Scale5
I0702 00:34:49.370496 20914 net.cpp:397] Scale7 -> Convolution7 (in-place)
I0702 00:34:49.369921 32261 net.cpp:165] Memory required for data: 2240524
I0702 00:34:49.370788 13010 net.cpp:454] Scale5 <- Convolution5
I0702 00:34:49.370512 20914 layer_factory.hpp:77] Creating layer Scale7
I0702 00:34:49.369935 32261 layer_factory.hpp:77] Creating layer Scale7
I0702 00:34:49.370798 13010 net.cpp:397] Scale5 -> Convolution5 (in-place)
I0702 00:34:49.369946 32261 net.cpp:106] Creating Layer Scale7
I0702 00:34:49.370815 13010 layer_factory.hpp:77] Creating layer Scale5
I0702 00:34:49.370543 20914 net.cpp:150] Setting up Scale7
I0702 00:34:49.370553 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369952 32261 net.cpp:454] Scale7 <- Convolution7
I0702 00:34:49.370563 20914 net.cpp:165] Memory required for data: 2306060
I0702 00:34:49.369964 32261 net.cpp:397] Scale7 -> Convolution7 (in-place)
I0702 00:34:49.370576 20914 layer_factory.hpp:77] Creating layer Eltwise3
I0702 00:34:49.369982 32261 layer_factory.hpp:77] Creating layer Scale7
I0702 00:34:49.370848 13010 net.cpp:150] Setting up Scale5
I0702 00:34:49.370587 20914 net.cpp:106] Creating Layer Eltwise3
I0702 00:34:49.370594 20914 net.cpp:454] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0702 00:34:49.370014 32261 net.cpp:150] Setting up Scale7
I0702 00:34:49.370859 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370602 20914 net.cpp:454] Eltwise3 <- Convolution7
I0702 00:34:49.370868 13010 net.cpp:165] Memory required for data: 1585164
I0702 00:34:49.370611 20914 net.cpp:411] Eltwise3 -> Eltwise3
I0702 00:34:49.370882 13010 layer_factory.hpp:77] Creating layer Eltwise2
I0702 00:34:49.370625 20914 net.cpp:150] Setting up Eltwise3
I0702 00:34:49.370894 13010 net.cpp:106] Creating Layer Eltwise2
I0702 00:34:49.370631 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370901 13010 net.cpp:454] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0702 00:34:49.370647 20914 net.cpp:165] Memory required for data: 2371596
I0702 00:34:49.370910 13010 net.cpp:454] Eltwise2 <- Convolution5
I0702 00:34:49.370654 20914 layer_factory.hpp:77] Creating layer ReLU7
I0702 00:34:49.370919 13010 net.cpp:411] Eltwise2 -> Eltwise2
I0702 00:34:49.370663 20914 net.cpp:106] Creating Layer ReLU7
I0702 00:34:49.370024 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370932 13010 net.cpp:150] Setting up Eltwise2
I0702 00:34:49.370671 20914 net.cpp:454] ReLU7 <- Eltwise3
I0702 00:34:49.370038 32261 net.cpp:165] Memory required for data: 2306060
I0702 00:34:49.370679 20914 net.cpp:397] ReLU7 -> Eltwise3 (in-place)
I0702 00:34:49.370048 32261 layer_factory.hpp:77] Creating layer Eltwise3
I0702 00:34:49.370689 20914 net.cpp:150] Setting up ReLU7
I0702 00:34:49.370059 32261 net.cpp:106] Creating Layer Eltwise3
I0702 00:34:49.370940 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370697 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370065 32261 net.cpp:454] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0702 00:34:49.370957 13010 net.cpp:165] Memory required for data: 1650700
I0702 00:34:49.370704 20914 net.cpp:165] Memory required for data: 2437132
I0702 00:34:49.370710 20914 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0702 00:34:49.370074 32261 net.cpp:454] Eltwise3 <- Convolution7
I0702 00:34:49.370965 13010 layer_factory.hpp:77] Creating layer ReLU5
I0702 00:34:49.370719 20914 net.cpp:106] Creating Layer Eltwise3_ReLU7_0_split
I0702 00:34:49.370081 32261 net.cpp:411] Eltwise3 -> Eltwise3
I0702 00:34:49.370975 13010 net.cpp:106] Creating Layer ReLU5
I0702 00:34:49.370726 20914 net.cpp:454] Eltwise3_ReLU7_0_split <- Eltwise3
I0702 00:34:49.370095 32261 net.cpp:150] Setting up Eltwise3
I0702 00:34:49.370981 13010 net.cpp:454] ReLU5 <- Eltwise2
I0702 00:34:49.370735 20914 net.cpp:411] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0702 00:34:49.370102 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370990 13010 net.cpp:397] ReLU5 -> Eltwise2 (in-place)
I0702 00:34:49.370746 20914 net.cpp:411] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0702 00:34:49.370111 32261 net.cpp:165] Memory required for data: 2371596
I0702 00:34:49.370999 13010 net.cpp:150] Setting up ReLU5
I0702 00:34:49.370766 20914 net.cpp:150] Setting up Eltwise3_ReLU7_0_split
I0702 00:34:49.370117 32261 layer_factory.hpp:77] Creating layer ReLU7
I0702 00:34:49.371006 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370776 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370126 32261 net.cpp:106] Creating Layer ReLU7
I0702 00:34:49.371014 13010 net.cpp:165] Memory required for data: 1716236
I0702 00:34:49.370785 20914 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370132 32261 net.cpp:454] ReLU7 <- Eltwise3
I0702 00:34:49.371021 13010 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0702 00:34:49.370793 20914 net.cpp:165] Memory required for data: 2568204
I0702 00:34:49.370141 32261 net.cpp:397] ReLU7 -> Eltwise3 (in-place)
I0702 00:34:49.371029 13010 net.cpp:106] Creating Layer Eltwise2_ReLU5_0_split
I0702 00:34:49.370800 20914 layer_factory.hpp:77] Creating layer Convolution8
I0702 00:34:49.370151 32261 net.cpp:150] Setting up ReLU7
I0702 00:34:49.371037 13010 net.cpp:454] Eltwise2_ReLU5_0_split <- Eltwise2
I0702 00:34:49.370822 20914 net.cpp:106] Creating Layer Convolution8
I0702 00:34:49.370157 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.371044 13010 net.cpp:411] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0702 00:34:49.370834 20914 net.cpp:454] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0702 00:34:49.370165 32261 net.cpp:165] Memory required for data: 2437132
I0702 00:34:49.371055 13010 net.cpp:411] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0702 00:34:49.370853 20914 net.cpp:411] Convolution8 -> Convolution8
I0702 00:34:49.370172 32261 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0702 00:34:49.371069 13010 net.cpp:150] Setting up Eltwise2_ReLU5_0_split
I0702 00:34:49.370179 32261 net.cpp:106] Creating Layer Eltwise3_ReLU7_0_split
I0702 00:34:49.371078 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370187 32261 net.cpp:454] Eltwise3_ReLU7_0_split <- Eltwise3
I0702 00:34:49.370198 32261 net.cpp:411] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0702 00:34:49.370210 32261 net.cpp:411] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0702 00:34:49.370230 32261 net.cpp:150] Setting up Eltwise3_ReLU7_0_split
I0702 00:34:49.370239 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.371086 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370249 32261 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.371094 13010 net.cpp:165] Memory required for data: 1847308
I0702 00:34:49.370261 32261 net.cpp:165] Memory required for data: 2568204
I0702 00:34:49.371100 13010 layer_factory.hpp:77] Creating layer Convolution6
I0702 00:34:49.370946 20914 net.cpp:150] Setting up Convolution8
I0702 00:34:49.370270 32261 layer_factory.hpp:77] Creating layer Convolution8
I0702 00:34:49.371124 13010 net.cpp:106] Creating Layer Convolution6
I0702 00:34:49.370960 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.370970 20914 net.cpp:165] Memory required for data: 2600972
I0702 00:34:49.370290 32261 net.cpp:106] Creating Layer Convolution8
I0702 00:34:49.371134 13010 net.cpp:454] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0702 00:34:49.370298 32261 net.cpp:454] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0702 00:34:49.371150 13010 net.cpp:411] Convolution6 -> Convolution6
I0702 00:34:49.370981 20914 layer_factory.hpp:77] Creating layer BatchNorm8
I0702 00:34:49.370308 32261 net.cpp:411] Convolution8 -> Convolution8
I0702 00:34:49.371281 13010 net.cpp:150] Setting up Convolution6
I0702 00:34:49.370997 20914 net.cpp:106] Creating Layer BatchNorm8
I0702 00:34:49.371006 20914 net.cpp:454] BatchNorm8 <- Convolution8
I0702 00:34:49.370394 32261 net.cpp:150] Setting up Convolution8
I0702 00:34:49.371016 20914 net.cpp:397] BatchNorm8 -> Convolution8 (in-place)
I0702 00:34:49.370406 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.371294 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.371040 20914 net.cpp:150] Setting up BatchNorm8
I0702 00:34:49.370416 32261 net.cpp:165] Memory required for data: 2600972
I0702 00:34:49.371305 13010 net.cpp:165] Memory required for data: 1912844
I0702 00:34:49.371050 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.371064 20914 net.cpp:165] Memory required for data: 2633740
I0702 00:34:49.370427 32261 layer_factory.hpp:77] Creating layer BatchNorm8
I0702 00:34:49.371320 13010 layer_factory.hpp:77] Creating layer BatchNorm6
I0702 00:34:49.371078 20914 layer_factory.hpp:77] Creating layer Scale8
I0702 00:34:49.370437 32261 net.cpp:106] Creating Layer BatchNorm8
I0702 00:34:49.371331 13010 net.cpp:106] Creating Layer BatchNorm6
I0702 00:34:49.371088 20914 net.cpp:106] Creating Layer Scale8
I0702 00:34:49.371095 20914 net.cpp:454] Scale8 <- Convolution8
I0702 00:34:49.370445 32261 net.cpp:454] BatchNorm8 <- Convolution8
I0702 00:34:49.371340 13010 net.cpp:454] BatchNorm6 <- Convolution6
I0702 00:34:49.371109 20914 net.cpp:397] Scale8 -> Convolution8 (in-place)
I0702 00:34:49.370455 32261 net.cpp:397] BatchNorm8 -> Convolution8 (in-place)
I0702 00:34:49.371351 13010 net.cpp:397] BatchNorm6 -> Convolution6 (in-place)
I0702 00:34:49.371129 20914 layer_factory.hpp:77] Creating layer Scale8
I0702 00:34:49.370479 32261 net.cpp:150] Setting up BatchNorm8
I0702 00:34:49.371385 13010 net.cpp:150] Setting up BatchNorm6
I0702 00:34:49.371160 20914 net.cpp:150] Setting up Scale8
I0702 00:34:49.370488 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.371171 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.371181 20914 net.cpp:165] Memory required for data: 2666508
I0702 00:34:49.370501 32261 net.cpp:165] Memory required for data: 2633740
I0702 00:34:49.371196 20914 layer_factory.hpp:77] Creating layer Convolution9
I0702 00:34:49.370514 32261 layer_factory.hpp:77] Creating layer Scale8
I0702 00:34:49.371397 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.371421 13010 net.cpp:165] Memory required for data: 1978380
I0702 00:34:49.370527 32261 net.cpp:106] Creating Layer Scale8
I0702 00:34:49.371438 13010 layer_factory.hpp:77] Creating layer Scale6
I0702 00:34:49.370533 32261 net.cpp:454] Scale8 <- Convolution8
I0702 00:34:49.371455 13010 net.cpp:106] Creating Layer Scale6
I0702 00:34:49.371217 20914 net.cpp:106] Creating Layer Convolution9
I0702 00:34:49.371233 20914 net.cpp:454] Convolution9 <- Eltwise3_ReLU7_0_split_1
I0702 00:34:49.370545 32261 net.cpp:397] Scale8 -> Convolution8 (in-place)
I0702 00:34:49.371465 13010 net.cpp:454] Scale6 <- Convolution6
I0702 00:34:49.371248 20914 net.cpp:411] Convolution9 -> Convolution9
I0702 00:34:49.370563 32261 layer_factory.hpp:77] Creating layer Scale8
I0702 00:34:49.371476 13010 net.cpp:397] Scale6 -> Convolution6 (in-place)
I0702 00:34:49.370591 32261 net.cpp:150] Setting up Scale8
I0702 00:34:49.371495 13010 layer_factory.hpp:77] Creating layer Scale6
I0702 00:34:49.370601 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.371531 13010 net.cpp:150] Setting up Scale6
I0702 00:34:49.370610 32261 net.cpp:165] Memory required for data: 2666508
I0702 00:34:49.371543 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370621 32261 layer_factory.hpp:77] Creating layer Convolution9
I0702 00:34:49.370645 32261 net.cpp:106] Creating Layer Convolution9
I0702 00:34:49.370656 32261 net.cpp:454] Convolution9 <- Eltwise3_ReLU7_0_split_1
I0702 00:34:49.370668 32261 net.cpp:411] Convolution9 -> Convolution9
I0702 00:34:49.371552 13010 net.cpp:165] Memory required for data: 2043916
I0702 00:34:49.371563 13010 layer_factory.hpp:77] Creating layer ReLU6
I0702 00:34:49.371573 13010 net.cpp:106] Creating Layer ReLU6
I0702 00:34:49.370834 32261 net.cpp:150] Setting up Convolution9
I0702 00:34:49.371579 13010 net.cpp:454] ReLU6 <- Convolution6
I0702 00:34:49.370846 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.371592 13010 net.cpp:397] ReLU6 -> Convolution6 (in-place)
I0702 00:34:49.370860 32261 net.cpp:165] Memory required for data: 2699276
I0702 00:34:49.371604 13010 net.cpp:150] Setting up ReLU6
I0702 00:34:49.370872 32261 layer_factory.hpp:77] Creating layer BatchNorm9
I0702 00:34:49.371611 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370883 32261 net.cpp:106] Creating Layer BatchNorm9
I0702 00:34:49.371619 13010 net.cpp:165] Memory required for data: 2109452
I0702 00:34:49.370892 32261 net.cpp:454] BatchNorm9 <- Convolution9
I0702 00:34:49.371626 13010 layer_factory.hpp:77] Creating layer Convolution7
I0702 00:34:49.370903 32261 net.cpp:397] BatchNorm9 -> Convolution9 (in-place)
I0702 00:34:49.371647 13010 net.cpp:106] Creating Layer Convolution7
I0702 00:34:49.370928 32261 net.cpp:150] Setting up BatchNorm9
I0702 00:34:49.371659 13010 net.cpp:454] Convolution7 <- Convolution6
I0702 00:34:49.370936 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.371670 13010 net.cpp:411] Convolution7 -> Convolution7
I0702 00:34:49.370944 32261 net.cpp:165] Memory required for data: 2732044
I0702 00:34:49.370957 32261 layer_factory.hpp:77] Creating layer Scale9
I0702 00:34:49.370970 32261 net.cpp:106] Creating Layer Scale9
I0702 00:34:49.370976 32261 net.cpp:454] Scale9 <- Convolution9
I0702 00:34:49.370987 32261 net.cpp:397] Scale9 -> Convolution9 (in-place)
I0702 00:34:49.371423 20914 net.cpp:150] Setting up Convolution9
I0702 00:34:49.371800 13010 net.cpp:150] Setting up Convolution7
I0702 00:34:49.371436 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.371445 20914 net.cpp:165] Memory required for data: 2699276
I0702 00:34:49.371006 32261 layer_factory.hpp:77] Creating layer Scale9
I0702 00:34:49.371035 32261 net.cpp:150] Setting up Scale9
I0702 00:34:49.371460 20914 layer_factory.hpp:77] Creating layer BatchNorm9
I0702 00:34:49.371471 20914 net.cpp:106] Creating Layer BatchNorm9
I0702 00:34:49.371479 20914 net.cpp:454] BatchNorm9 <- Convolution9
I0702 00:34:49.371045 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.371054 32261 net.cpp:165] Memory required for data: 2764812
I0702 00:34:49.371814 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.371500 20914 net.cpp:397] BatchNorm9 -> Convolution9 (in-place)
I0702 00:34:49.371065 32261 layer_factory.hpp:77] Creating layer ReLU8
I0702 00:34:49.371829 13010 net.cpp:165] Memory required for data: 2174988
I0702 00:34:49.371076 32261 net.cpp:106] Creating Layer ReLU8
I0702 00:34:49.371841 13010 layer_factory.hpp:77] Creating layer BatchNorm7
I0702 00:34:49.371083 32261 net.cpp:454] ReLU8 <- Convolution9
I0702 00:34:49.371529 20914 net.cpp:150] Setting up BatchNorm9
I0702 00:34:49.371091 32261 net.cpp:397] ReLU8 -> Convolution9 (in-place)
I0702 00:34:49.371101 32261 net.cpp:150] Setting up ReLU8
I0702 00:34:49.371857 13010 net.cpp:106] Creating Layer BatchNorm7
I0702 00:34:49.371541 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.371107 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.371866 13010 net.cpp:454] BatchNorm7 <- Convolution7
I0702 00:34:49.371549 20914 net.cpp:165] Memory required for data: 2732044
I0702 00:34:49.371116 32261 net.cpp:165] Memory required for data: 2797580
I0702 00:34:49.371876 13010 net.cpp:397] BatchNorm7 -> Convolution7 (in-place)
I0702 00:34:49.371562 20914 layer_factory.hpp:77] Creating layer Scale9
I0702 00:34:49.371578 20914 net.cpp:106] Creating Layer Scale9
I0702 00:34:49.371585 20914 net.cpp:454] Scale9 <- Convolution9
I0702 00:34:49.371904 13010 net.cpp:150] Setting up BatchNorm7
I0702 00:34:49.371594 20914 net.cpp:397] Scale9 -> Convolution9 (in-place)
I0702 00:34:49.371124 32261 layer_factory.hpp:77] Creating layer Convolution10
I0702 00:34:49.371611 20914 layer_factory.hpp:77] Creating layer Scale9
I0702 00:34:49.371143 32261 net.cpp:106] Creating Layer Convolution10
I0702 00:34:49.371152 32261 net.cpp:454] Convolution10 <- Convolution9
I0702 00:34:49.371914 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.371173 32261 net.cpp:411] Convolution10 -> Convolution10
I0702 00:34:49.371923 13010 net.cpp:165] Memory required for data: 2240524
I0702 00:34:49.371644 20914 net.cpp:150] Setting up Scale9
I0702 00:34:49.371937 13010 layer_factory.hpp:77] Creating layer Scale7
I0702 00:34:49.371655 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.371665 20914 net.cpp:165] Memory required for data: 2764812
I0702 00:34:49.371949 13010 net.cpp:106] Creating Layer Scale7
I0702 00:34:49.371675 20914 layer_factory.hpp:77] Creating layer ReLU8
I0702 00:34:49.371685 20914 net.cpp:106] Creating Layer ReLU8
I0702 00:34:49.371691 20914 net.cpp:454] ReLU8 <- Convolution9
I0702 00:34:49.371956 13010 net.cpp:454] Scale7 <- Convolution7
I0702 00:34:49.371702 20914 net.cpp:397] ReLU8 -> Convolution9 (in-place)
I0702 00:34:49.371973 13010 net.cpp:397] Scale7 -> Convolution7 (in-place)
I0702 00:34:49.371713 20914 net.cpp:150] Setting up ReLU8
I0702 00:34:49.371719 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.371994 13010 layer_factory.hpp:77] Creating layer Scale7
I0702 00:34:49.371728 20914 net.cpp:165] Memory required for data: 2797580
I0702 00:34:49.371734 20914 layer_factory.hpp:77] Creating layer Convolution10
I0702 00:34:49.372028 13010 net.cpp:150] Setting up Scale7
I0702 00:34:49.371773 20914 net.cpp:106] Creating Layer Convolution10
I0702 00:34:49.372040 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.371446 32261 net.cpp:150] Setting up Convolution10
I0702 00:34:49.372056 13010 net.cpp:165] Memory required for data: 2306060
I0702 00:34:49.372068 13010 layer_factory.hpp:77] Creating layer Eltwise3
I0702 00:34:49.371784 20914 net.cpp:454] Convolution10 <- Convolution9
I0702 00:34:49.372079 13010 net.cpp:106] Creating Layer Eltwise3
I0702 00:34:49.371462 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.371472 32261 net.cpp:165] Memory required for data: 2830348
I0702 00:34:49.372087 13010 net.cpp:454] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0702 00:34:49.371809 20914 net.cpp:411] Convolution10 -> Convolution10
I0702 00:34:49.372095 13010 net.cpp:454] Eltwise3 <- Convolution7
I0702 00:34:49.372104 13010 net.cpp:411] Eltwise3 -> Eltwise3
I0702 00:34:49.371497 32261 layer_factory.hpp:77] Creating layer BatchNorm10
I0702 00:34:49.372117 13010 net.cpp:150] Setting up Eltwise3
I0702 00:34:49.371511 32261 net.cpp:106] Creating Layer BatchNorm10
I0702 00:34:49.372125 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.371520 32261 net.cpp:454] BatchNorm10 <- Convolution10
I0702 00:34:49.371529 32261 net.cpp:397] BatchNorm10 -> Convolution10 (in-place)
I0702 00:34:49.372134 13010 net.cpp:165] Memory required for data: 2371596
I0702 00:34:49.372140 13010 layer_factory.hpp:77] Creating layer ReLU7
I0702 00:34:49.372149 13010 net.cpp:106] Creating Layer ReLU7
I0702 00:34:49.372155 13010 net.cpp:454] ReLU7 <- Eltwise3
I0702 00:34:49.371554 32261 net.cpp:150] Setting up BatchNorm10
I0702 00:34:49.372164 13010 net.cpp:397] ReLU7 -> Eltwise3 (in-place)
I0702 00:34:49.371563 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372174 13010 net.cpp:150] Setting up ReLU7
I0702 00:34:49.371574 32261 net.cpp:165] Memory required for data: 2863116
I0702 00:34:49.372180 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.372189 13010 net.cpp:165] Memory required for data: 2437132
I0702 00:34:49.372195 13010 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0702 00:34:49.372203 13010 net.cpp:106] Creating Layer Eltwise3_ReLU7_0_split
I0702 00:34:49.372210 13010 net.cpp:454] Eltwise3_ReLU7_0_split <- Eltwise3
I0702 00:34:49.371588 32261 layer_factory.hpp:77] Creating layer Scale10
I0702 00:34:49.372223 13010 net.cpp:411] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0702 00:34:49.371600 32261 net.cpp:106] Creating Layer Scale10
I0702 00:34:49.372239 13010 net.cpp:411] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0702 00:34:49.371608 32261 net.cpp:454] Scale10 <- Convolution10
I0702 00:34:49.372259 13010 net.cpp:150] Setting up Eltwise3_ReLU7_0_split
I0702 00:34:49.371620 32261 net.cpp:397] Scale10 -> Convolution10 (in-place)
I0702 00:34:49.372268 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.372277 13010 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.371639 32261 layer_factory.hpp:77] Creating layer Scale10
I0702 00:34:49.372285 13010 net.cpp:165] Memory required for data: 2568204
I0702 00:34:49.371666 32261 net.cpp:150] Setting up Scale10
I0702 00:34:49.372292 13010 layer_factory.hpp:77] Creating layer Convolution8
I0702 00:34:49.371677 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372316 13010 net.cpp:106] Creating Layer Convolution8
I0702 00:34:49.371686 32261 net.cpp:165] Memory required for data: 2895884
I0702 00:34:49.372328 13010 net.cpp:454] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0702 00:34:49.372341 13010 net.cpp:411] Convolution8 -> Convolution8
I0702 00:34:49.371697 32261 layer_factory.hpp:77] Creating layer Eltwise4
I0702 00:34:49.371711 32261 net.cpp:106] Creating Layer Eltwise4
I0702 00:34:49.371719 32261 net.cpp:454] Eltwise4 <- Convolution8
I0702 00:34:49.372437 13010 net.cpp:150] Setting up Convolution8
I0702 00:34:49.371727 32261 net.cpp:454] Eltwise4 <- Convolution10
I0702 00:34:49.371737 32261 net.cpp:411] Eltwise4 -> Eltwise4
I0702 00:34:49.372452 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372460 13010 net.cpp:165] Memory required for data: 2600972
I0702 00:34:49.372473 13010 layer_factory.hpp:77] Creating layer BatchNorm8
I0702 00:34:49.371749 32261 net.cpp:150] Setting up Eltwise4
I0702 00:34:49.371757 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.371765 32261 net.cpp:165] Memory required for data: 2928652
I0702 00:34:49.372117 20914 net.cpp:150] Setting up Convolution10
I0702 00:34:49.371773 32261 layer_factory.hpp:77] Creating layer ReLU9
I0702 00:34:49.372483 13010 net.cpp:106] Creating Layer BatchNorm8
I0702 00:34:49.372133 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372143 20914 net.cpp:165] Memory required for data: 2830348
I0702 00:34:49.371783 32261 net.cpp:106] Creating Layer ReLU9
I0702 00:34:49.372493 13010 net.cpp:454] BatchNorm8 <- Convolution8
I0702 00:34:49.371790 32261 net.cpp:454] ReLU9 <- Eltwise4
I0702 00:34:49.372501 13010 net.cpp:397] BatchNorm8 -> Convolution8 (in-place)
I0702 00:34:49.372169 20914 layer_factory.hpp:77] Creating layer BatchNorm10
I0702 00:34:49.372184 20914 net.cpp:106] Creating Layer BatchNorm10
I0702 00:34:49.371798 32261 net.cpp:397] ReLU9 -> Eltwise4 (in-place)
I0702 00:34:49.372191 20914 net.cpp:454] BatchNorm10 <- Convolution10
I0702 00:34:49.372201 20914 net.cpp:397] BatchNorm10 -> Convolution10 (in-place)
I0702 00:34:49.372529 13010 net.cpp:150] Setting up BatchNorm8
I0702 00:34:49.372539 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372233 20914 net.cpp:150] Setting up BatchNorm10
I0702 00:34:49.372557 13010 net.cpp:165] Memory required for data: 2633740
I0702 00:34:49.371809 32261 net.cpp:150] Setting up ReLU9
I0702 00:34:49.372571 13010 layer_factory.hpp:77] Creating layer Scale8
I0702 00:34:49.372242 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372251 20914 net.cpp:165] Memory required for data: 2863116
I0702 00:34:49.371815 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.371824 32261 net.cpp:165] Memory required for data: 2961420
I0702 00:34:49.372583 13010 net.cpp:106] Creating Layer Scale8
I0702 00:34:49.372265 20914 layer_factory.hpp:77] Creating layer Scale10
I0702 00:34:49.371829 32261 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0702 00:34:49.371839 32261 net.cpp:106] Creating Layer Eltwise4_ReLU9_0_split
I0702 00:34:49.372277 20914 net.cpp:106] Creating Layer Scale10
I0702 00:34:49.372283 20914 net.cpp:454] Scale10 <- Convolution10
I0702 00:34:49.371845 32261 net.cpp:454] Eltwise4_ReLU9_0_split <- Eltwise4
I0702 00:34:49.371855 32261 net.cpp:411] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0702 00:34:49.372591 13010 net.cpp:454] Scale8 <- Convolution8
I0702 00:34:49.372295 20914 net.cpp:397] Scale10 -> Convolution10 (in-place)
I0702 00:34:49.371866 32261 net.cpp:411] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0702 00:34:49.372602 13010 net.cpp:397] Scale8 -> Convolution8 (in-place)
I0702 00:34:49.372313 20914 layer_factory.hpp:77] Creating layer Scale10
I0702 00:34:49.371879 32261 net.cpp:150] Setting up Eltwise4_ReLU9_0_split
I0702 00:34:49.372619 13010 layer_factory.hpp:77] Creating layer Scale8
I0702 00:34:49.372339 20914 net.cpp:150] Setting up Scale10
I0702 00:34:49.372347 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.371888 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372650 13010 net.cpp:150] Setting up Scale8
I0702 00:34:49.372356 20914 net.cpp:165] Memory required for data: 2895884
I0702 00:34:49.371896 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372370 20914 layer_factory.hpp:77] Creating layer Eltwise4
I0702 00:34:49.371904 32261 net.cpp:165] Memory required for data: 3026956
I0702 00:34:49.372380 20914 net.cpp:106] Creating Layer Eltwise4
I0702 00:34:49.371912 32261 layer_factory.hpp:77] Creating layer Convolution11
I0702 00:34:49.372661 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372387 20914 net.cpp:454] Eltwise4 <- Convolution8
I0702 00:34:49.372678 13010 net.cpp:165] Memory required for data: 2666508
I0702 00:34:49.372395 20914 net.cpp:454] Eltwise4 <- Convolution10
I0702 00:34:49.372690 13010 layer_factory.hpp:77] Creating layer Convolution9
I0702 00:34:49.372404 20914 net.cpp:411] Eltwise4 -> Eltwise4
I0702 00:34:49.372714 13010 net.cpp:106] Creating Layer Convolution9
I0702 00:34:49.372418 20914 net.cpp:150] Setting up Eltwise4
I0702 00:34:49.371929 32261 net.cpp:106] Creating Layer Convolution11
I0702 00:34:49.372725 13010 net.cpp:454] Convolution9 <- Eltwise3_ReLU7_0_split_1
I0702 00:34:49.372427 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372439 20914 net.cpp:165] Memory required for data: 2928652
I0702 00:34:49.371939 32261 net.cpp:454] Convolution11 <- Eltwise4_ReLU9_0_split_0
I0702 00:34:49.372741 13010 net.cpp:411] Convolution9 -> Convolution9
I0702 00:34:49.372447 20914 layer_factory.hpp:77] Creating layer ReLU9
I0702 00:34:49.372455 20914 net.cpp:106] Creating Layer ReLU9
I0702 00:34:49.371949 32261 net.cpp:411] Convolution11 -> Convolution11
I0702 00:34:49.372462 20914 net.cpp:454] ReLU9 <- Eltwise4
I0702 00:34:49.372470 20914 net.cpp:397] ReLU9 -> Eltwise4 (in-place)
I0702 00:34:49.372480 20914 net.cpp:150] Setting up ReLU9
I0702 00:34:49.372488 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372495 20914 net.cpp:165] Memory required for data: 2961420
I0702 00:34:49.372501 20914 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0702 00:34:49.372517 20914 net.cpp:106] Creating Layer Eltwise4_ReLU9_0_split
I0702 00:34:49.372205 32261 net.cpp:150] Setting up Convolution11
I0702 00:34:49.372527 20914 net.cpp:454] Eltwise4_ReLU9_0_split <- Eltwise4
I0702 00:34:49.372536 20914 net.cpp:411] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0702 00:34:49.372915 13010 net.cpp:150] Setting up Convolution9
I0702 00:34:49.372561 20914 net.cpp:411] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0702 00:34:49.372218 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372227 32261 net.cpp:165] Memory required for data: 3059724
I0702 00:34:49.372575 20914 net.cpp:150] Setting up Eltwise4_ReLU9_0_split
I0702 00:34:49.372581 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372238 32261 layer_factory.hpp:77] Creating layer BatchNorm11
I0702 00:34:49.372591 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372598 20914 net.cpp:165] Memory required for data: 3026956
I0702 00:34:49.372606 20914 layer_factory.hpp:77] Creating layer Convolution11
I0702 00:34:49.372928 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372625 20914 net.cpp:106] Creating Layer Convolution11
I0702 00:34:49.372946 13010 net.cpp:165] Memory required for data: 2699276
I0702 00:34:49.372635 20914 net.cpp:454] Convolution11 <- Eltwise4_ReLU9_0_split_0
I0702 00:34:49.372252 32261 net.cpp:106] Creating Layer BatchNorm11
I0702 00:34:49.372957 13010 layer_factory.hpp:77] Creating layer BatchNorm9
I0702 00:34:49.372647 20914 net.cpp:411] Convolution11 -> Convolution11
I0702 00:34:49.372277 32261 net.cpp:454] BatchNorm11 <- Convolution11
I0702 00:34:49.372968 13010 net.cpp:106] Creating Layer BatchNorm9
I0702 00:34:49.372287 32261 net.cpp:397] BatchNorm11 -> Convolution11 (in-place)
I0702 00:34:49.372977 13010 net.cpp:454] BatchNorm9 <- Convolution9
I0702 00:34:49.372311 32261 net.cpp:150] Setting up BatchNorm11
I0702 00:34:49.372989 13010 net.cpp:397] BatchNorm9 -> Convolution9 (in-place)
I0702 00:34:49.373018 13010 net.cpp:150] Setting up BatchNorm9
I0702 00:34:49.372320 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373028 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372329 32261 net.cpp:165] Memory required for data: 3092492
I0702 00:34:49.373036 13010 net.cpp:165] Memory required for data: 2732044
I0702 00:34:49.372352 32261 layer_factory.hpp:77] Creating layer Scale11
I0702 00:34:49.373050 13010 layer_factory.hpp:77] Creating layer Scale9
I0702 00:34:49.372365 32261 net.cpp:106] Creating Layer Scale11
I0702 00:34:49.373066 13010 net.cpp:106] Creating Layer Scale9
I0702 00:34:49.372372 32261 net.cpp:454] Scale11 <- Convolution11
I0702 00:34:49.373076 13010 net.cpp:454] Scale9 <- Convolution9
I0702 00:34:49.372381 32261 net.cpp:397] Scale11 -> Convolution11 (in-place)
I0702 00:34:49.373086 13010 net.cpp:397] Scale9 -> Convolution9 (in-place)
I0702 00:34:49.372400 32261 layer_factory.hpp:77] Creating layer Scale11
I0702 00:34:49.373103 13010 layer_factory.hpp:77] Creating layer Scale9
I0702 00:34:49.372428 32261 net.cpp:150] Setting up Scale11
I0702 00:34:49.373136 13010 net.cpp:150] Setting up Scale9
I0702 00:34:49.372438 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373147 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372447 32261 net.cpp:165] Memory required for data: 3125260
I0702 00:34:49.372458 32261 layer_factory.hpp:77] Creating layer ReLU10
I0702 00:34:49.373155 13010 net.cpp:165] Memory required for data: 2764812
I0702 00:34:49.373167 13010 layer_factory.hpp:77] Creating layer ReLU8
I0702 00:34:49.372473 32261 net.cpp:106] Creating Layer ReLU10
I0702 00:34:49.373176 13010 net.cpp:106] Creating Layer ReLU8
I0702 00:34:49.372481 32261 net.cpp:454] ReLU10 <- Convolution11
I0702 00:34:49.373183 13010 net.cpp:454] ReLU8 <- Convolution9
I0702 00:34:49.372490 32261 net.cpp:397] ReLU10 -> Convolution11 (in-place)
I0702 00:34:49.373191 13010 net.cpp:397] ReLU8 -> Convolution9 (in-place)
I0702 00:34:49.372500 32261 net.cpp:150] Setting up ReLU10
I0702 00:34:49.373203 13010 net.cpp:150] Setting up ReLU8
I0702 00:34:49.372506 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372514 32261 net.cpp:165] Memory required for data: 3158028
I0702 00:34:49.372521 32261 layer_factory.hpp:77] Creating layer Convolution12
I0702 00:34:49.373208 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373225 13010 net.cpp:165] Memory required for data: 2797580
I0702 00:34:49.373234 13010 layer_factory.hpp:77] Creating layer Convolution10
I0702 00:34:49.372543 32261 net.cpp:106] Creating Layer Convolution12
I0702 00:34:49.373257 13010 net.cpp:106] Creating Layer Convolution10
I0702 00:34:49.372910 20914 net.cpp:150] Setting up Convolution11
I0702 00:34:49.372552 32261 net.cpp:454] Convolution12 <- Convolution11
I0702 00:34:49.372563 32261 net.cpp:411] Convolution12 -> Convolution12
I0702 00:34:49.372923 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372933 20914 net.cpp:165] Memory required for data: 3059724
I0702 00:34:49.373268 13010 net.cpp:454] Convolution10 <- Convolution9
I0702 00:34:49.372944 20914 layer_factory.hpp:77] Creating layer BatchNorm11
I0702 00:34:49.372959 20914 net.cpp:106] Creating Layer BatchNorm11
I0702 00:34:49.372967 20914 net.cpp:454] BatchNorm11 <- Convolution11
I0702 00:34:49.373293 13010 net.cpp:411] Convolution10 -> Convolution10
I0702 00:34:49.372977 20914 net.cpp:397] BatchNorm11 -> Convolution11 (in-place)
I0702 00:34:49.373003 20914 net.cpp:150] Setting up BatchNorm11
I0702 00:34:49.373009 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373025 20914 net.cpp:165] Memory required for data: 3092492
I0702 00:34:49.373049 20914 layer_factory.hpp:77] Creating layer Scale11
I0702 00:34:49.373059 20914 net.cpp:106] Creating Layer Scale11
I0702 00:34:49.373067 20914 net.cpp:454] Scale11 <- Convolution11
I0702 00:34:49.373078 20914 net.cpp:397] Scale11 -> Convolution11 (in-place)
I0702 00:34:49.373095 20914 layer_factory.hpp:77] Creating layer Scale11
I0702 00:34:49.373121 20914 net.cpp:150] Setting up Scale11
I0702 00:34:49.372817 32261 net.cpp:150] Setting up Convolution12
I0702 00:34:49.373131 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373142 20914 net.cpp:165] Memory required for data: 3125260
I0702 00:34:49.373152 20914 layer_factory.hpp:77] Creating layer ReLU10
I0702 00:34:49.373163 20914 net.cpp:106] Creating Layer ReLU10
I0702 00:34:49.373172 20914 net.cpp:454] ReLU10 <- Convolution11
I0702 00:34:49.373180 20914 net.cpp:397] ReLU10 -> Convolution11 (in-place)
I0702 00:34:49.372829 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372838 32261 net.cpp:165] Memory required for data: 3190796
I0702 00:34:49.373195 20914 net.cpp:150] Setting up ReLU10
I0702 00:34:49.373203 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372849 32261 layer_factory.hpp:77] Creating layer BatchNorm12
I0702 00:34:49.373571 13010 net.cpp:150] Setting up Convolution10
I0702 00:34:49.373211 20914 net.cpp:165] Memory required for data: 3158028
I0702 00:34:49.373219 20914 layer_factory.hpp:77] Creating layer Convolution12
I0702 00:34:49.373245 20914 net.cpp:106] Creating Layer Convolution12
I0702 00:34:49.372864 32261 net.cpp:106] Creating Layer BatchNorm12
I0702 00:34:49.373586 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373595 13010 net.cpp:165] Memory required for data: 2830348
I0702 00:34:49.373255 20914 net.cpp:454] Convolution12 <- Convolution11
I0702 00:34:49.372872 32261 net.cpp:454] BatchNorm12 <- Convolution12
I0702 00:34:49.373625 13010 layer_factory.hpp:77] Creating layer BatchNorm10
I0702 00:34:49.373267 20914 net.cpp:411] Convolution12 -> Convolution12
I0702 00:34:49.372881 32261 net.cpp:397] BatchNorm12 -> Convolution12 (in-place)
I0702 00:34:49.372905 32261 net.cpp:150] Setting up BatchNorm12
I0702 00:34:49.372915 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373639 13010 net.cpp:106] Creating Layer BatchNorm10
I0702 00:34:49.372923 32261 net.cpp:165] Memory required for data: 3223564
I0702 00:34:49.373649 13010 net.cpp:454] BatchNorm10 <- Convolution10
I0702 00:34:49.373659 13010 net.cpp:397] BatchNorm10 -> Convolution10 (in-place)
I0702 00:34:49.372936 32261 layer_factory.hpp:77] Creating layer Scale12
I0702 00:34:49.372951 32261 net.cpp:106] Creating Layer Scale12
I0702 00:34:49.373687 13010 net.cpp:150] Setting up BatchNorm10
I0702 00:34:49.372959 32261 net.cpp:454] Scale12 <- Convolution12
I0702 00:34:49.373697 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372970 32261 net.cpp:397] Scale12 -> Convolution12 (in-place)
I0702 00:34:49.373713 13010 net.cpp:165] Memory required for data: 2863116
I0702 00:34:49.372987 32261 layer_factory.hpp:77] Creating layer Scale12
I0702 00:34:49.373015 32261 net.cpp:150] Setting up Scale12
I0702 00:34:49.373728 13010 layer_factory.hpp:77] Creating layer Scale10
I0702 00:34:49.373739 13010 net.cpp:106] Creating Layer Scale10
I0702 00:34:49.373746 13010 net.cpp:454] Scale10 <- Convolution10
I0702 00:34:49.373759 13010 net.cpp:397] Scale10 -> Convolution10 (in-place)
I0702 00:34:49.373025 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373034 32261 net.cpp:165] Memory required for data: 3256332
I0702 00:34:49.373045 32261 layer_factory.hpp:77] Creating layer Eltwise5
I0702 00:34:49.373057 32261 net.cpp:106] Creating Layer Eltwise5
I0702 00:34:49.373066 32261 net.cpp:454] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0702 00:34:49.373775 13010 layer_factory.hpp:77] Creating layer Scale10
I0702 00:34:49.373075 32261 net.cpp:454] Eltwise5 <- Convolution12
I0702 00:34:49.373807 13010 net.cpp:150] Setting up Scale10
I0702 00:34:49.373083 32261 net.cpp:411] Eltwise5 -> Eltwise5
I0702 00:34:49.373818 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373834 13010 net.cpp:165] Memory required for data: 2895884
I0702 00:34:49.373096 32261 net.cpp:150] Setting up Eltwise5
I0702 00:34:49.373847 13010 layer_factory.hpp:77] Creating layer Eltwise4
I0702 00:34:49.373105 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373113 32261 net.cpp:165] Memory required for data: 3289100
I0702 00:34:49.373857 13010 net.cpp:106] Creating Layer Eltwise4
I0702 00:34:49.373119 32261 layer_factory.hpp:77] Creating layer ReLU11
I0702 00:34:49.373131 32261 net.cpp:106] Creating Layer ReLU11
I0702 00:34:49.373138 32261 net.cpp:454] ReLU11 <- Eltwise5
I0702 00:34:49.373147 32261 net.cpp:397] ReLU11 -> Eltwise5 (in-place)
I0702 00:34:49.373157 32261 net.cpp:150] Setting up ReLU11
I0702 00:34:49.373864 13010 net.cpp:454] Eltwise4 <- Convolution8
I0702 00:34:49.373162 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373872 13010 net.cpp:454] Eltwise4 <- Convolution10
I0702 00:34:49.373548 20914 net.cpp:150] Setting up Convolution12
I0702 00:34:49.373881 13010 net.cpp:411] Eltwise4 -> Eltwise4
I0702 00:34:49.373896 13010 net.cpp:150] Setting up Eltwise4
I0702 00:34:49.373170 32261 net.cpp:165] Memory required for data: 3321868
I0702 00:34:49.373178 32261 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0702 00:34:49.373185 32261 net.cpp:106] Creating Layer Eltwise5_ReLU11_0_split
I0702 00:34:49.373193 32261 net.cpp:454] Eltwise5_ReLU11_0_split <- Eltwise5
I0702 00:34:49.373564 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373574 20914 net.cpp:165] Memory required for data: 3190796
I0702 00:34:49.373203 32261 net.cpp:411] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0702 00:34:49.373215 32261 net.cpp:411] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0702 00:34:49.373905 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373584 20914 layer_factory.hpp:77] Creating layer BatchNorm12
I0702 00:34:49.373232 32261 net.cpp:150] Setting up Eltwise5_ReLU11_0_split
I0702 00:34:49.373914 13010 net.cpp:165] Memory required for data: 2928652
I0702 00:34:49.373603 20914 net.cpp:106] Creating Layer BatchNorm12
I0702 00:34:49.373613 20914 net.cpp:454] BatchNorm12 <- Convolution12
I0702 00:34:49.373623 20914 net.cpp:397] BatchNorm12 -> Convolution12 (in-place)
I0702 00:34:49.373247 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373920 13010 layer_factory.hpp:77] Creating layer ReLU9
I0702 00:34:49.373652 20914 net.cpp:150] Setting up BatchNorm12
I0702 00:34:49.373929 13010 net.cpp:106] Creating Layer ReLU9
I0702 00:34:49.373936 13010 net.cpp:454] ReLU9 <- Eltwise4
I0702 00:34:49.373661 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373263 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373945 13010 net.cpp:397] ReLU9 -> Eltwise4 (in-place)
I0702 00:34:49.373670 20914 net.cpp:165] Memory required for data: 3223564
I0702 00:34:49.373273 32261 net.cpp:165] Memory required for data: 3387404
I0702 00:34:49.373281 32261 layer_factory.hpp:77] Creating layer Convolution13
I0702 00:34:49.373955 13010 net.cpp:150] Setting up ReLU9
I0702 00:34:49.373687 20914 layer_factory.hpp:77] Creating layer Scale12
I0702 00:34:49.373302 32261 net.cpp:106] Creating Layer Convolution13
I0702 00:34:49.373963 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373697 20914 net.cpp:106] Creating Layer Scale12
I0702 00:34:49.373312 32261 net.cpp:454] Convolution13 <- Eltwise5_ReLU11_0_split_0
I0702 00:34:49.373704 20914 net.cpp:454] Scale12 <- Convolution12
I0702 00:34:49.373713 20914 net.cpp:397] Scale12 -> Convolution12 (in-place)
I0702 00:34:49.373323 32261 net.cpp:411] Convolution13 -> Convolution13
I0702 00:34:49.373740 20914 layer_factory.hpp:77] Creating layer Scale12
I0702 00:34:49.373971 13010 net.cpp:165] Memory required for data: 2961420
I0702 00:34:49.373775 20914 net.cpp:150] Setting up Scale12
I0702 00:34:49.373978 13010 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0702 00:34:49.373786 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373987 13010 net.cpp:106] Creating Layer Eltwise4_ReLU9_0_split
I0702 00:34:49.373993 13010 net.cpp:454] Eltwise4_ReLU9_0_split <- Eltwise4
I0702 00:34:49.373795 20914 net.cpp:165] Memory required for data: 3256332
I0702 00:34:49.374008 13010 net.cpp:411] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0702 00:34:49.373807 20914 layer_factory.hpp:77] Creating layer Eltwise5
I0702 00:34:49.374024 13010 net.cpp:411] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0702 00:34:49.373819 20914 net.cpp:106] Creating Layer Eltwise5
I0702 00:34:49.374037 13010 net.cpp:150] Setting up Eltwise4_ReLU9_0_split
I0702 00:34:49.373828 20914 net.cpp:454] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0702 00:34:49.374045 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373836 20914 net.cpp:454] Eltwise5 <- Convolution12
I0702 00:34:49.374054 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373845 20914 net.cpp:411] Eltwise5 -> Eltwise5
I0702 00:34:49.374063 13010 net.cpp:165] Memory required for data: 3026956
I0702 00:34:49.373858 20914 net.cpp:150] Setting up Eltwise5
I0702 00:34:49.373865 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374069 13010 layer_factory.hpp:77] Creating layer Convolution11
I0702 00:34:49.373874 20914 net.cpp:165] Memory required for data: 3289100
I0702 00:34:49.374090 13010 net.cpp:106] Creating Layer Convolution11
I0702 00:34:49.373880 20914 layer_factory.hpp:77] Creating layer ReLU11
I0702 00:34:49.374101 13010 net.cpp:454] Convolution11 <- Eltwise4_ReLU9_0_split_0
I0702 00:34:49.373908 20914 net.cpp:106] Creating Layer ReLU11
I0702 00:34:49.373585 32261 net.cpp:150] Setting up Convolution13
I0702 00:34:49.373921 20914 net.cpp:454] ReLU11 <- Eltwise5
I0702 00:34:49.373931 20914 net.cpp:397] ReLU11 -> Eltwise5 (in-place)
I0702 00:34:49.374114 13010 net.cpp:411] Convolution11 -> Convolution11
I0702 00:34:49.373956 20914 net.cpp:150] Setting up ReLU11
I0702 00:34:49.373600 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373611 32261 net.cpp:165] Memory required for data: 3420172
I0702 00:34:49.373965 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373973 20914 net.cpp:165] Memory required for data: 3321868
I0702 00:34:49.373623 32261 layer_factory.hpp:77] Creating layer BatchNorm13
I0702 00:34:49.373980 20914 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0702 00:34:49.373989 20914 net.cpp:106] Creating Layer Eltwise5_ReLU11_0_split
I0702 00:34:49.373996 20914 net.cpp:454] Eltwise5_ReLU11_0_split <- Eltwise5
I0702 00:34:49.374009 20914 net.cpp:411] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0702 00:34:49.373636 32261 net.cpp:106] Creating Layer BatchNorm13
I0702 00:34:49.374387 13010 net.cpp:150] Setting up Convolution11
I0702 00:34:49.374022 20914 net.cpp:411] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0702 00:34:49.373642 32261 net.cpp:454] BatchNorm13 <- Convolution13
I0702 00:34:49.373654 32261 net.cpp:397] BatchNorm13 -> Convolution13 (in-place)
I0702 00:34:49.374035 20914 net.cpp:150] Setting up Eltwise5_ReLU11_0_split
I0702 00:34:49.373678 32261 net.cpp:150] Setting up BatchNorm13
I0702 00:34:49.373687 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374418 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374050 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374060 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373697 32261 net.cpp:165] Memory required for data: 3452940
I0702 00:34:49.374430 13010 net.cpp:165] Memory required for data: 3059724
I0702 00:34:49.374078 20914 net.cpp:165] Memory required for data: 3387404
I0702 00:34:49.374085 20914 layer_factory.hpp:77] Creating layer Convolution13
I0702 00:34:49.373709 32261 layer_factory.hpp:77] Creating layer Scale13
I0702 00:34:49.373721 32261 net.cpp:106] Creating Layer Scale13
I0702 00:34:49.374444 13010 layer_factory.hpp:77] Creating layer BatchNorm11
I0702 00:34:49.374107 20914 net.cpp:106] Creating Layer Convolution13
I0702 00:34:49.374117 20914 net.cpp:454] Convolution13 <- Eltwise5_ReLU11_0_split_0
I0702 00:34:49.373728 32261 net.cpp:454] Scale13 <- Convolution13
I0702 00:34:49.374460 13010 net.cpp:106] Creating Layer BatchNorm11
I0702 00:34:49.374133 20914 net.cpp:411] Convolution13 -> Convolution13
I0702 00:34:49.373739 32261 net.cpp:397] Scale13 -> Convolution13 (in-place)
I0702 00:34:49.374471 13010 net.cpp:454] BatchNorm11 <- Convolution11
I0702 00:34:49.373756 32261 layer_factory.hpp:77] Creating layer Scale13
I0702 00:34:49.374485 13010 net.cpp:397] BatchNorm11 -> Convolution11 (in-place)
I0702 00:34:49.373786 32261 net.cpp:150] Setting up Scale13
I0702 00:34:49.373795 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373805 32261 net.cpp:165] Memory required for data: 3485708
I0702 00:34:49.374511 13010 net.cpp:150] Setting up BatchNorm11
I0702 00:34:49.374523 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374533 13010 net.cpp:165] Memory required for data: 3092492
I0702 00:34:49.373816 32261 layer_factory.hpp:77] Creating layer ReLU12
I0702 00:34:49.374555 13010 layer_factory.hpp:77] Creating layer Scale11
I0702 00:34:49.373826 32261 net.cpp:106] Creating Layer ReLU12
I0702 00:34:49.374568 13010 net.cpp:106] Creating Layer Scale11
I0702 00:34:49.373832 32261 net.cpp:454] ReLU12 <- Convolution13
I0702 00:34:49.374575 13010 net.cpp:454] Scale11 <- Convolution11
I0702 00:34:49.373841 32261 net.cpp:397] ReLU12 -> Convolution13 (in-place)
I0702 00:34:49.373850 32261 net.cpp:150] Setting up ReLU12
I0702 00:34:49.373857 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373864 32261 net.cpp:165] Memory required for data: 3518476
I0702 00:34:49.373872 32261 layer_factory.hpp:77] Creating layer Convolution14
I0702 00:34:49.374589 13010 net.cpp:397] Scale11 -> Convolution11 (in-place)
I0702 00:34:49.373898 32261 net.cpp:106] Creating Layer Convolution14
I0702 00:34:49.374611 13010 layer_factory.hpp:77] Creating layer Scale11
I0702 00:34:49.373908 32261 net.cpp:454] Convolution14 <- Convolution13
I0702 00:34:49.374641 13010 net.cpp:150] Setting up Scale11
I0702 00:34:49.373919 32261 net.cpp:411] Convolution14 -> Convolution14
I0702 00:34:49.374652 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374661 13010 net.cpp:165] Memory required for data: 3125260
I0702 00:34:49.374676 13010 layer_factory.hpp:77] Creating layer ReLU10
I0702 00:34:49.374687 13010 net.cpp:106] Creating Layer ReLU10
I0702 00:34:49.374694 13010 net.cpp:454] ReLU10 <- Convolution11
I0702 00:34:49.374703 13010 net.cpp:397] ReLU10 -> Convolution11 (in-place)
I0702 00:34:49.374713 13010 net.cpp:150] Setting up ReLU10
I0702 00:34:49.374720 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374728 13010 net.cpp:165] Memory required for data: 3158028
I0702 00:34:49.374734 13010 layer_factory.hpp:77] Creating layer Convolution12
I0702 00:34:49.374416 20914 net.cpp:150] Setting up Convolution13
I0702 00:34:49.374758 13010 net.cpp:106] Creating Layer Convolution12
I0702 00:34:49.374769 13010 net.cpp:454] Convolution12 <- Convolution11
I0702 00:34:49.374781 13010 net.cpp:411] Convolution12 -> Convolution12
I0702 00:34:49.374431 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374440 20914 net.cpp:165] Memory required for data: 3420172
I0702 00:34:49.374455 20914 layer_factory.hpp:77] Creating layer BatchNorm13
I0702 00:34:49.374467 20914 net.cpp:106] Creating Layer BatchNorm13
I0702 00:34:49.374475 20914 net.cpp:454] BatchNorm13 <- Convolution13
I0702 00:34:49.374490 20914 net.cpp:397] BatchNorm13 -> Convolution13 (in-place)
I0702 00:34:49.374176 32261 net.cpp:150] Setting up Convolution14
I0702 00:34:49.374521 20914 net.cpp:150] Setting up BatchNorm13
I0702 00:34:49.374188 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374197 32261 net.cpp:165] Memory required for data: 3551244
I0702 00:34:49.374531 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374541 20914 net.cpp:165] Memory required for data: 3452940
I0702 00:34:49.374209 32261 layer_factory.hpp:77] Creating layer BatchNorm14
I0702 00:34:49.374553 20914 layer_factory.hpp:77] Creating layer Scale13
I0702 00:34:49.374567 20914 net.cpp:106] Creating Layer Scale13
I0702 00:34:49.374574 20914 net.cpp:454] Scale13 <- Convolution13
I0702 00:34:49.374583 20914 net.cpp:397] Scale13 -> Convolution13 (in-place)
I0702 00:34:49.374224 32261 net.cpp:106] Creating Layer BatchNorm14
I0702 00:34:49.374599 20914 layer_factory.hpp:77] Creating layer Scale13
I0702 00:34:49.374233 32261 net.cpp:454] BatchNorm14 <- Convolution14
I0702 00:34:49.374630 20914 net.cpp:150] Setting up Scale13
I0702 00:34:49.374243 32261 net.cpp:397] BatchNorm14 -> Convolution14 (in-place)
I0702 00:34:49.374642 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374660 20914 net.cpp:165] Memory required for data: 3485708
I0702 00:34:49.374671 20914 layer_factory.hpp:77] Creating layer ReLU12
I0702 00:34:49.374274 32261 net.cpp:150] Setting up BatchNorm14
I0702 00:34:49.374681 20914 net.cpp:106] Creating Layer ReLU12
I0702 00:34:49.374284 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374688 20914 net.cpp:454] ReLU12 <- Convolution13
I0702 00:34:49.374294 32261 net.cpp:165] Memory required for data: 3584012
I0702 00:34:49.375051 13010 net.cpp:150] Setting up Convolution12
I0702 00:34:49.374701 20914 net.cpp:397] ReLU12 -> Convolution13 (in-place)
I0702 00:34:49.374310 32261 layer_factory.hpp:77] Creating layer Scale14
I0702 00:34:49.374711 20914 net.cpp:150] Setting up ReLU12
I0702 00:34:49.374717 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374322 32261 net.cpp:106] Creating Layer Scale14
I0702 00:34:49.374725 20914 net.cpp:165] Memory required for data: 3518476
I0702 00:34:49.374328 32261 net.cpp:454] Scale14 <- Convolution14
I0702 00:34:49.375064 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.375073 13010 net.cpp:165] Memory required for data: 3190796
I0702 00:34:49.374732 20914 layer_factory.hpp:77] Creating layer Convolution14
I0702 00:34:49.374338 32261 net.cpp:397] Scale14 -> Convolution14 (in-place)
I0702 00:34:49.375085 13010 layer_factory.hpp:77] Creating layer BatchNorm12
I0702 00:34:49.374760 20914 net.cpp:106] Creating Layer Convolution14
I0702 00:34:49.375102 13010 net.cpp:106] Creating Layer BatchNorm12
I0702 00:34:49.374773 20914 net.cpp:454] Convolution14 <- Convolution13
I0702 00:34:49.375110 13010 net.cpp:454] BatchNorm12 <- Convolution12
I0702 00:34:49.374784 20914 net.cpp:411] Convolution14 -> Convolution14
I0702 00:34:49.374357 32261 layer_factory.hpp:77] Creating layer Scale14
I0702 00:34:49.375119 13010 net.cpp:397] BatchNorm12 -> Convolution12 (in-place)
I0702 00:34:49.374385 32261 net.cpp:150] Setting up Scale14
I0702 00:34:49.374395 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374404 32261 net.cpp:165] Memory required for data: 3616780
I0702 00:34:49.374415 32261 layer_factory.hpp:77] Creating layer Eltwise6
I0702 00:34:49.374429 32261 net.cpp:106] Creating Layer Eltwise6
I0702 00:34:49.375146 13010 net.cpp:150] Setting up BatchNorm12
I0702 00:34:49.374439 32261 net.cpp:454] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0702 00:34:49.375156 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374454 32261 net.cpp:454] Eltwise6 <- Convolution14
I0702 00:34:49.375172 13010 net.cpp:165] Memory required for data: 3223564
I0702 00:34:49.374464 32261 net.cpp:411] Eltwise6 -> Eltwise6
I0702 00:34:49.375186 13010 layer_factory.hpp:77] Creating layer Scale12
I0702 00:34:49.374477 32261 net.cpp:150] Setting up Eltwise6
I0702 00:34:49.375198 13010 net.cpp:106] Creating Layer Scale12
I0702 00:34:49.375205 13010 net.cpp:454] Scale12 <- Convolution12
I0702 00:34:49.374485 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374493 32261 net.cpp:165] Memory required for data: 3649548
I0702 00:34:49.374500 32261 layer_factory.hpp:77] Creating layer ReLU13
I0702 00:34:49.375218 13010 net.cpp:397] Scale12 -> Convolution12 (in-place)
I0702 00:34:49.374510 32261 net.cpp:106] Creating Layer ReLU13
I0702 00:34:49.375237 13010 layer_factory.hpp:77] Creating layer Scale12
I0702 00:34:49.374516 32261 net.cpp:454] ReLU13 <- Eltwise6
I0702 00:34:49.375270 13010 net.cpp:150] Setting up Scale12
I0702 00:34:49.374526 32261 net.cpp:397] ReLU13 -> Eltwise6 (in-place)
I0702 00:34:49.374536 32261 net.cpp:150] Setting up ReLU13
I0702 00:34:49.374542 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374550 32261 net.cpp:165] Memory required for data: 3682316
I0702 00:34:49.374557 32261 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0702 00:34:49.375282 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374567 32261 net.cpp:106] Creating Layer Eltwise6_ReLU13_0_split
I0702 00:34:49.375290 13010 net.cpp:165] Memory required for data: 3256332
I0702 00:34:49.374572 32261 net.cpp:454] Eltwise6_ReLU13_0_split <- Eltwise6
I0702 00:34:49.375303 13010 layer_factory.hpp:77] Creating layer Eltwise5
I0702 00:34:49.375317 13010 net.cpp:106] Creating Layer Eltwise5
I0702 00:34:49.375327 13010 net.cpp:454] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0702 00:34:49.374583 32261 net.cpp:411] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0702 00:34:49.374596 32261 net.cpp:411] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0702 00:34:49.374608 32261 net.cpp:150] Setting up Eltwise6_ReLU13_0_split
I0702 00:34:49.374614 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.375336 13010 net.cpp:454] Eltwise5 <- Convolution12
I0702 00:34:49.374624 32261 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.375346 13010 net.cpp:411] Eltwise5 -> Eltwise5
I0702 00:34:49.374631 32261 net.cpp:165] Memory required for data: 3747852
I0702 00:34:49.375360 13010 net.cpp:150] Setting up Eltwise5
I0702 00:34:49.374637 32261 layer_factory.hpp:77] Creating layer Convolution15
I0702 00:34:49.375367 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374656 32261 net.cpp:106] Creating Layer Convolution15
I0702 00:34:49.375376 13010 net.cpp:165] Memory required for data: 3289100
I0702 00:34:49.374665 32261 net.cpp:454] Convolution15 <- Eltwise6_ReLU13_0_split_0
I0702 00:34:49.375382 13010 layer_factory.hpp:77] Creating layer ReLU11
I0702 00:34:49.374676 32261 net.cpp:411] Convolution15 -> Convolution15
I0702 00:34:49.375394 13010 net.cpp:106] Creating Layer ReLU11
I0702 00:34:49.375411 13010 net.cpp:454] ReLU11 <- Eltwise5
I0702 00:34:49.375419 13010 net.cpp:397] ReLU11 -> Eltwise5 (in-place)
I0702 00:34:49.375430 13010 net.cpp:150] Setting up ReLU11
I0702 00:34:49.375437 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.375445 13010 net.cpp:165] Memory required for data: 3321868
I0702 00:34:49.375074 20914 net.cpp:150] Setting up Convolution14
I0702 00:34:49.375089 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.375099 20914 net.cpp:165] Memory required for data: 3551244
I0702 00:34:49.374791 32261 net.cpp:150] Setting up Convolution15
I0702 00:34:49.375111 20914 layer_factory.hpp:77] Creating layer BatchNorm14
I0702 00:34:49.375125 20914 net.cpp:106] Creating Layer BatchNorm14
I0702 00:34:49.375452 13010 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0702 00:34:49.375133 20914 net.cpp:454] BatchNorm14 <- Convolution14
I0702 00:34:49.375142 20914 net.cpp:397] BatchNorm14 -> Convolution14 (in-place)
I0702 00:34:49.374804 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.374814 32261 net.cpp:165] Memory required for data: 3764236
I0702 00:34:49.375460 13010 net.cpp:106] Creating Layer Eltwise5_ReLU11_0_split
I0702 00:34:49.375171 20914 net.cpp:150] Setting up BatchNorm14
I0702 00:34:49.374825 32261 layer_factory.hpp:77] Creating layer BatchNorm15
I0702 00:34:49.375468 13010 net.cpp:454] Eltwise5_ReLU11_0_split <- Eltwise5
I0702 00:34:49.375180 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374835 32261 net.cpp:106] Creating Layer BatchNorm15
I0702 00:34:49.375481 13010 net.cpp:411] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0702 00:34:49.375195 20914 net.cpp:165] Memory required for data: 3584012
I0702 00:34:49.375495 13010 net.cpp:411] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0702 00:34:49.375208 20914 layer_factory.hpp:77] Creating layer Scale14
I0702 00:34:49.375219 20914 net.cpp:106] Creating Layer Scale14
I0702 00:34:49.374843 32261 net.cpp:454] BatchNorm15 <- Convolution15
I0702 00:34:49.375233 20914 net.cpp:454] Scale14 <- Convolution14
I0702 00:34:49.374855 32261 net.cpp:397] BatchNorm15 -> Convolution15 (in-place)
I0702 00:34:49.375512 13010 net.cpp:150] Setting up Eltwise5_ReLU11_0_split
I0702 00:34:49.375247 20914 net.cpp:397] Scale14 -> Convolution14 (in-place)
I0702 00:34:49.374879 32261 net.cpp:150] Setting up BatchNorm15
I0702 00:34:49.375527 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.375263 20914 layer_factory.hpp:77] Creating layer Scale14
I0702 00:34:49.374887 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.375537 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.375295 20914 net.cpp:150] Setting up Scale14
I0702 00:34:49.374897 32261 net.cpp:165] Memory required for data: 3780620
I0702 00:34:49.375548 13010 net.cpp:165] Memory required for data: 3387404
I0702 00:34:49.375308 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374909 32261 layer_factory.hpp:77] Creating layer Scale15
I0702 00:34:49.375555 13010 layer_factory.hpp:77] Creating layer Convolution13
I0702 00:34:49.375316 20914 net.cpp:165] Memory required for data: 3616780
I0702 00:34:49.375577 13010 net.cpp:106] Creating Layer Convolution13
I0702 00:34:49.375329 20914 layer_factory.hpp:77] Creating layer Eltwise6
I0702 00:34:49.375588 13010 net.cpp:454] Convolution13 <- Eltwise5_ReLU11_0_split_0
I0702 00:34:49.375344 20914 net.cpp:106] Creating Layer Eltwise6
I0702 00:34:49.374922 32261 net.cpp:106] Creating Layer Scale15
I0702 00:34:49.375602 13010 net.cpp:411] Convolution13 -> Convolution13
I0702 00:34:49.375355 20914 net.cpp:454] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0702 00:34:49.374928 32261 net.cpp:454] Scale15 <- Convolution15
I0702 00:34:49.375372 20914 net.cpp:454] Eltwise6 <- Convolution14
I0702 00:34:49.374939 32261 net.cpp:397] Scale15 -> Convolution15 (in-place)
I0702 00:34:49.375383 20914 net.cpp:411] Eltwise6 -> Eltwise6
I0702 00:34:49.374958 32261 layer_factory.hpp:77] Creating layer Scale15
I0702 00:34:49.375397 20914 net.cpp:150] Setting up Eltwise6
I0702 00:34:49.375404 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374985 32261 net.cpp:150] Setting up Scale15
I0702 00:34:49.375413 20914 net.cpp:165] Memory required for data: 3649548
I0702 00:34:49.374995 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.375421 20914 layer_factory.hpp:77] Creating layer ReLU13
I0702 00:34:49.375005 32261 net.cpp:165] Memory required for data: 3797004
I0702 00:34:49.375432 20914 net.cpp:106] Creating Layer ReLU13
I0702 00:34:49.375015 32261 layer_factory.hpp:77] Creating layer Convolution16
I0702 00:34:49.375438 20914 net.cpp:454] ReLU13 <- Eltwise6
I0702 00:34:49.375447 20914 net.cpp:397] ReLU13 -> Eltwise6 (in-place)
I0702 00:34:49.375457 20914 net.cpp:150] Setting up ReLU13
I0702 00:34:49.375463 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.375471 20914 net.cpp:165] Memory required for data: 3682316
I0702 00:34:49.375038 32261 net.cpp:106] Creating Layer Convolution16
I0702 00:34:49.375478 20914 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0702 00:34:49.375047 32261 net.cpp:454] Convolution16 <- Eltwise6_ReLU13_0_split_1
I0702 00:34:49.375486 20914 net.cpp:106] Creating Layer Eltwise6_ReLU13_0_split
I0702 00:34:49.375494 20914 net.cpp:454] Eltwise6_ReLU13_0_split <- Eltwise6
I0702 00:34:49.375061 32261 net.cpp:411] Convolution16 -> Convolution16
I0702 00:34:49.375872 13010 net.cpp:150] Setting up Convolution13
I0702 00:34:49.375506 20914 net.cpp:411] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0702 00:34:49.375520 20914 net.cpp:411] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0702 00:34:49.375533 20914 net.cpp:150] Setting up Eltwise6_ReLU13_0_split
I0702 00:34:49.375540 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.375550 20914 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.375557 20914 net.cpp:165] Memory required for data: 3747852
I0702 00:34:49.375886 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.375563 20914 layer_factory.hpp:77] Creating layer Convolution15
I0702 00:34:49.375901 13010 net.cpp:165] Memory required for data: 3420172
I0702 00:34:49.375587 20914 net.cpp:106] Creating Layer Convolution15
I0702 00:34:49.375914 13010 layer_factory.hpp:77] Creating layer BatchNorm13
I0702 00:34:49.375598 20914 net.cpp:454] Convolution15 <- Eltwise6_ReLU13_0_split_0
I0702 00:34:49.375926 13010 net.cpp:106] Creating Layer BatchNorm13
I0702 00:34:49.375610 20914 net.cpp:411] Convolution15 -> Convolution15
I0702 00:34:49.375934 13010 net.cpp:454] BatchNorm13 <- Convolution13
I0702 00:34:49.375946 13010 net.cpp:397] BatchNorm13 -> Convolution13 (in-place)
I0702 00:34:49.375973 13010 net.cpp:150] Setting up BatchNorm13
I0702 00:34:49.375984 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.375993 13010 net.cpp:165] Memory required for data: 3452940
I0702 00:34:49.376006 13010 layer_factory.hpp:77] Creating layer Scale13
I0702 00:34:49.376019 13010 net.cpp:106] Creating Layer Scale13
I0702 00:34:49.376025 13010 net.cpp:454] Scale13 <- Convolution13
I0702 00:34:49.376039 13010 net.cpp:397] Scale13 -> Convolution13 (in-place)
I0702 00:34:49.376060 13010 layer_factory.hpp:77] Creating layer Scale13
I0702 00:34:49.375731 20914 net.cpp:150] Setting up Convolution15
I0702 00:34:49.376093 13010 net.cpp:150] Setting up Scale13
I0702 00:34:49.375746 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.375756 20914 net.cpp:165] Memory required for data: 3764236
I0702 00:34:49.376104 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.376113 13010 net.cpp:165] Memory required for data: 3485708
I0702 00:34:49.376125 13010 layer_factory.hpp:77] Creating layer ReLU12
I0702 00:34:49.375767 20914 layer_factory.hpp:77] Creating layer BatchNorm15
I0702 00:34:49.375778 20914 net.cpp:106] Creating Layer BatchNorm15
I0702 00:34:49.375785 20914 net.cpp:454] BatchNorm15 <- Convolution15
I0702 00:34:49.375802 20914 net.cpp:397] BatchNorm15 -> Convolution15 (in-place)
I0702 00:34:49.376137 13010 net.cpp:106] Creating Layer ReLU12
I0702 00:34:49.375829 20914 net.cpp:150] Setting up BatchNorm15
I0702 00:34:49.376143 13010 net.cpp:454] ReLU12 <- Convolution13
I0702 00:34:49.375838 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.375514 32261 net.cpp:150] Setting up Convolution16
I0702 00:34:49.376152 13010 net.cpp:397] ReLU12 -> Convolution13 (in-place)
I0702 00:34:49.375847 20914 net.cpp:165] Memory required for data: 3780620
I0702 00:34:49.376161 13010 net.cpp:150] Setting up ReLU12
I0702 00:34:49.375860 20914 layer_factory.hpp:77] Creating layer Scale15
I0702 00:34:49.376168 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.375874 20914 net.cpp:106] Creating Layer Scale15
I0702 00:34:49.375881 20914 net.cpp:454] Scale15 <- Convolution15
I0702 00:34:49.376176 13010 net.cpp:165] Memory required for data: 3518476
I0702 00:34:49.375890 20914 net.cpp:397] Scale15 -> Convolution15 (in-place)
I0702 00:34:49.375528 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.375537 32261 net.cpp:165] Memory required for data: 3813388
I0702 00:34:49.375907 20914 layer_factory.hpp:77] Creating layer Scale15
I0702 00:34:49.375550 32261 layer_factory.hpp:77] Creating layer BatchNorm16
I0702 00:34:49.375560 32261 net.cpp:106] Creating Layer BatchNorm16
I0702 00:34:49.376183 13010 layer_factory.hpp:77] Creating layer Convolution14
I0702 00:34:49.375942 20914 net.cpp:150] Setting up Scale15
I0702 00:34:49.375568 32261 net.cpp:454] BatchNorm16 <- Convolution16
I0702 00:34:49.376212 13010 net.cpp:106] Creating Layer Convolution14
I0702 00:34:49.375955 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.376224 13010 net.cpp:454] Convolution14 <- Convolution13
I0702 00:34:49.375964 20914 net.cpp:165] Memory required for data: 3797004
I0702 00:34:49.375977 20914 layer_factory.hpp:77] Creating layer Convolution16
I0702 00:34:49.376236 13010 net.cpp:411] Convolution14 -> Convolution14
I0702 00:34:49.375581 32261 net.cpp:397] BatchNorm16 -> Convolution16 (in-place)
I0702 00:34:49.375607 32261 net.cpp:150] Setting up BatchNorm16
I0702 00:34:49.376015 20914 net.cpp:106] Creating Layer Convolution16
I0702 00:34:49.375615 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.376027 20914 net.cpp:454] Convolution16 <- Eltwise6_ReLU13_0_split_1
I0702 00:34:49.375623 32261 net.cpp:165] Memory required for data: 3829772
I0702 00:34:49.376044 20914 net.cpp:411] Convolution16 -> Convolution16
I0702 00:34:49.375645 32261 layer_factory.hpp:77] Creating layer Scale16
I0702 00:34:49.375660 32261 net.cpp:106] Creating Layer Scale16
I0702 00:34:49.375669 32261 net.cpp:454] Scale16 <- Convolution16
I0702 00:34:49.375679 32261 net.cpp:397] Scale16 -> Convolution16 (in-place)
I0702 00:34:49.375695 32261 layer_factory.hpp:77] Creating layer Scale16
I0702 00:34:49.375725 32261 net.cpp:150] Setting up Scale16
I0702 00:34:49.375735 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.375744 32261 net.cpp:165] Memory required for data: 3846156
I0702 00:34:49.375756 32261 layer_factory.hpp:77] Creating layer ReLU14
I0702 00:34:49.375767 32261 net.cpp:106] Creating Layer ReLU14
I0702 00:34:49.376519 13010 net.cpp:150] Setting up Convolution14
I0702 00:34:49.375773 32261 net.cpp:454] ReLU14 <- Convolution16
I0702 00:34:49.375785 32261 net.cpp:397] ReLU14 -> Convolution16 (in-place)
I0702 00:34:49.375795 32261 net.cpp:150] Setting up ReLU14
I0702 00:34:49.375802 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.375811 32261 net.cpp:165] Memory required for data: 3862540
I0702 00:34:49.375818 32261 layer_factory.hpp:77] Creating layer Convolution17
I0702 00:34:49.376534 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.376543 13010 net.cpp:165] Memory required for data: 3551244
I0702 00:34:49.376556 13010 layer_factory.hpp:77] Creating layer BatchNorm14
I0702 00:34:49.375840 32261 net.cpp:106] Creating Layer Convolution17
I0702 00:34:49.375850 32261 net.cpp:454] Convolution17 <- Convolution16
I0702 00:34:49.375860 32261 net.cpp:411] Convolution17 -> Convolution17
I0702 00:34:49.376574 13010 net.cpp:106] Creating Layer BatchNorm14
I0702 00:34:49.376585 13010 net.cpp:454] BatchNorm14 <- Convolution14
I0702 00:34:49.376595 13010 net.cpp:397] BatchNorm14 -> Convolution14 (in-place)
I0702 00:34:49.376626 13010 net.cpp:150] Setting up BatchNorm14
I0702 00:34:49.376637 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.376646 13010 net.cpp:165] Memory required for data: 3584012
I0702 00:34:49.376662 13010 layer_factory.hpp:77] Creating layer Scale14
I0702 00:34:49.376674 13010 net.cpp:106] Creating Layer Scale14
I0702 00:34:49.376682 13010 net.cpp:454] Scale14 <- Convolution14
I0702 00:34:49.376690 13010 net.cpp:397] Scale14 -> Convolution14 (in-place)
I0702 00:34:49.376713 13010 layer_factory.hpp:77] Creating layer Scale14
I0702 00:34:49.368300  4664 net.cpp:397] ReLU4 -> Convolution4 (in-place)
I0702 00:34:49.368314  4664 net.cpp:150] Setting up ReLU4
I0702 00:34:49.368321  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.376745 13010 net.cpp:150] Setting up Scale14
I0702 00:34:49.368330  4664 net.cpp:165] Memory required for data: 1388556
I0702 00:34:49.368336  4664 layer_factory.hpp:77] Creating layer Convolution5
I0702 00:34:49.376756 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.376765 13010 net.cpp:165] Memory required for data: 3616780
I0702 00:34:49.368360  4664 net.cpp:106] Creating Layer Convolution5
I0702 00:34:49.368378  4664 net.cpp:454] Convolution5 <- Convolution4
I0702 00:34:49.368391  4664 net.cpp:411] Convolution5 -> Convolution5
I0702 00:34:49.368525  4664 net.cpp:150] Setting up Convolution5
I0702 00:34:49.368538  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.376780 13010 layer_factory.hpp:77] Creating layer Eltwise6
I0702 00:34:49.368547  4664 net.cpp:165] Memory required for data: 1454092
I0702 00:34:49.376791 13010 net.cpp:106] Creating Layer Eltwise6
I0702 00:34:49.368559  4664 layer_factory.hpp:77] Creating layer BatchNorm5
I0702 00:34:49.376799 13010 net.cpp:454] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0702 00:34:49.368571  4664 net.cpp:106] Creating Layer BatchNorm5
I0702 00:34:49.376814 13010 net.cpp:454] Eltwise6 <- Convolution14
I0702 00:34:49.368580  4664 net.cpp:454] BatchNorm5 <- Convolution5
I0702 00:34:49.376823 13010 net.cpp:411] Eltwise6 -> Eltwise6
I0702 00:34:49.368595  4664 net.cpp:397] BatchNorm5 -> Convolution5 (in-place)
I0702 00:34:49.368628  4664 net.cpp:150] Setting up BatchNorm5
I0702 00:34:49.368639  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368655  4664 net.cpp:165] Memory required for data: 1519628
I0702 00:34:49.368676  4664 layer_factory.hpp:77] Creating layer Scale5
I0702 00:34:49.368690  4664 net.cpp:106] Creating Layer Scale5
I0702 00:34:49.376837 13010 net.cpp:150] Setting up Eltwise6
I0702 00:34:49.368696  4664 net.cpp:454] Scale5 <- Convolution5
I0702 00:34:49.376845 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.368710  4664 net.cpp:397] Scale5 -> Convolution5 (in-place)
I0702 00:34:49.376863 13010 net.cpp:165] Memory required for data: 3649548
I0702 00:34:49.376529 20914 net.cpp:150] Setting up Convolution16
I0702 00:34:49.368731  4664 layer_factory.hpp:77] Creating layer Scale5
I0702 00:34:49.376870 13010 layer_factory.hpp:77] Creating layer ReLU13
I0702 00:34:49.376545 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.376555 20914 net.cpp:165] Memory required for data: 3813388
I0702 00:34:49.368768  4664 net.cpp:150] Setting up Scale5
I0702 00:34:49.376879 13010 net.cpp:106] Creating Layer ReLU13
I0702 00:34:49.376567 20914 layer_factory.hpp:77] Creating layer BatchNorm16
I0702 00:34:49.376581 20914 net.cpp:106] Creating Layer BatchNorm16
I0702 00:34:49.368779  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.376885 13010 net.cpp:454] ReLU13 <- Eltwise6
I0702 00:34:49.376588 20914 net.cpp:454] BatchNorm16 <- Convolution16
I0702 00:34:49.376598 20914 net.cpp:397] BatchNorm16 -> Convolution16 (in-place)
I0702 00:34:49.368788  4664 net.cpp:165] Memory required for data: 1585164
I0702 00:34:49.368800  4664 layer_factory.hpp:77] Creating layer Eltwise2
I0702 00:34:49.368818  4664 net.cpp:106] Creating Layer Eltwise2
I0702 00:34:49.368829  4664 net.cpp:454] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I0702 00:34:49.376894 13010 net.cpp:397] ReLU13 -> Eltwise6 (in-place)
I0702 00:34:49.376624 20914 net.cpp:150] Setting up BatchNorm16
I0702 00:34:49.368837  4664 net.cpp:454] Eltwise2 <- Convolution5
I0702 00:34:49.376904 13010 net.cpp:150] Setting up ReLU13
I0702 00:34:49.376636 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.368847  4664 net.cpp:411] Eltwise2 -> Eltwise2
I0702 00:34:49.376910 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.376646 20914 net.cpp:165] Memory required for data: 3829772
I0702 00:34:49.376665 20914 layer_factory.hpp:77] Creating layer Scale16
I0702 00:34:49.368860  4664 net.cpp:150] Setting up Eltwise2
I0702 00:34:49.376919 13010 net.cpp:165] Memory required for data: 3682316
I0702 00:34:49.376925 13010 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0702 00:34:49.376683 20914 net.cpp:106] Creating Layer Scale16
I0702 00:34:49.368870  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.376935 13010 net.cpp:106] Creating Layer Eltwise6_ReLU13_0_split
I0702 00:34:49.376693 20914 net.cpp:454] Scale16 <- Convolution16
I0702 00:34:49.376703 20914 net.cpp:397] Scale16 -> Convolution16 (in-place)
I0702 00:34:49.368877  4664 net.cpp:165] Memory required for data: 1650700
I0702 00:34:49.376941 13010 net.cpp:454] Eltwise6_ReLU13_0_split <- Eltwise6
I0702 00:34:49.376720 20914 layer_factory.hpp:77] Creating layer Scale16
I0702 00:34:49.368885  4664 layer_factory.hpp:77] Creating layer ReLU5
I0702 00:34:49.376952 13010 net.cpp:411] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0702 00:34:49.368892  4664 net.cpp:106] Creating Layer ReLU5
I0702 00:34:49.376965 13010 net.cpp:411] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0702 00:34:49.376757 20914 net.cpp:150] Setting up Scale16
I0702 00:34:49.368899  4664 net.cpp:454] ReLU5 <- Eltwise2
I0702 00:34:49.376976 13010 net.cpp:150] Setting up Eltwise6_ReLU13_0_split
I0702 00:34:49.376770 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.376780 20914 net.cpp:165] Memory required for data: 3846156
I0702 00:34:49.368908  4664 net.cpp:397] ReLU5 -> Eltwise2 (in-place)
I0702 00:34:49.376984 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.368917  4664 net.cpp:150] Setting up ReLU5
I0702 00:34:49.376993 13010 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.376791 20914 layer_factory.hpp:77] Creating layer ReLU14
I0702 00:34:49.368924  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.368932  4664 net.cpp:165] Memory required for data: 1716236
I0702 00:34:49.368939  4664 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I0702 00:34:49.368948  4664 net.cpp:106] Creating Layer Eltwise2_ReLU5_0_split
I0702 00:34:49.376802 20914 net.cpp:106] Creating Layer ReLU14
I0702 00:34:49.368963  4664 net.cpp:454] Eltwise2_ReLU5_0_split <- Eltwise2
I0702 00:34:49.377001 13010 net.cpp:165] Memory required for data: 3747852
I0702 00:34:49.376809 20914 net.cpp:454] ReLU14 <- Convolution16
I0702 00:34:49.376818 20914 net.cpp:397] ReLU14 -> Convolution16 (in-place)
I0702 00:34:49.368978  4664 net.cpp:411] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I0702 00:34:49.377007 13010 layer_factory.hpp:77] Creating layer Convolution15
I0702 00:34:49.376828 20914 net.cpp:150] Setting up ReLU14
I0702 00:34:49.376835 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.376844 20914 net.cpp:165] Memory required for data: 3862540
I0702 00:34:49.376850 20914 layer_factory.hpp:77] Creating layer Convolution17
I0702 00:34:49.368994  4664 net.cpp:411] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I0702 00:34:49.377028 13010 net.cpp:106] Creating Layer Convolution15
I0702 00:34:49.376876 20914 net.cpp:106] Creating Layer Convolution17
I0702 00:34:49.369009  4664 net.cpp:150] Setting up Eltwise2_ReLU5_0_split
I0702 00:34:49.377040 13010 net.cpp:454] Convolution15 <- Eltwise6_ReLU13_0_split_0
I0702 00:34:49.376888 20914 net.cpp:454] Convolution17 <- Convolution16
I0702 00:34:49.369019  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.377053 13010 net.cpp:411] Convolution15 -> Convolution15
I0702 00:34:49.376899 20914 net.cpp:411] Convolution17 -> Convolution17
I0702 00:34:49.369027  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.377173 13010 net.cpp:150] Setting up Convolution15
I0702 00:34:49.369035  4664 net.cpp:165] Memory required for data: 1847308
I0702 00:34:49.369042  4664 layer_factory.hpp:77] Creating layer Convolution6
I0702 00:34:49.369062  4664 net.cpp:106] Creating Layer Convolution6
I0702 00:34:49.369073  4664 net.cpp:454] Convolution6 <- Eltwise2_ReLU5_0_split_0
I0702 00:34:49.369086  4664 net.cpp:411] Convolution6 -> Convolution6
I0702 00:34:49.369213  4664 net.cpp:150] Setting up Convolution6
I0702 00:34:49.377187 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.369227  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.377197 13010 net.cpp:165] Memory required for data: 3764236
I0702 00:34:49.369236  4664 net.cpp:165] Memory required for data: 1912844
I0702 00:34:49.377208 13010 layer_factory.hpp:77] Creating layer BatchNorm15
I0702 00:34:49.369248  4664 layer_factory.hpp:77] Creating layer BatchNorm6
I0702 00:34:49.377223 13010 net.cpp:106] Creating Layer BatchNorm15
I0702 00:34:49.369266  4664 net.cpp:106] Creating Layer BatchNorm6
I0702 00:34:49.377231 13010 net.cpp:454] BatchNorm15 <- Convolution15
I0702 00:34:49.369277  4664 net.cpp:454] BatchNorm6 <- Convolution6
I0702 00:34:49.377241 13010 net.cpp:397] BatchNorm15 -> Convolution15 (in-place)
I0702 00:34:49.369289  4664 net.cpp:397] BatchNorm6 -> Convolution6 (in-place)
I0702 00:34:49.377267 13010 net.cpp:150] Setting up BatchNorm15
I0702 00:34:49.369316  4664 net.cpp:150] Setting up BatchNorm6
I0702 00:34:49.377277 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.369328  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.377286 13010 net.cpp:165] Memory required for data: 3780620
I0702 00:34:49.376675 32261 net.cpp:150] Setting up Convolution17
I0702 00:34:49.369344  4664 net.cpp:165] Memory required for data: 1978380
I0702 00:34:49.377300 13010 layer_factory.hpp:77] Creating layer Scale15
I0702 00:34:49.369362  4664 layer_factory.hpp:77] Creating layer Scale6
I0702 00:34:49.377312 13010 net.cpp:106] Creating Layer Scale15
I0702 00:34:49.369375  4664 net.cpp:106] Creating Layer Scale6
I0702 00:34:49.369382  4664 net.cpp:454] Scale6 <- Convolution6
I0702 00:34:49.376690 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.376699 32261 net.cpp:165] Memory required for data: 3878924
I0702 00:34:49.369391  4664 net.cpp:397] Scale6 -> Convolution6 (in-place)
I0702 00:34:49.376711 32261 layer_factory.hpp:77] Creating layer BatchNorm17
I0702 00:34:49.369408  4664 layer_factory.hpp:77] Creating layer Scale6
I0702 00:34:49.369444  4664 net.cpp:150] Setting up Scale6
I0702 00:34:49.377319 13010 net.cpp:454] Scale15 <- Convolution15
I0702 00:34:49.369457  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.377333 13010 net.cpp:397] Scale15 -> Convolution15 (in-place)
I0702 00:34:49.369465  4664 net.cpp:165] Memory required for data: 2043916
I0702 00:34:49.377355 13010 layer_factory.hpp:77] Creating layer Scale15
I0702 00:34:49.376722 32261 net.cpp:106] Creating Layer BatchNorm17
I0702 00:34:49.369477  4664 layer_factory.hpp:77] Creating layer ReLU6
I0702 00:34:49.377388 13010 net.cpp:150] Setting up Scale15
I0702 00:34:49.376731 32261 net.cpp:454] BatchNorm17 <- Convolution17
I0702 00:34:49.369488  4664 net.cpp:106] Creating Layer ReLU6
I0702 00:34:49.377405 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.376745 32261 net.cpp:397] BatchNorm17 -> Convolution17 (in-place)
I0702 00:34:49.369494  4664 net.cpp:454] ReLU6 <- Convolution6
I0702 00:34:49.369508  4664 net.cpp:397] ReLU6 -> Convolution6 (in-place)
I0702 00:34:49.369524  4664 net.cpp:150] Setting up ReLU6
I0702 00:34:49.369530  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369539  4664 net.cpp:165] Memory required for data: 2109452
I0702 00:34:49.377416 13010 net.cpp:165] Memory required for data: 3797004
I0702 00:34:49.369545  4664 layer_factory.hpp:77] Creating layer Convolution7
I0702 00:34:49.377429 13010 layer_factory.hpp:77] Creating layer Convolution16
I0702 00:34:49.376768 32261 net.cpp:150] Setting up BatchNorm17
I0702 00:34:49.369570  4664 net.cpp:106] Creating Layer Convolution7
I0702 00:34:49.377454 13010 net.cpp:106] Creating Layer Convolution16
I0702 00:34:49.376777 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.369580  4664 net.cpp:454] Convolution7 <- Convolution6
I0702 00:34:49.377465 13010 net.cpp:454] Convolution16 <- Eltwise6_ReLU13_0_split_1
I0702 00:34:49.376788 32261 net.cpp:165] Memory required for data: 3895308
I0702 00:34:49.369596  4664 net.cpp:411] Convolution7 -> Convolution7
I0702 00:34:49.377478 13010 net.cpp:411] Convolution16 -> Convolution16
I0702 00:34:49.376802 32261 layer_factory.hpp:77] Creating layer Scale17
I0702 00:34:49.369724  4664 net.cpp:150] Setting up Convolution7
I0702 00:34:49.376814 32261 net.cpp:106] Creating Layer Scale17
I0702 00:34:49.369737  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.369747  4664 net.cpp:165] Memory required for data: 2174988
I0702 00:34:49.369758  4664 layer_factory.hpp:77] Creating layer BatchNorm7
I0702 00:34:49.369778  4664 net.cpp:106] Creating Layer BatchNorm7
I0702 00:34:49.369789  4664 net.cpp:454] BatchNorm7 <- Convolution7
I0702 00:34:49.376821 32261 net.cpp:454] Scale17 <- Convolution17
I0702 00:34:49.369799  4664 net.cpp:397] BatchNorm7 -> Convolution7 (in-place)
I0702 00:34:49.376832 32261 net.cpp:397] Scale17 -> Convolution17 (in-place)
I0702 00:34:49.369832  4664 net.cpp:150] Setting up BatchNorm7
I0702 00:34:49.376849 32261 layer_factory.hpp:77] Creating layer Scale17
I0702 00:34:49.369841  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.376878 32261 net.cpp:150] Setting up Scale17
I0702 00:34:49.369850  4664 net.cpp:165] Memory required for data: 2240524
I0702 00:34:49.376888 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.369864  4664 layer_factory.hpp:77] Creating layer Scale7
I0702 00:34:49.376897 32261 net.cpp:165] Memory required for data: 3911692
I0702 00:34:49.369879  4664 net.cpp:106] Creating Layer Scale7
I0702 00:34:49.369887  4664 net.cpp:454] Scale7 <- Convolution7
I0702 00:34:49.369896  4664 net.cpp:397] Scale7 -> Convolution7 (in-place)
I0702 00:34:49.369913  4664 layer_factory.hpp:77] Creating layer Scale7
I0702 00:34:49.369949  4664 net.cpp:150] Setting up Scale7
I0702 00:34:49.376909 32261 layer_factory.hpp:77] Creating layer Eltwise7
I0702 00:34:49.369968  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.376919 32261 net.cpp:106] Creating Layer Eltwise7
I0702 00:34:49.369977  4664 net.cpp:165] Memory required for data: 2306060
I0702 00:34:49.376926 32261 net.cpp:454] Eltwise7 <- Convolution15
I0702 00:34:49.369989  4664 layer_factory.hpp:77] Creating layer Eltwise3
I0702 00:34:49.376935 32261 net.cpp:454] Eltwise7 <- Convolution17
I0702 00:34:49.370002  4664 net.cpp:106] Creating Layer Eltwise3
I0702 00:34:49.376945 32261 net.cpp:411] Eltwise7 -> Eltwise7
I0702 00:34:49.370009  4664 net.cpp:454] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I0702 00:34:49.376958 32261 net.cpp:150] Setting up Eltwise7
I0702 00:34:49.370018  4664 net.cpp:454] Eltwise3 <- Convolution7
I0702 00:34:49.370026  4664 net.cpp:411] Eltwise3 -> Eltwise3
I0702 00:34:49.370045  4664 net.cpp:150] Setting up Eltwise3
I0702 00:34:49.370056  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.370065  4664 net.cpp:165] Memory required for data: 2371596
I0702 00:34:49.376967 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.370071  4664 layer_factory.hpp:77] Creating layer ReLU7
I0702 00:34:49.376976 32261 net.cpp:165] Memory required for data: 3928076
I0702 00:34:49.370080  4664 net.cpp:106] Creating Layer ReLU7
I0702 00:34:49.376982 32261 layer_factory.hpp:77] Creating layer ReLU15
I0702 00:34:49.376991 32261 net.cpp:106] Creating Layer ReLU15
I0702 00:34:49.370087  4664 net.cpp:454] ReLU7 <- Eltwise3
I0702 00:34:49.376997 32261 net.cpp:454] ReLU15 <- Eltwise7
I0702 00:34:49.370095  4664 net.cpp:397] ReLU7 -> Eltwise3 (in-place)
I0702 00:34:49.377008 32261 net.cpp:397] ReLU15 -> Eltwise7 (in-place)
I0702 00:34:49.370106  4664 net.cpp:150] Setting up ReLU7
I0702 00:34:49.377020 32261 net.cpp:150] Setting up ReLU15
I0702 00:34:49.370112  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.377027 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.370121  4664 net.cpp:165] Memory required for data: 2437132
I0702 00:34:49.370126  4664 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I0702 00:34:49.370136  4664 net.cpp:106] Creating Layer Eltwise3_ReLU7_0_split
I0702 00:34:49.370141  4664 net.cpp:454] Eltwise3_ReLU7_0_split <- Eltwise3
I0702 00:34:49.370151  4664 net.cpp:411] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I0702 00:34:49.377034 32261 net.cpp:165] Memory required for data: 3944460
I0702 00:34:49.370162  4664 net.cpp:411] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I0702 00:34:49.377041 32261 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0702 00:34:49.370182  4664 net.cpp:150] Setting up Eltwise3_ReLU7_0_split
I0702 00:34:49.377050 32261 net.cpp:106] Creating Layer Eltwise7_ReLU15_0_split
I0702 00:34:49.370190  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.377058 32261 net.cpp:454] Eltwise7_ReLU15_0_split <- Eltwise7
I0702 00:34:49.370199  4664 net.cpp:157] Top shape: 1 16 32 32 (16384)
I0702 00:34:49.377065 32261 net.cpp:411] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0702 00:34:49.370208  4664 net.cpp:165] Memory required for data: 2568204
I0702 00:34:49.377076 32261 net.cpp:411] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0702 00:34:49.370213  4664 layer_factory.hpp:77] Creating layer Convolution8
I0702 00:34:49.377087 32261 net.cpp:150] Setting up Eltwise7_ReLU15_0_split
I0702 00:34:49.370234  4664 net.cpp:106] Creating Layer Convolution8
I0702 00:34:49.370245  4664 net.cpp:454] Convolution8 <- Eltwise3_ReLU7_0_split_0
I0702 00:34:49.370262  4664 net.cpp:411] Convolution8 -> Convolution8
I0702 00:34:49.370349  4664 net.cpp:150] Setting up Convolution8
I0702 00:34:49.370363  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.377102 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.370380  4664 net.cpp:165] Memory required for data: 2600972
I0702 00:34:49.377116 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.377125 32261 net.cpp:165] Memory required for data: 3977228
I0702 00:34:49.370393  4664 layer_factory.hpp:77] Creating layer BatchNorm8
I0702 00:34:49.377131 32261 layer_factory.hpp:77] Creating layer Convolution18
I0702 00:34:49.370405  4664 net.cpp:106] Creating Layer BatchNorm8
I0702 00:34:49.377151 32261 net.cpp:106] Creating Layer Convolution18
I0702 00:34:49.370412  4664 net.cpp:454] BatchNorm8 <- Convolution8
I0702 00:34:49.377161 32261 net.cpp:454] Convolution18 <- Eltwise7_ReLU15_0_split_0
I0702 00:34:49.370421  4664 net.cpp:397] BatchNorm8 -> Convolution8 (in-place)
I0702 00:34:49.377174 32261 net.cpp:411] Convolution18 -> Convolution18
I0702 00:34:49.370448  4664 net.cpp:150] Setting up BatchNorm8
I0702 00:34:49.370458  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.370467  4664 net.cpp:165] Memory required for data: 2633740
I0702 00:34:49.370481  4664 layer_factory.hpp:77] Creating layer Scale8
I0702 00:34:49.370493  4664 net.cpp:106] Creating Layer Scale8
I0702 00:34:49.370501  4664 net.cpp:454] Scale8 <- Convolution8
I0702 00:34:49.370514  4664 net.cpp:397] Scale8 -> Convolution8 (in-place)
I0702 00:34:49.377933 13010 net.cpp:150] Setting up Convolution16
I0702 00:34:49.370535  4664 layer_factory.hpp:77] Creating layer Scale8
I0702 00:34:49.370573  4664 net.cpp:150] Setting up Scale8
I0702 00:34:49.370585  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.370594  4664 net.cpp:165] Memory required for data: 2666508
I0702 00:34:49.370606  4664 layer_factory.hpp:77] Creating layer Convolution9
I0702 00:34:49.377948 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.377957 13010 net.cpp:165] Memory required for data: 3813388
I0702 00:34:49.370633  4664 net.cpp:106] Creating Layer Convolution9
I0702 00:34:49.377969 13010 layer_factory.hpp:77] Creating layer BatchNorm16
I0702 00:34:49.370645  4664 net.cpp:454] Convolution9 <- Eltwise3_ReLU7_0_split_1
I0702 00:34:49.370656  4664 net.cpp:411] Convolution9 -> Convolution9
I0702 00:34:49.370828  4664 net.cpp:150] Setting up Convolution9
I0702 00:34:49.370842  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.370851  4664 net.cpp:165] Memory required for data: 2699276
I0702 00:34:49.377985 13010 net.cpp:106] Creating Layer BatchNorm16
I0702 00:34:49.370863  4664 layer_factory.hpp:77] Creating layer BatchNorm9
I0702 00:34:49.377996 13010 net.cpp:454] BatchNorm16 <- Convolution16
I0702 00:34:49.370875  4664 net.cpp:106] Creating Layer BatchNorm9
I0702 00:34:49.378006 13010 net.cpp:397] BatchNorm16 -> Convolution16 (in-place)
I0702 00:34:49.370883  4664 net.cpp:454] BatchNorm9 <- Convolution9
I0702 00:34:49.370898  4664 net.cpp:397] BatchNorm9 -> Convolution9 (in-place)
I0702 00:34:49.370928  4664 net.cpp:150] Setting up BatchNorm9
I0702 00:34:49.370939  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.370947  4664 net.cpp:165] Memory required for data: 2732044
I0702 00:34:49.370971  4664 layer_factory.hpp:77] Creating layer Scale9
I0702 00:34:49.378033 13010 net.cpp:150] Setting up BatchNorm16
I0702 00:34:49.370985  4664 net.cpp:106] Creating Layer Scale9
I0702 00:34:49.378043 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.370991  4664 net.cpp:454] Scale9 <- Convolution9
I0702 00:34:49.378052 13010 net.cpp:165] Memory required for data: 3829772
I0702 00:34:49.371001  4664 net.cpp:397] Scale9 -> Convolution9 (in-place)
I0702 00:34:49.371017  4664 layer_factory.hpp:77] Creating layer Scale9
I0702 00:34:49.371047  4664 net.cpp:150] Setting up Scale9
I0702 00:34:49.371058  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.371068  4664 net.cpp:165] Memory required for data: 2764812
I0702 00:34:49.378074 13010 layer_factory.hpp:77] Creating layer Scale16
I0702 00:34:49.371079  4664 layer_factory.hpp:77] Creating layer ReLU8
I0702 00:34:49.378089 13010 net.cpp:106] Creating Layer Scale16
I0702 00:34:49.371089  4664 net.cpp:106] Creating Layer ReLU8
I0702 00:34:49.378098 13010 net.cpp:454] Scale16 <- Convolution16
I0702 00:34:49.371100  4664 net.cpp:454] ReLU8 <- Convolution9
I0702 00:34:49.378108 13010 net.cpp:397] Scale16 -> Convolution16 (in-place)
I0702 00:34:49.377768 20914 net.cpp:150] Setting up Convolution17
I0702 00:34:49.371110  4664 net.cpp:397] ReLU8 -> Convolution9 (in-place)
I0702 00:34:49.371120  4664 net.cpp:150] Setting up ReLU8
I0702 00:34:49.371126  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.378125 13010 layer_factory.hpp:77] Creating layer Scale16
I0702 00:34:49.371135  4664 net.cpp:165] Memory required for data: 2797580
I0702 00:34:49.378157 13010 net.cpp:150] Setting up Scale16
I0702 00:34:49.377784 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.377804 20914 net.cpp:165] Memory required for data: 3878924
I0702 00:34:49.371141  4664 layer_factory.hpp:77] Creating layer Convolution10
I0702 00:34:49.377816 20914 layer_factory.hpp:77] Creating layer BatchNorm17
I0702 00:34:49.377827 20914 net.cpp:106] Creating Layer BatchNorm17
I0702 00:34:49.371165  4664 net.cpp:106] Creating Layer Convolution10
I0702 00:34:49.378168 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.377835 20914 net.cpp:454] BatchNorm17 <- Convolution17
I0702 00:34:49.377846 20914 net.cpp:397] BatchNorm17 -> Convolution17 (in-place)
I0702 00:34:49.371176  4664 net.cpp:454] Convolution10 <- Convolution9
I0702 00:34:49.378177 13010 net.cpp:165] Memory required for data: 3846156
I0702 00:34:49.377876 20914 net.cpp:150] Setting up BatchNorm17
I0702 00:34:49.371196  4664 net.cpp:411] Convolution10 -> Convolution10
I0702 00:34:49.378190 13010 layer_factory.hpp:77] Creating layer ReLU14
I0702 00:34:49.377887 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.371475  4664 net.cpp:150] Setting up Convolution10
I0702 00:34:49.377897 20914 net.cpp:165] Memory required for data: 3895308
I0702 00:34:49.371490  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.377910 20914 layer_factory.hpp:77] Creating layer Scale17
I0702 00:34:49.371500  4664 net.cpp:165] Memory required for data: 2830348
I0702 00:34:49.378203 13010 net.cpp:106] Creating Layer ReLU14
I0702 00:34:49.377920 20914 net.cpp:106] Creating Layer Scale17
I0702 00:34:49.371527  4664 layer_factory.hpp:77] Creating layer BatchNorm10
I0702 00:34:49.378214 13010 net.cpp:454] ReLU14 <- Convolution16
I0702 00:34:49.377928 20914 net.cpp:454] Scale17 <- Convolution17
I0702 00:34:49.371546  4664 net.cpp:106] Creating Layer BatchNorm10
I0702 00:34:49.378223 13010 net.cpp:397] ReLU14 -> Convolution16 (in-place)
I0702 00:34:49.377946 20914 net.cpp:397] Scale17 -> Convolution17 (in-place)
I0702 00:34:49.371554  4664 net.cpp:454] BatchNorm10 <- Convolution10
I0702 00:34:49.378234 13010 net.cpp:150] Setting up ReLU14
I0702 00:34:49.377965 20914 layer_factory.hpp:77] Creating layer Scale17
I0702 00:34:49.371564  4664 net.cpp:397] BatchNorm10 -> Convolution10 (in-place)
I0702 00:34:49.378240 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.371592  4664 net.cpp:150] Setting up BatchNorm10
I0702 00:34:49.378248 13010 net.cpp:165] Memory required for data: 3862540
I0702 00:34:49.371601  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.378255 13010 layer_factory.hpp:77] Creating layer Convolution17
I0702 00:34:49.371610  4664 net.cpp:165] Memory required for data: 2863116
I0702 00:34:49.378280 13010 net.cpp:106] Creating Layer Convolution17
I0702 00:34:49.377995 20914 net.cpp:150] Setting up Scale17
I0702 00:34:49.371624  4664 layer_factory.hpp:77] Creating layer Scale10
I0702 00:34:49.378291 13010 net.cpp:454] Convolution17 <- Convolution16
I0702 00:34:49.378006 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.378015 20914 net.cpp:165] Memory required for data: 3911692
I0702 00:34:49.371641  4664 net.cpp:106] Creating Layer Scale10
I0702 00:34:49.378027 20914 layer_factory.hpp:77] Creating layer Eltwise7
I0702 00:34:49.378037 20914 net.cpp:106] Creating Layer Eltwise7
I0702 00:34:49.371652  4664 net.cpp:454] Scale10 <- Convolution10
I0702 00:34:49.378304 13010 net.cpp:411] Convolution17 -> Convolution17
I0702 00:34:49.378044 20914 net.cpp:454] Eltwise7 <- Convolution15
I0702 00:34:49.371662  4664 net.cpp:397] Scale10 -> Convolution10 (in-place)
I0702 00:34:49.378056 20914 net.cpp:454] Eltwise7 <- Convolution17
I0702 00:34:49.371678  4664 layer_factory.hpp:77] Creating layer Scale10
I0702 00:34:49.378069 20914 net.cpp:411] Eltwise7 -> Eltwise7
I0702 00:34:49.371711  4664 net.cpp:150] Setting up Scale10
I0702 00:34:49.378083 20914 net.cpp:150] Setting up Eltwise7
I0702 00:34:49.371722  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.378094 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.371731  4664 net.cpp:165] Memory required for data: 2895884
I0702 00:34:49.378103 20914 net.cpp:165] Memory required for data: 3928076
I0702 00:34:49.371743  4664 layer_factory.hpp:77] Creating layer Eltwise4
I0702 00:34:49.378110 20914 layer_factory.hpp:77] Creating layer ReLU15
I0702 00:34:49.371754  4664 net.cpp:106] Creating Layer Eltwise4
I0702 00:34:49.378119 20914 net.cpp:106] Creating Layer ReLU15
I0702 00:34:49.371762  4664 net.cpp:454] Eltwise4 <- Convolution8
I0702 00:34:49.378126 20914 net.cpp:454] ReLU15 <- Eltwise7
I0702 00:34:49.371769  4664 net.cpp:454] Eltwise4 <- Convolution10
I0702 00:34:49.371785  4664 net.cpp:411] Eltwise4 -> Eltwise4
I0702 00:34:49.378180 20914 net.cpp:397] ReLU15 -> Eltwise7 (in-place)
I0702 00:34:49.371803  4664 net.cpp:150] Setting up Eltwise4
I0702 00:34:49.371811  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.378196 20914 net.cpp:150] Setting up ReLU15
I0702 00:34:49.378202 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.371820  4664 net.cpp:165] Memory required for data: 2928652
I0702 00:34:49.378211 20914 net.cpp:165] Memory required for data: 3944460
I0702 00:34:49.371827  4664 layer_factory.hpp:77] Creating layer ReLU9
I0702 00:34:49.378218 20914 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0702 00:34:49.371836  4664 net.cpp:106] Creating Layer ReLU9
I0702 00:34:49.378235 20914 net.cpp:106] Creating Layer Eltwise7_ReLU15_0_split
I0702 00:34:49.378242 20914 net.cpp:454] Eltwise7_ReLU15_0_split <- Eltwise7
I0702 00:34:49.371843  4664 net.cpp:454] ReLU9 <- Eltwise4
I0702 00:34:49.378252 20914 net.cpp:411] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0702 00:34:49.371855  4664 net.cpp:397] ReLU9 -> Eltwise4 (in-place)
I0702 00:34:49.378263 20914 net.cpp:411] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0702 00:34:49.371865  4664 net.cpp:150] Setting up ReLU9
I0702 00:34:49.378274 20914 net.cpp:150] Setting up Eltwise7_ReLU15_0_split
I0702 00:34:49.371872  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.378291 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.378301 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.371881  4664 net.cpp:165] Memory required for data: 2961420
I0702 00:34:49.378309 20914 net.cpp:165] Memory required for data: 3977228
I0702 00:34:49.378315 20914 layer_factory.hpp:77] Creating layer Convolution18
I0702 00:34:49.371887  4664 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I0702 00:34:49.377992 32261 net.cpp:150] Setting up Convolution18
I0702 00:34:49.371896  4664 net.cpp:106] Creating Layer Eltwise4_ReLU9_0_split
I0702 00:34:49.378340 20914 net.cpp:106] Creating Layer Convolution18
I0702 00:34:49.371903  4664 net.cpp:454] Eltwise4_ReLU9_0_split <- Eltwise4
I0702 00:34:49.378351 20914 net.cpp:454] Convolution18 <- Eltwise7_ReLU15_0_split_0
I0702 00:34:49.371912  4664 net.cpp:411] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I0702 00:34:49.378363 20914 net.cpp:411] Convolution18 -> Convolution18
I0702 00:34:49.378007 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.378017 32261 net.cpp:165] Memory required for data: 3993612
I0702 00:34:49.371922  4664 net.cpp:411] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I0702 00:34:49.378028 32261 layer_factory.hpp:77] Creating layer BatchNorm18
I0702 00:34:49.371933  4664 net.cpp:150] Setting up Eltwise4_ReLU9_0_split
I0702 00:34:49.371940  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.371971  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.371982  4664 net.cpp:165] Memory required for data: 3026956
I0702 00:34:49.371990  4664 layer_factory.hpp:77] Creating layer Convolution11
I0702 00:34:49.378042 32261 net.cpp:106] Creating Layer BatchNorm18
I0702 00:34:49.372011  4664 net.cpp:106] Creating Layer Convolution11
I0702 00:34:49.378051 32261 net.cpp:454] BatchNorm18 <- Convolution18
I0702 00:34:49.372022  4664 net.cpp:454] Convolution11 <- Eltwise4_ReLU9_0_split_0
I0702 00:34:49.378060 32261 net.cpp:397] BatchNorm18 -> Convolution18 (in-place)
I0702 00:34:49.372040  4664 net.cpp:411] Convolution11 -> Convolution11
I0702 00:34:49.378084 32261 net.cpp:150] Setting up BatchNorm18
I0702 00:34:49.372308  4664 net.cpp:150] Setting up Convolution11
I0702 00:34:49.378093 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.372323  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.378103 32261 net.cpp:165] Memory required for data: 4009996
I0702 00:34:49.372334  4664 net.cpp:165] Memory required for data: 3059724
I0702 00:34:49.372344  4664 layer_factory.hpp:77] Creating layer BatchNorm11
I0702 00:34:49.372357  4664 net.cpp:106] Creating Layer BatchNorm11
I0702 00:34:49.372364  4664 net.cpp:454] BatchNorm11 <- Convolution11
I0702 00:34:49.372380  4664 net.cpp:397] BatchNorm11 -> Convolution11 (in-place)
I0702 00:34:49.378115 32261 layer_factory.hpp:77] Creating layer Scale18
I0702 00:34:49.372411  4664 net.cpp:150] Setting up BatchNorm11
I0702 00:34:49.378129 32261 net.cpp:106] Creating Layer Scale18
I0702 00:34:49.372421  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.378139 32261 net.cpp:454] Scale18 <- Convolution18
I0702 00:34:49.372429  4664 net.cpp:165] Memory required for data: 3092492
I0702 00:34:49.378149 32261 net.cpp:397] Scale18 -> Convolution18 (in-place)
I0702 00:34:49.372452  4664 layer_factory.hpp:77] Creating layer Scale11
I0702 00:34:49.378167 32261 layer_factory.hpp:77] Creating layer Scale18
I0702 00:34:49.372467  4664 net.cpp:106] Creating Layer Scale11
I0702 00:34:49.372475  4664 net.cpp:454] Scale11 <- Convolution11
I0702 00:34:49.372484  4664 net.cpp:397] Scale11 -> Convolution11 (in-place)
I0702 00:34:49.372501  4664 layer_factory.hpp:77] Creating layer Scale11
I0702 00:34:49.372539  4664 net.cpp:150] Setting up Scale11
I0702 00:34:49.378195 32261 net.cpp:150] Setting up Scale18
I0702 00:34:49.372551  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.378204 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.372560  4664 net.cpp:165] Memory required for data: 3125260
I0702 00:34:49.378213 32261 net.cpp:165] Memory required for data: 4026380
I0702 00:34:49.372571  4664 layer_factory.hpp:77] Creating layer ReLU10
I0702 00:34:49.378224 32261 layer_factory.hpp:77] Creating layer ReLU16
I0702 00:34:49.372583  4664 net.cpp:106] Creating Layer ReLU10
I0702 00:34:49.378233 32261 net.cpp:106] Creating Layer ReLU16
I0702 00:34:49.372589  4664 net.cpp:454] ReLU10 <- Convolution11
I0702 00:34:49.372601  4664 net.cpp:397] ReLU10 -> Convolution11 (in-place)
I0702 00:34:49.372612  4664 net.cpp:150] Setting up ReLU10
I0702 00:34:49.372620  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372628  4664 net.cpp:165] Memory required for data: 3158028
I0702 00:34:49.378240 32261 net.cpp:454] ReLU16 <- Convolution18
I0702 00:34:49.372635  4664 layer_factory.hpp:77] Creating layer Convolution12
I0702 00:34:49.378248 32261 net.cpp:397] ReLU16 -> Convolution18 (in-place)
I0702 00:34:49.372656  4664 net.cpp:106] Creating Layer Convolution12
I0702 00:34:49.378264 32261 net.cpp:150] Setting up ReLU16
I0702 00:34:49.372668  4664 net.cpp:454] Convolution12 <- Convolution11
I0702 00:34:49.378273 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.372681  4664 net.cpp:411] Convolution12 -> Convolution12
I0702 00:34:49.378283 32261 net.cpp:165] Memory required for data: 4042764
I0702 00:34:49.372951  4664 net.cpp:150] Setting up Convolution12
I0702 00:34:49.378289 32261 layer_factory.hpp:77] Creating layer Convolution19
I0702 00:34:49.372972  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.372989  4664 net.cpp:165] Memory required for data: 3190796
I0702 00:34:49.373003  4664 layer_factory.hpp:77] Creating layer BatchNorm12
I0702 00:34:49.373015  4664 net.cpp:106] Creating Layer BatchNorm12
I0702 00:34:49.373023  4664 net.cpp:454] BatchNorm12 <- Convolution12
I0702 00:34:49.378310 32261 net.cpp:106] Creating Layer Convolution19
I0702 00:34:49.373034  4664 net.cpp:397] BatchNorm12 -> Convolution12 (in-place)
I0702 00:34:49.378319 32261 net.cpp:454] Convolution19 <- Convolution18
I0702 00:34:49.373062  4664 net.cpp:150] Setting up BatchNorm12
I0702 00:34:49.378332 32261 net.cpp:411] Convolution19 -> Convolution19
I0702 00:34:49.373073  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373081  4664 net.cpp:165] Memory required for data: 3223564
I0702 00:34:49.373095  4664 layer_factory.hpp:77] Creating layer Scale12
I0702 00:34:49.373112  4664 net.cpp:106] Creating Layer Scale12
I0702 00:34:49.373122  4664 net.cpp:454] Scale12 <- Convolution12
I0702 00:34:49.373132  4664 net.cpp:397] Scale12 -> Convolution12 (in-place)
I0702 00:34:49.373148  4664 layer_factory.hpp:77] Creating layer Scale12
I0702 00:34:49.373183  4664 net.cpp:150] Setting up Scale12
I0702 00:34:49.373194  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373203  4664 net.cpp:165] Memory required for data: 3256332
I0702 00:34:49.373215  4664 layer_factory.hpp:77] Creating layer Eltwise5
I0702 00:34:49.373225  4664 net.cpp:106] Creating Layer Eltwise5
I0702 00:34:49.373234  4664 net.cpp:454] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I0702 00:34:49.373242  4664 net.cpp:454] Eltwise5 <- Convolution12
I0702 00:34:49.373256  4664 net.cpp:411] Eltwise5 -> Eltwise5
I0702 00:34:49.373273  4664 net.cpp:150] Setting up Eltwise5
I0702 00:34:49.379137 13010 net.cpp:150] Setting up Convolution17
I0702 00:34:49.373282  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373291  4664 net.cpp:165] Memory required for data: 3289100
I0702 00:34:49.373297  4664 layer_factory.hpp:77] Creating layer ReLU11
I0702 00:34:49.373306  4664 net.cpp:106] Creating Layer ReLU11
I0702 00:34:49.373313  4664 net.cpp:454] ReLU11 <- Eltwise5
I0702 00:34:49.379153 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.379163 13010 net.cpp:165] Memory required for data: 3878924
I0702 00:34:49.373324  4664 net.cpp:397] ReLU11 -> Eltwise5 (in-place)
I0702 00:34:49.379174 13010 layer_factory.hpp:77] Creating layer BatchNorm17
I0702 00:34:49.373335  4664 net.cpp:150] Setting up ReLU11
I0702 00:34:49.373343  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373353  4664 net.cpp:165] Memory required for data: 3321868
I0702 00:34:49.373359  4664 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I0702 00:34:49.373368  4664 net.cpp:106] Creating Layer Eltwise5_ReLU11_0_split
I0702 00:34:49.379186 13010 net.cpp:106] Creating Layer BatchNorm17
I0702 00:34:49.373374  4664 net.cpp:454] Eltwise5_ReLU11_0_split <- Eltwise5
I0702 00:34:49.379194 13010 net.cpp:454] BatchNorm17 <- Convolution17
I0702 00:34:49.373383  4664 net.cpp:411] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I0702 00:34:49.379209 13010 net.cpp:397] BatchNorm17 -> Convolution17 (in-place)
I0702 00:34:49.373394  4664 net.cpp:411] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I0702 00:34:49.373414  4664 net.cpp:150] Setting up Eltwise5_ReLU11_0_split
I0702 00:34:49.373430  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373440  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373448  4664 net.cpp:165] Memory required for data: 3387404
I0702 00:34:49.379240 13010 net.cpp:150] Setting up BatchNorm17
I0702 00:34:49.373456  4664 layer_factory.hpp:77] Creating layer Convolution13
I0702 00:34:49.379250 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.373478  4664 net.cpp:106] Creating Layer Convolution13
I0702 00:34:49.379258 13010 net.cpp:165] Memory required for data: 3895308
I0702 00:34:49.373489  4664 net.cpp:454] Convolution13 <- Eltwise5_ReLU11_0_split_0
I0702 00:34:49.373502  4664 net.cpp:411] Convolution13 -> Convolution13
I0702 00:34:49.373775  4664 net.cpp:150] Setting up Convolution13
I0702 00:34:49.373788  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373798  4664 net.cpp:165] Memory required for data: 3420172
I0702 00:34:49.379271 13010 layer_factory.hpp:77] Creating layer Scale17
I0702 00:34:49.373811  4664 layer_factory.hpp:77] Creating layer BatchNorm13
I0702 00:34:49.379283 13010 net.cpp:106] Creating Layer Scale17
I0702 00:34:49.373828  4664 net.cpp:106] Creating Layer BatchNorm13
I0702 00:34:49.379292 13010 net.cpp:454] Scale17 <- Convolution17
I0702 00:34:49.373838  4664 net.cpp:454] BatchNorm13 <- Convolution13
I0702 00:34:49.379303 13010 net.cpp:397] Scale17 -> Convolution17 (in-place)
I0702 00:34:49.373848  4664 net.cpp:397] BatchNorm13 -> Convolution13 (in-place)
I0702 00:34:49.373874  4664 net.cpp:150] Setting up BatchNorm13
I0702 00:34:49.373884  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.373893  4664 net.cpp:165] Memory required for data: 3452940
I0702 00:34:49.373909  4664 layer_factory.hpp:77] Creating layer Scale13
I0702 00:34:49.379320 13010 layer_factory.hpp:77] Creating layer Scale17
I0702 00:34:49.373921  4664 net.cpp:106] Creating Layer Scale13
I0702 00:34:49.379350 13010 net.cpp:150] Setting up Scale17
I0702 00:34:49.373929  4664 net.cpp:454] Scale13 <- Convolution13
I0702 00:34:49.373937  4664 net.cpp:397] Scale13 -> Convolution13 (in-place)
I0702 00:34:49.373965  4664 layer_factory.hpp:77] Creating layer Scale13
I0702 00:34:49.374001  4664 net.cpp:150] Setting up Scale13
I0702 00:34:49.374011  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.379361 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.374020  4664 net.cpp:165] Memory required for data: 3485708
I0702 00:34:49.379370 13010 net.cpp:165] Memory required for data: 3911692
I0702 00:34:49.374032  4664 layer_factory.hpp:77] Creating layer ReLU12
I0702 00:34:49.379382 13010 layer_factory.hpp:77] Creating layer Eltwise7
I0702 00:34:49.374044  4664 net.cpp:106] Creating Layer ReLU12
I0702 00:34:49.379392 13010 net.cpp:106] Creating Layer Eltwise7
I0702 00:34:49.374053  4664 net.cpp:454] ReLU12 <- Convolution13
I0702 00:34:49.374063  4664 net.cpp:397] ReLU12 -> Convolution13 (in-place)
I0702 00:34:49.374073  4664 net.cpp:150] Setting up ReLU12
I0702 00:34:49.374079  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374088  4664 net.cpp:165] Memory required for data: 3518476
I0702 00:34:49.379405 13010 net.cpp:454] Eltwise7 <- Convolution15
I0702 00:34:49.374094  4664 layer_factory.hpp:77] Creating layer Convolution14
I0702 00:34:49.379416 13010 net.cpp:454] Eltwise7 <- Convolution17
I0702 00:34:49.374121  4664 net.cpp:106] Creating Layer Convolution14
I0702 00:34:49.379432 13010 net.cpp:411] Eltwise7 -> Eltwise7
I0702 00:34:49.374133  4664 net.cpp:454] Convolution14 <- Convolution13
I0702 00:34:49.379451 13010 net.cpp:150] Setting up Eltwise7
I0702 00:34:49.374147  4664 net.cpp:411] Convolution14 -> Convolution14
I0702 00:34:49.374421  4664 net.cpp:150] Setting up Convolution14
I0702 00:34:49.374436  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.374445  4664 net.cpp:165] Memory required for data: 3551244
I0702 00:34:49.374457  4664 layer_factory.hpp:77] Creating layer BatchNorm14
I0702 00:34:49.374470  4664 net.cpp:106] Creating Layer BatchNorm14
I0702 00:34:49.379459 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.374477  4664 net.cpp:454] BatchNorm14 <- Convolution14
I0702 00:34:49.379467 13010 net.cpp:165] Memory required for data: 3928076
I0702 00:34:49.374492  4664 net.cpp:397] BatchNorm14 -> Convolution14 (in-place)
I0702 00:34:49.379474 13010 layer_factory.hpp:77] Creating layer ReLU15
I0702 00:34:49.374522  4664 net.cpp:150] Setting up BatchNorm14
I0702 00:34:49.379483 13010 net.cpp:106] Creating Layer ReLU15
I0702 00:34:49.374532  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.379490 13010 net.cpp:454] ReLU15 <- Eltwise7
I0702 00:34:49.374541  4664 net.cpp:165] Memory required for data: 3584012
I0702 00:34:49.379501 13010 net.cpp:397] ReLU15 -> Eltwise7 (in-place)
I0702 00:34:49.374557  4664 layer_factory.hpp:77] Creating layer Scale14
I0702 00:34:49.379197 20914 net.cpp:150] Setting up Convolution18
I0702 00:34:49.374569  4664 net.cpp:106] Creating Layer Scale14
I0702 00:34:49.374577  4664 net.cpp:454] Scale14 <- Convolution14
I0702 00:34:49.379511 13010 net.cpp:150] Setting up ReLU15
I0702 00:34:49.374585  4664 net.cpp:397] Scale14 -> Convolution14 (in-place)
I0702 00:34:49.379519 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.379214 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.374601  4664 layer_factory.hpp:77] Creating layer Scale14
I0702 00:34:49.379528 13010 net.cpp:165] Memory required for data: 3944460
I0702 00:34:49.379230 20914 net.cpp:165] Memory required for data: 3993612
I0702 00:34:49.379241 20914 layer_factory.hpp:77] Creating layer BatchNorm18
I0702 00:34:49.374634  4664 net.cpp:150] Setting up Scale14
I0702 00:34:49.379534 13010 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0702 00:34:49.379261 20914 net.cpp:106] Creating Layer BatchNorm18
I0702 00:34:49.374644  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.379544 13010 net.cpp:106] Creating Layer Eltwise7_ReLU15_0_split
I0702 00:34:49.379273 20914 net.cpp:454] BatchNorm18 <- Convolution18
I0702 00:34:49.374653  4664 net.cpp:165] Memory required for data: 3616780
I0702 00:34:49.379550 13010 net.cpp:454] Eltwise7_ReLU15_0_split <- Eltwise7
I0702 00:34:49.379287 20914 net.cpp:397] BatchNorm18 -> Convolution18 (in-place)
I0702 00:34:49.374665  4664 layer_factory.hpp:77] Creating layer Eltwise6
I0702 00:34:49.379559 13010 net.cpp:411] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0702 00:34:49.379312 20914 net.cpp:150] Setting up BatchNorm18
I0702 00:34:49.374678  4664 net.cpp:106] Creating Layer Eltwise6
I0702 00:34:49.379570 13010 net.cpp:411] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0702 00:34:49.379323 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.374687  4664 net.cpp:454] Eltwise6 <- Eltwise5_ReLU11_0_split_1
I0702 00:34:49.379333 20914 net.cpp:165] Memory required for data: 4009996
I0702 00:34:49.374702  4664 net.cpp:454] Eltwise6 <- Convolution14
I0702 00:34:49.379348 20914 layer_factory.hpp:77] Creating layer Scale18
I0702 00:34:49.374712  4664 net.cpp:411] Eltwise6 -> Eltwise6
I0702 00:34:49.379580 13010 net.cpp:150] Setting up Eltwise7_ReLU15_0_split
I0702 00:34:49.379360 20914 net.cpp:106] Creating Layer Scale18
I0702 00:34:49.374727  4664 net.cpp:150] Setting up Eltwise6
I0702 00:34:49.379596 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.379369 20914 net.cpp:454] Scale18 <- Convolution18
I0702 00:34:49.374734  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.379613 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.379377 20914 net.cpp:397] Scale18 -> Convolution18 (in-place)
I0702 00:34:49.374743  4664 net.cpp:165] Memory required for data: 3649548
I0702 00:34:49.379622 13010 net.cpp:165] Memory required for data: 3977228
I0702 00:34:49.379400 20914 layer_factory.hpp:77] Creating layer Scale18
I0702 00:34:49.374749  4664 layer_factory.hpp:77] Creating layer ReLU13
I0702 00:34:49.379629 13010 layer_factory.hpp:77] Creating layer Convolution18
I0702 00:34:49.379431 20914 net.cpp:150] Setting up Scale18
I0702 00:34:49.374758  4664 net.cpp:106] Creating Layer ReLU13
I0702 00:34:49.379652 13010 net.cpp:106] Creating Layer Convolution18
I0702 00:34:49.374765  4664 net.cpp:454] ReLU13 <- Eltwise6
I0702 00:34:49.379663 13010 net.cpp:454] Convolution18 <- Eltwise7_ReLU15_0_split_0
I0702 00:34:49.379443 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.379456 20914 net.cpp:165] Memory required for data: 4026380
I0702 00:34:49.374778  4664 net.cpp:397] ReLU13 -> Eltwise6 (in-place)
I0702 00:34:49.379679 13010 net.cpp:411] Convolution18 -> Convolution18
I0702 00:34:49.379467 20914 layer_factory.hpp:77] Creating layer ReLU16
I0702 00:34:49.374794  4664 net.cpp:150] Setting up ReLU13
I0702 00:34:49.379145 32261 net.cpp:150] Setting up Convolution19
I0702 00:34:49.374799  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.379477 20914 net.cpp:106] Creating Layer ReLU16
I0702 00:34:49.374809  4664 net.cpp:165] Memory required for data: 3682316
I0702 00:34:49.379483 20914 net.cpp:454] ReLU16 <- Convolution18
I0702 00:34:49.379492 20914 net.cpp:397] ReLU16 -> Convolution18 (in-place)
I0702 00:34:49.374814  4664 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I0702 00:34:49.379505 20914 net.cpp:150] Setting up ReLU16
I0702 00:34:49.379513 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.379520 20914 net.cpp:165] Memory required for data: 4042764
I0702 00:34:49.379159 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.379168 32261 net.cpp:165] Memory required for data: 4059148
I0702 00:34:49.374824  4664 net.cpp:106] Creating Layer Eltwise6_ReLU13_0_split
I0702 00:34:49.379528 20914 layer_factory.hpp:77] Creating layer Convolution19
I0702 00:34:49.379180 32261 layer_factory.hpp:77] Creating layer BatchNorm19
I0702 00:34:49.374830  4664 net.cpp:454] Eltwise6_ReLU13_0_split <- Eltwise6
I0702 00:34:49.379549 20914 net.cpp:106] Creating Layer Convolution19
I0702 00:34:49.374841  4664 net.cpp:411] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I0702 00:34:49.379560 20914 net.cpp:454] Convolution19 <- Convolution18
I0702 00:34:49.374852  4664 net.cpp:411] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I0702 00:34:49.379575 20914 net.cpp:411] Convolution19 -> Convolution19
I0702 00:34:49.379194 32261 net.cpp:106] Creating Layer BatchNorm19
I0702 00:34:49.374866  4664 net.cpp:150] Setting up Eltwise6_ReLU13_0_split
I0702 00:34:49.379204 32261 net.cpp:454] BatchNorm19 <- Convolution19
I0702 00:34:49.374872  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.379212 32261 net.cpp:397] BatchNorm19 -> Convolution19 (in-place)
I0702 00:34:49.374881  4664 net.cpp:157] Top shape: 1 32 16 16 (8192)
I0702 00:34:49.379236 32261 net.cpp:150] Setting up BatchNorm19
I0702 00:34:49.374888  4664 net.cpp:165] Memory required for data: 3747852
I0702 00:34:49.379245 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.374896  4664 layer_factory.hpp:77] Creating layer Convolution15
I0702 00:34:49.374917  4664 net.cpp:106] Creating Layer Convolution15
I0702 00:34:49.374928  4664 net.cpp:454] Convolution15 <- Eltwise6_ReLU13_0_split_0
I0702 00:34:49.374940  4664 net.cpp:411] Convolution15 -> Convolution15
I0702 00:34:49.375061  4664 net.cpp:150] Setting up Convolution15
I0702 00:34:49.379253 32261 net.cpp:165] Memory required for data: 4075532
I0702 00:34:49.375075  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.379295 32261 layer_factory.hpp:77] Creating layer Scale19
I0702 00:34:49.375092  4664 net.cpp:165] Memory required for data: 3764236
I0702 00:34:49.379312 32261 net.cpp:106] Creating Layer Scale19
I0702 00:34:49.375104  4664 layer_factory.hpp:77] Creating layer BatchNorm15
I0702 00:34:49.379320 32261 net.cpp:454] Scale19 <- Convolution19
I0702 00:34:49.375118  4664 net.cpp:106] Creating Layer BatchNorm15
I0702 00:34:49.375124  4664 net.cpp:454] BatchNorm15 <- Convolution15
I0702 00:34:49.375136  4664 net.cpp:397] BatchNorm15 -> Convolution15 (in-place)
I0702 00:34:49.375165  4664 net.cpp:150] Setting up BatchNorm15
I0702 00:34:49.375175  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.379334 32261 net.cpp:397] Scale19 -> Convolution19 (in-place)
I0702 00:34:49.375185  4664 net.cpp:165] Memory required for data: 3780620
I0702 00:34:49.379354 32261 layer_factory.hpp:77] Creating layer Scale19
I0702 00:34:49.375198  4664 layer_factory.hpp:77] Creating layer Scale15
I0702 00:34:49.375211  4664 net.cpp:106] Creating Layer Scale15
I0702 00:34:49.375217  4664 net.cpp:454] Scale15 <- Convolution15
I0702 00:34:49.375231  4664 net.cpp:397] Scale15 -> Convolution15 (in-place)
I0702 00:34:49.375252  4664 layer_factory.hpp:77] Creating layer Scale15
I0702 00:34:49.379380 32261 net.cpp:150] Setting up Scale19
I0702 00:34:49.375283  4664 net.cpp:150] Setting up Scale15
I0702 00:34:49.379390 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.379400 32261 net.cpp:165] Memory required for data: 4091916
I0702 00:34:49.375293  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.379411 32261 layer_factory.hpp:77] Creating layer Eltwise8
I0702 00:34:49.375303  4664 net.cpp:165] Memory required for data: 3797004
I0702 00:34:49.375314  4664 layer_factory.hpp:77] Creating layer Convolution16
I0702 00:34:49.375339  4664 net.cpp:106] Creating Layer Convolution16
I0702 00:34:49.375352  4664 net.cpp:454] Convolution16 <- Eltwise6_ReLU13_0_split_1
I0702 00:34:49.375367  4664 net.cpp:411] Convolution16 -> Convolution16
I0702 00:34:49.379421 32261 net.cpp:106] Creating Layer Eltwise8
I0702 00:34:49.375820  4664 net.cpp:150] Setting up Convolution16
I0702 00:34:49.379431 32261 net.cpp:454] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0702 00:34:49.375834  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.379446 32261 net.cpp:454] Eltwise8 <- Convolution19
I0702 00:34:49.375844  4664 net.cpp:165] Memory required for data: 3813388
I0702 00:34:49.379458 32261 net.cpp:411] Eltwise8 -> Eltwise8
I0702 00:34:49.375856  4664 layer_factory.hpp:77] Creating layer BatchNorm16
I0702 00:34:49.375869  4664 net.cpp:106] Creating Layer BatchNorm16
I0702 00:34:49.375876  4664 net.cpp:454] BatchNorm16 <- Convolution16
I0702 00:34:49.375891  4664 net.cpp:397] BatchNorm16 -> Convolution16 (in-place)
I0702 00:34:49.379472 32261 net.cpp:150] Setting up Eltwise8
I0702 00:34:49.379480 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.379489 32261 net.cpp:165] Memory required for data: 4108300
I0702 00:34:49.379496 32261 layer_factory.hpp:77] Creating layer ReLU17
I0702 00:34:49.379504 32261 net.cpp:106] Creating Layer ReLU17
I0702 00:34:49.375921  4664 net.cpp:150] Setting up BatchNorm16
I0702 00:34:49.375931  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.375941  4664 net.cpp:165] Memory required for data: 3829772
I0702 00:34:49.375967  4664 layer_factory.hpp:77] Creating layer Scale16
I0702 00:34:49.375983  4664 net.cpp:106] Creating Layer Scale16
I0702 00:34:49.375993  4664 net.cpp:454] Scale16 <- Convolution16
I0702 00:34:49.379511 32261 net.cpp:454] ReLU17 <- Eltwise8
I0702 00:34:49.379519 32261 net.cpp:397] ReLU17 -> Eltwise8 (in-place)
I0702 00:34:49.376003  4664 net.cpp:397] Scale16 -> Convolution16 (in-place)
I0702 00:34:49.379529 32261 net.cpp:150] Setting up ReLU17
I0702 00:34:49.379536 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.379544 32261 net.cpp:165] Memory required for data: 4124684
I0702 00:34:49.379550 32261 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0702 00:34:49.376019  4664 layer_factory.hpp:77] Creating layer Scale16
I0702 00:34:49.379564 32261 net.cpp:106] Creating Layer Eltwise8_ReLU17_0_split
I0702 00:34:49.376050  4664 net.cpp:150] Setting up Scale16
I0702 00:34:49.376062  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.376071  4664 net.cpp:165] Memory required for data: 3846156
I0702 00:34:49.376082  4664 layer_factory.hpp:77] Creating layer ReLU14
I0702 00:34:49.376092  4664 net.cpp:106] Creating Layer ReLU14
I0702 00:34:49.379570 32261 net.cpp:454] Eltwise8_ReLU17_0_split <- Eltwise8
I0702 00:34:49.379580 32261 net.cpp:411] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0702 00:34:49.376099  4664 net.cpp:454] ReLU14 <- Convolution16
I0702 00:34:49.379590 32261 net.cpp:411] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0702 00:34:49.376112  4664 net.cpp:397] ReLU14 -> Convolution16 (in-place)
I0702 00:34:49.379602 32261 net.cpp:150] Setting up Eltwise8_ReLU17_0_split
I0702 00:34:49.376127  4664 net.cpp:150] Setting up ReLU14
I0702 00:34:49.379608 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.376133  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.376142  4664 net.cpp:165] Memory required for data: 3862540
I0702 00:34:49.376148  4664 layer_factory.hpp:77] Creating layer Convolution17
I0702 00:34:49.376175  4664 net.cpp:106] Creating Layer Convolution17
I0702 00:34:49.376186  4664 net.cpp:454] Convolution17 <- Convolution16
I0702 00:34:49.379616 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.376199  4664 net.cpp:411] Convolution17 -> Convolution17
I0702 00:34:49.379626 32261 net.cpp:165] Memory required for data: 4157452
I0702 00:34:49.377035  4664 net.cpp:150] Setting up Convolution17
I0702 00:34:49.379631 32261 layer_factory.hpp:77] Creating layer Convolution20
I0702 00:34:49.377051  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.379650 32261 net.cpp:106] Creating Layer Convolution20
I0702 00:34:49.377061  4664 net.cpp:165] Memory required for data: 3878924
I0702 00:34:49.379659 32261 net.cpp:454] Convolution20 <- Eltwise8_ReLU17_0_split_0
I0702 00:34:49.377076  4664 layer_factory.hpp:77] Creating layer BatchNorm17
I0702 00:34:49.377089  4664 net.cpp:106] Creating Layer BatchNorm17
I0702 00:34:49.377096  4664 net.cpp:454] BatchNorm17 <- Convolution17
I0702 00:34:49.377110  4664 net.cpp:397] BatchNorm17 -> Convolution17 (in-place)
I0702 00:34:49.377135  4664 net.cpp:150] Setting up BatchNorm17
I0702 00:34:49.379670 32261 net.cpp:411] Convolution20 -> Convolution20
I0702 00:34:49.377144  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.377161  4664 net.cpp:165] Memory required for data: 3895308
I0702 00:34:49.377176  4664 layer_factory.hpp:77] Creating layer Scale17
I0702 00:34:49.377187  4664 net.cpp:106] Creating Layer Scale17
I0702 00:34:49.377194  4664 net.cpp:454] Scale17 <- Convolution17
I0702 00:34:49.377205  4664 net.cpp:397] Scale17 -> Convolution17 (in-place)
I0702 00:34:49.377223  4664 layer_factory.hpp:77] Creating layer Scale17
I0702 00:34:49.377254  4664 net.cpp:150] Setting up Scale17
I0702 00:34:49.377265  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.377274  4664 net.cpp:165] Memory required for data: 3911692
I0702 00:34:49.377285  4664 layer_factory.hpp:77] Creating layer Eltwise7
I0702 00:34:49.377296  4664 net.cpp:106] Creating Layer Eltwise7
I0702 00:34:49.377305  4664 net.cpp:454] Eltwise7 <- Convolution15
I0702 00:34:49.377312  4664 net.cpp:454] Eltwise7 <- Convolution17
I0702 00:34:49.377327  4664 net.cpp:411] Eltwise7 -> Eltwise7
I0702 00:34:49.377344  4664 net.cpp:150] Setting up Eltwise7
I0702 00:34:49.377353  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.377362  4664 net.cpp:165] Memory required for data: 3928076
I0702 00:34:49.377368  4664 layer_factory.hpp:77] Creating layer ReLU15
I0702 00:34:49.377377  4664 net.cpp:106] Creating Layer ReLU15
I0702 00:34:49.380506 13010 net.cpp:150] Setting up Convolution18
I0702 00:34:49.377383  4664 net.cpp:454] ReLU15 <- Eltwise7
I0702 00:34:49.377395  4664 net.cpp:397] ReLU15 -> Eltwise7 (in-place)
I0702 00:34:49.377405  4664 net.cpp:150] Setting up ReLU15
I0702 00:34:49.377411  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.377419  4664 net.cpp:165] Memory required for data: 3944460
I0702 00:34:49.380522 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.380532 13010 net.cpp:165] Memory required for data: 3993612
I0702 00:34:49.377426  4664 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I0702 00:34:49.380544 13010 layer_factory.hpp:77] Creating layer BatchNorm18
I0702 00:34:49.377434  4664 net.cpp:106] Creating Layer Eltwise7_ReLU15_0_split
I0702 00:34:49.377441  4664 net.cpp:454] Eltwise7_ReLU15_0_split <- Eltwise7
I0702 00:34:49.377449  4664 net.cpp:411] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I0702 00:34:49.377460  4664 net.cpp:411] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I0702 00:34:49.377471  4664 net.cpp:150] Setting up Eltwise7_ReLU15_0_split
I0702 00:34:49.380561 13010 net.cpp:106] Creating Layer BatchNorm18
I0702 00:34:49.377486  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.380570 13010 net.cpp:454] BatchNorm18 <- Convolution18
I0702 00:34:49.377504  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.380587 13010 net.cpp:397] BatchNorm18 -> Convolution18 (in-place)
I0702 00:34:49.377513  4664 net.cpp:165] Memory required for data: 3977228
I0702 00:34:49.377521  4664 layer_factory.hpp:77] Creating layer Convolution18
I0702 00:34:49.377545  4664 net.cpp:106] Creating Layer Convolution18
I0702 00:34:49.377557  4664 net.cpp:454] Convolution18 <- Eltwise7_ReLU15_0_split_0
I0702 00:34:49.377573  4664 net.cpp:411] Convolution18 -> Convolution18
I0702 00:34:49.378399  4664 net.cpp:150] Setting up Convolution18
I0702 00:34:49.380614 13010 net.cpp:150] Setting up BatchNorm18
I0702 00:34:49.378415  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.380622 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.378424  4664 net.cpp:165] Memory required for data: 3993612
I0702 00:34:49.380638 13010 net.cpp:165] Memory required for data: 4009996
I0702 00:34:49.378437  4664 layer_factory.hpp:77] Creating layer BatchNorm18
I0702 00:34:49.378453  4664 net.cpp:106] Creating Layer BatchNorm18
I0702 00:34:49.378459  4664 net.cpp:454] BatchNorm18 <- Convolution18
I0702 00:34:49.378474  4664 net.cpp:397] BatchNorm18 -> Convolution18 (in-place)
I0702 00:34:49.378500  4664 net.cpp:150] Setting up BatchNorm18
I0702 00:34:49.380652 13010 layer_factory.hpp:77] Creating layer Scale18
I0702 00:34:49.378509  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.380666 13010 net.cpp:106] Creating Layer Scale18
I0702 00:34:49.378526  4664 net.cpp:165] Memory required for data: 4009996
I0702 00:34:49.380672 13010 net.cpp:454] Scale18 <- Convolution18
I0702 00:34:49.378541  4664 layer_factory.hpp:77] Creating layer Scale18
I0702 00:34:49.380684 13010 net.cpp:397] Scale18 -> Convolution18 (in-place)
I0702 00:34:49.378553  4664 net.cpp:106] Creating Layer Scale18
I0702 00:34:49.378561  4664 net.cpp:454] Scale18 <- Convolution18
I0702 00:34:49.378572  4664 net.cpp:397] Scale18 -> Convolution18 (in-place)
I0702 00:34:49.378592  4664 layer_factory.hpp:77] Creating layer Scale18
I0702 00:34:49.378621  4664 net.cpp:150] Setting up Scale18
I0702 00:34:49.380703 13010 layer_factory.hpp:77] Creating layer Scale18
I0702 00:34:49.378633  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.380733 13010 net.cpp:150] Setting up Scale18
I0702 00:34:49.378641  4664 net.cpp:165] Memory required for data: 4026380
I0702 00:34:49.378654  4664 layer_factory.hpp:77] Creating layer ReLU16
I0702 00:34:49.378664  4664 net.cpp:106] Creating Layer ReLU16
I0702 00:34:49.378671  4664 net.cpp:454] ReLU16 <- Convolution18
I0702 00:34:49.378679  4664 net.cpp:397] ReLU16 -> Convolution18 (in-place)
I0702 00:34:49.380744 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.378690  4664 net.cpp:150] Setting up ReLU16
I0702 00:34:49.380753 13010 net.cpp:165] Memory required for data: 4026380
I0702 00:34:49.378696  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.380765 13010 layer_factory.hpp:77] Creating layer ReLU16
I0702 00:34:49.380415 20914 net.cpp:150] Setting up Convolution19
I0702 00:34:49.378705  4664 net.cpp:165] Memory required for data: 4042764
I0702 00:34:49.380774 13010 net.cpp:106] Creating Layer ReLU16
I0702 00:34:49.380431 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.380441 20914 net.cpp:165] Memory required for data: 4059148
I0702 00:34:49.378711  4664 layer_factory.hpp:77] Creating layer Convolution19
I0702 00:34:49.380453 20914 layer_factory.hpp:77] Creating layer BatchNorm19
I0702 00:34:49.378734  4664 net.cpp:106] Creating Layer Convolution19
I0702 00:34:49.380470 20914 net.cpp:106] Creating Layer BatchNorm19
I0702 00:34:49.378746  4664 net.cpp:454] Convolution19 <- Convolution18
I0702 00:34:49.380781 13010 net.cpp:454] ReLU16 <- Convolution18
I0702 00:34:49.380479 20914 net.cpp:454] BatchNorm19 <- Convolution19
I0702 00:34:49.378765  4664 net.cpp:411] Convolution19 -> Convolution19
I0702 00:34:49.380790 13010 net.cpp:397] ReLU16 -> Convolution18 (in-place)
I0702 00:34:49.380489 20914 net.cpp:397] BatchNorm19 -> Convolution19 (in-place)
I0702 00:34:49.380800 13010 net.cpp:150] Setting up ReLU16
I0702 00:34:49.380515 20914 net.cpp:150] Setting up BatchNorm19
I0702 00:34:49.380806 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.380527 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.379596  4664 net.cpp:150] Setting up Convolution19
I0702 00:34:49.380815 13010 net.cpp:165] Memory required for data: 4042764
I0702 00:34:49.380535 20914 net.cpp:165] Memory required for data: 4075532
I0702 00:34:49.379611  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.380821 13010 layer_factory.hpp:77] Creating layer Convolution19
I0702 00:34:49.380574 20914 layer_factory.hpp:77] Creating layer Scale19
I0702 00:34:49.379621  4664 net.cpp:165] Memory required for data: 4059148
I0702 00:34:49.379634  4664 layer_factory.hpp:77] Creating layer BatchNorm19
I0702 00:34:49.379648  4664 net.cpp:106] Creating Layer BatchNorm19
I0702 00:34:49.380844 13010 net.cpp:106] Creating Layer Convolution19
I0702 00:34:49.379657  4664 net.cpp:454] BatchNorm19 <- Convolution19
I0702 00:34:49.380856 13010 net.cpp:454] Convolution19 <- Convolution18
I0702 00:34:49.380590 20914 net.cpp:106] Creating Layer Scale19
I0702 00:34:49.380597 20914 net.cpp:454] Scale19 <- Convolution19
I0702 00:34:49.379667  4664 net.cpp:397] BatchNorm19 -> Convolution19 (in-place)
I0702 00:34:49.380872 13010 net.cpp:411] Convolution19 -> Convolution19
I0702 00:34:49.380607 20914 net.cpp:397] Scale19 -> Convolution19 (in-place)
I0702 00:34:49.379693  4664 net.cpp:150] Setting up BatchNorm19
I0702 00:34:49.380625 20914 layer_factory.hpp:77] Creating layer Scale19
I0702 00:34:49.379703  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.380654 20914 net.cpp:150] Setting up Scale19
I0702 00:34:49.379714  4664 net.cpp:165] Memory required for data: 4075532
I0702 00:34:49.380666 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.379748  4664 layer_factory.hpp:77] Creating layer Scale19
I0702 00:34:49.380676 20914 net.cpp:165] Memory required for data: 4091916
I0702 00:34:49.379765  4664 net.cpp:106] Creating Layer Scale19
I0702 00:34:49.380686 20914 layer_factory.hpp:77] Creating layer Eltwise8
I0702 00:34:49.379776  4664 net.cpp:454] Scale19 <- Convolution19
I0702 00:34:49.380697 20914 net.cpp:106] Creating Layer Eltwise8
I0702 00:34:49.379786  4664 net.cpp:397] Scale19 -> Convolution19 (in-place)
I0702 00:34:49.380704 20914 net.cpp:454] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0702 00:34:49.379803  4664 layer_factory.hpp:77] Creating layer Scale19
I0702 00:34:49.380720 20914 net.cpp:454] Eltwise8 <- Convolution19
I0702 00:34:49.379832  4664 net.cpp:150] Setting up Scale19
I0702 00:34:49.380736 20914 net.cpp:411] Eltwise8 -> Eltwise8
I0702 00:34:49.379843  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.380754 20914 net.cpp:150] Setting up Eltwise8
I0702 00:34:49.379853  4664 net.cpp:165] Memory required for data: 4091916
I0702 00:34:49.380762 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.379864  4664 layer_factory.hpp:77] Creating layer Eltwise8
I0702 00:34:49.380771 20914 net.cpp:165] Memory required for data: 4108300
I0702 00:34:49.379879  4664 net.cpp:106] Creating Layer Eltwise8
I0702 00:34:49.380779 20914 layer_factory.hpp:77] Creating layer ReLU17
I0702 00:34:49.379889  4664 net.cpp:454] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0702 00:34:49.380787 20914 net.cpp:106] Creating Layer ReLU17
I0702 00:34:49.379905  4664 net.cpp:454] Eltwise8 <- Convolution19
I0702 00:34:49.380795 20914 net.cpp:454] ReLU17 <- Eltwise8
I0702 00:34:49.379915  4664 net.cpp:411] Eltwise8 -> Eltwise8
I0702 00:34:49.380805 20914 net.cpp:397] ReLU17 -> Eltwise8 (in-place)
I0702 00:34:49.379928  4664 net.cpp:150] Setting up Eltwise8
I0702 00:34:49.380816 20914 net.cpp:150] Setting up ReLU17
I0702 00:34:49.380486 32261 net.cpp:150] Setting up Convolution20
I0702 00:34:49.379936  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.380822 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.379945  4664 net.cpp:165] Memory required for data: 4108300
I0702 00:34:49.380831 20914 net.cpp:165] Memory required for data: 4124684
I0702 00:34:49.379951  4664 layer_factory.hpp:77] Creating layer ReLU17
I0702 00:34:49.380837 20914 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0702 00:34:49.380501 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.379966  4664 net.cpp:106] Creating Layer ReLU17
I0702 00:34:49.380846 20914 net.cpp:106] Creating Layer Eltwise8_ReLU17_0_split
I0702 00:34:49.380853 20914 net.cpp:454] Eltwise8_ReLU17_0_split <- Eltwise8
I0702 00:34:49.380511 32261 net.cpp:165] Memory required for data: 4173836
I0702 00:34:49.380522 32261 layer_factory.hpp:77] Creating layer BatchNorm20
I0702 00:34:49.379972  4664 net.cpp:454] ReLU17 <- Eltwise8
I0702 00:34:49.380861 20914 net.cpp:411] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0702 00:34:49.380535 32261 net.cpp:106] Creating Layer BatchNorm20
I0702 00:34:49.379987  4664 net.cpp:397] ReLU17 -> Eltwise8 (in-place)
I0702 00:34:49.380873 20914 net.cpp:411] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0702 00:34:49.380543 32261 net.cpp:454] BatchNorm20 <- Convolution20
I0702 00:34:49.380884 20914 net.cpp:150] Setting up Eltwise8_ReLU17_0_split
I0702 00:34:49.380002  4664 net.cpp:150] Setting up ReLU17
I0702 00:34:49.380892 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.380009  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.380017  4664 net.cpp:165] Memory required for data: 4124684
I0702 00:34:49.380024  4664 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0702 00:34:49.380908 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.380034  4664 net.cpp:106] Creating Layer Eltwise8_ReLU17_0_split
I0702 00:34:49.380918 20914 net.cpp:165] Memory required for data: 4157452
I0702 00:34:49.380555 32261 net.cpp:397] BatchNorm20 -> Convolution20 (in-place)
I0702 00:34:49.380041  4664 net.cpp:454] Eltwise8_ReLU17_0_split <- Eltwise8
I0702 00:34:49.380923 20914 layer_factory.hpp:77] Creating layer Convolution20
I0702 00:34:49.380581 32261 net.cpp:150] Setting up BatchNorm20
I0702 00:34:49.380050  4664 net.cpp:411] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0702 00:34:49.380942 20914 net.cpp:106] Creating Layer Convolution20
I0702 00:34:49.380590 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.380064  4664 net.cpp:411] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0702 00:34:49.380954 20914 net.cpp:454] Convolution20 <- Eltwise8_ReLU17_0_split_0
I0702 00:34:49.380599 32261 net.cpp:165] Memory required for data: 4190220
I0702 00:34:49.380076  4664 net.cpp:150] Setting up Eltwise8_ReLU17_0_split
I0702 00:34:49.380975 20914 net.cpp:411] Convolution20 -> Convolution20
I0702 00:34:49.380612 32261 layer_factory.hpp:77] Creating layer Scale20
I0702 00:34:49.380084  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.380092  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.380100  4664 net.cpp:165] Memory required for data: 4157452
I0702 00:34:49.380106  4664 layer_factory.hpp:77] Creating layer Convolution20
I0702 00:34:49.380127  4664 net.cpp:106] Creating Layer Convolution20
I0702 00:34:49.380626 32261 net.cpp:106] Creating Layer Scale20
I0702 00:34:49.380139  4664 net.cpp:454] Convolution20 <- Eltwise8_ReLU17_0_split_0
I0702 00:34:49.380635 32261 net.cpp:454] Scale20 <- Convolution20
I0702 00:34:49.380151  4664 net.cpp:411] Convolution20 -> Convolution20
I0702 00:34:49.380647 32261 net.cpp:397] Scale20 -> Convolution20 (in-place)
I0702 00:34:49.380671 32261 layer_factory.hpp:77] Creating layer Scale20
I0702 00:34:49.380698 32261 net.cpp:150] Setting up Scale20
I0702 00:34:49.380714 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.380726 32261 net.cpp:165] Memory required for data: 4206604
I0702 00:34:49.380738 32261 layer_factory.hpp:77] Creating layer ReLU18
I0702 00:34:49.380753 32261 net.cpp:106] Creating Layer ReLU18
I0702 00:34:49.380762 32261 net.cpp:454] ReLU18 <- Convolution20
I0702 00:34:49.380771 32261 net.cpp:397] ReLU18 -> Convolution20 (in-place)
I0702 00:34:49.380782 32261 net.cpp:150] Setting up ReLU18
I0702 00:34:49.380789 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.380797 32261 net.cpp:165] Memory required for data: 4222988
I0702 00:34:49.380803 32261 layer_factory.hpp:77] Creating layer Convolution21
I0702 00:34:49.380821 32261 net.cpp:106] Creating Layer Convolution21
I0702 00:34:49.380831 32261 net.cpp:454] Convolution21 <- Convolution20
I0702 00:34:49.380844 32261 net.cpp:411] Convolution21 -> Convolution21
I0702 00:34:49.381711 13010 net.cpp:150] Setting up Convolution19
I0702 00:34:49.381728 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.381738 13010 net.cpp:165] Memory required for data: 4059148
I0702 00:34:49.381750 13010 layer_factory.hpp:77] Creating layer BatchNorm19
I0702 00:34:49.381762 13010 net.cpp:106] Creating Layer BatchNorm19
I0702 00:34:49.381770 13010 net.cpp:454] BatchNorm19 <- Convolution19
I0702 00:34:49.381780 13010 net.cpp:397] BatchNorm19 -> Convolution19 (in-place)
I0702 00:34:49.381798 13010 net.cpp:150] Setting up BatchNorm19
I0702 00:34:49.381808 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.381815 13010 net.cpp:165] Memory required for data: 4075532
I0702 00:34:49.381848 13010 layer_factory.hpp:77] Creating layer Scale19
I0702 00:34:49.381866 13010 net.cpp:106] Creating Layer Scale19
I0702 00:34:49.380986  4664 net.cpp:150] Setting up Convolution20
I0702 00:34:49.381875 13010 net.cpp:454] Scale19 <- Convolution19
I0702 00:34:49.381886 13010 net.cpp:397] Scale19 -> Convolution19 (in-place)
I0702 00:34:49.381903 13010 layer_factory.hpp:77] Creating layer Scale19
I0702 00:34:49.381002  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.381929 13010 net.cpp:150] Setting up Scale19
I0702 00:34:49.381939 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.381018  4664 net.cpp:165] Memory required for data: 4173836
I0702 00:34:49.381031  4664 layer_factory.hpp:77] Creating layer BatchNorm20
I0702 00:34:49.381042  4664 net.cpp:106] Creating Layer BatchNorm20
I0702 00:34:49.381948 13010 net.cpp:165] Memory required for data: 4091916
I0702 00:34:49.381960 13010 layer_factory.hpp:77] Creating layer Eltwise8
I0702 00:34:49.381970 13010 net.cpp:106] Creating Layer Eltwise8
I0702 00:34:49.381050  4664 net.cpp:454] BatchNorm20 <- Convolution20
I0702 00:34:49.381062  4664 net.cpp:397] BatchNorm20 -> Convolution20 (in-place)
I0702 00:34:49.381980 13010 net.cpp:454] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I0702 00:34:49.381997 13010 net.cpp:454] Eltwise8 <- Convolution19
I0702 00:34:49.382007 13010 net.cpp:411] Eltwise8 -> Eltwise8
I0702 00:34:49.381093  4664 net.cpp:150] Setting up BatchNorm20
I0702 00:34:49.382021 13010 net.cpp:150] Setting up Eltwise8
I0702 00:34:49.381104  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.381114  4664 net.cpp:165] Memory required for data: 4190220
I0702 00:34:49.381127  4664 layer_factory.hpp:77] Creating layer Scale20
I0702 00:34:49.382030 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.382037 13010 net.cpp:165] Memory required for data: 4108300
I0702 00:34:49.382045 13010 layer_factory.hpp:77] Creating layer ReLU17
I0702 00:34:49.381137  4664 net.cpp:106] Creating Layer Scale20
I0702 00:34:49.382053 13010 net.cpp:106] Creating Layer ReLU17
I0702 00:34:49.381145  4664 net.cpp:454] Scale20 <- Convolution20
I0702 00:34:49.382059 13010 net.cpp:454] ReLU17 <- Eltwise8
I0702 00:34:49.381158  4664 net.cpp:397] Scale20 -> Convolution20 (in-place)
I0702 00:34:49.382071 13010 net.cpp:397] ReLU17 -> Eltwise8 (in-place)
I0702 00:34:49.381178  4664 layer_factory.hpp:77] Creating layer Scale20
I0702 00:34:49.382081 13010 net.cpp:150] Setting up ReLU17
I0702 00:34:49.381206  4664 net.cpp:150] Setting up Scale20
I0702 00:34:49.382089 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.381218  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.382097 13010 net.cpp:165] Memory required for data: 4124684
I0702 00:34:49.381227  4664 net.cpp:165] Memory required for data: 4206604
I0702 00:34:49.382104 13010 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I0702 00:34:49.381238  4664 layer_factory.hpp:77] Creating layer ReLU18
I0702 00:34:49.382113 13010 net.cpp:106] Creating Layer Eltwise8_ReLU17_0_split
I0702 00:34:49.382119 13010 net.cpp:454] Eltwise8_ReLU17_0_split <- Eltwise8
I0702 00:34:49.382128 13010 net.cpp:411] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I0702 00:34:49.381814 20914 net.cpp:150] Setting up Convolution20
I0702 00:34:49.381248  4664 net.cpp:106] Creating Layer ReLU18
I0702 00:34:49.381255  4664 net.cpp:454] ReLU18 <- Convolution20
I0702 00:34:49.381266  4664 net.cpp:397] ReLU18 -> Convolution20 (in-place)
I0702 00:34:49.382139 13010 net.cpp:411] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I0702 00:34:49.381278  4664 net.cpp:150] Setting up ReLU18
I0702 00:34:49.382155 13010 net.cpp:150] Setting up Eltwise8_ReLU17_0_split
I0702 00:34:49.381830 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.381840 20914 net.cpp:165] Memory required for data: 4173836
I0702 00:34:49.381852 20914 layer_factory.hpp:77] Creating layer BatchNorm20
I0702 00:34:49.382163 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.382170 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.381866 20914 net.cpp:106] Creating Layer BatchNorm20
I0702 00:34:49.382179 13010 net.cpp:165] Memory required for data: 4157452
I0702 00:34:49.381873 20914 net.cpp:454] BatchNorm20 <- Convolution20
I0702 00:34:49.381882 20914 net.cpp:397] BatchNorm20 -> Convolution20 (in-place)
I0702 00:34:49.381283  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.382185 13010 layer_factory.hpp:77] Creating layer Convolution20
I0702 00:34:49.381909 20914 net.cpp:150] Setting up BatchNorm20
I0702 00:34:49.381291  4664 net.cpp:165] Memory required for data: 4222988
I0702 00:34:49.381918 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.381299  4664 layer_factory.hpp:77] Creating layer Convolution21
I0702 00:34:49.381927 20914 net.cpp:165] Memory required for data: 4190220
I0702 00:34:49.381319  4664 net.cpp:106] Creating Layer Convolution21
I0702 00:34:49.382205 13010 net.cpp:106] Creating Layer Convolution20
I0702 00:34:49.381940 20914 layer_factory.hpp:77] Creating layer Scale20
I0702 00:34:49.381331  4664 net.cpp:454] Convolution21 <- Convolution20
I0702 00:34:49.382215 13010 net.cpp:454] Convolution20 <- Eltwise8_ReLU17_0_split_0
I0702 00:34:49.381955 20914 net.cpp:106] Creating Layer Scale20
I0702 00:34:49.381342  4664 net.cpp:411] Convolution21 -> Convolution21
I0702 00:34:49.382226 13010 net.cpp:411] Convolution20 -> Convolution20
I0702 00:34:49.381966 20914 net.cpp:454] Scale20 <- Convolution20
I0702 00:34:49.381978 20914 net.cpp:397] Scale20 -> Convolution20 (in-place)
I0702 00:34:49.381662 32261 net.cpp:150] Setting up Convolution21
I0702 00:34:49.381995 20914 layer_factory.hpp:77] Creating layer Scale20
I0702 00:34:49.382027 20914 net.cpp:150] Setting up Scale20
I0702 00:34:49.382038 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.381677 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.381686 32261 net.cpp:165] Memory required for data: 4239372
I0702 00:34:49.382048 20914 net.cpp:165] Memory required for data: 4206604
I0702 00:34:49.381698 32261 layer_factory.hpp:77] Creating layer BatchNorm21
I0702 00:34:49.382059 20914 layer_factory.hpp:77] Creating layer ReLU18
I0702 00:34:49.382068 20914 net.cpp:106] Creating Layer ReLU18
I0702 00:34:49.382076 20914 net.cpp:454] ReLU18 <- Convolution20
I0702 00:34:49.382084 20914 net.cpp:397] ReLU18 -> Convolution20 (in-place)
I0702 00:34:49.382094 20914 net.cpp:150] Setting up ReLU18
I0702 00:34:49.381721 32261 net.cpp:106] Creating Layer BatchNorm21
I0702 00:34:49.382102 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.381731 32261 net.cpp:454] BatchNorm21 <- Convolution21
I0702 00:34:49.382109 20914 net.cpp:165] Memory required for data: 4222988
I0702 00:34:49.381741 32261 net.cpp:397] BatchNorm21 -> Convolution21 (in-place)
I0702 00:34:49.382117 20914 layer_factory.hpp:77] Creating layer Convolution21
I0702 00:34:49.381764 32261 net.cpp:150] Setting up BatchNorm21
I0702 00:34:49.382139 20914 net.cpp:106] Creating Layer Convolution21
I0702 00:34:49.381773 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.382153 20914 net.cpp:454] Convolution21 <- Convolution20
I0702 00:34:49.382169 20914 net.cpp:411] Convolution21 -> Convolution21
I0702 00:34:49.381783 32261 net.cpp:165] Memory required for data: 4255756
I0702 00:34:49.381795 32261 layer_factory.hpp:77] Creating layer Scale21
I0702 00:34:49.381808 32261 net.cpp:106] Creating Layer Scale21
I0702 00:34:49.381817 32261 net.cpp:454] Scale21 <- Convolution21
I0702 00:34:49.381826 32261 net.cpp:397] Scale21 -> Convolution21 (in-place)
I0702 00:34:49.381842 32261 layer_factory.hpp:77] Creating layer Scale21
I0702 00:34:49.381870 32261 net.cpp:150] Setting up Scale21
I0702 00:34:49.381880 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.381889 32261 net.cpp:165] Memory required for data: 4272140
I0702 00:34:49.381901 32261 layer_factory.hpp:77] Creating layer Eltwise9
I0702 00:34:49.381913 32261 net.cpp:106] Creating Layer Eltwise9
I0702 00:34:49.381923 32261 net.cpp:454] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0702 00:34:49.381932 32261 net.cpp:454] Eltwise9 <- Convolution21
I0702 00:34:49.381939 32261 net.cpp:411] Eltwise9 -> Eltwise9
I0702 00:34:49.381953 32261 net.cpp:150] Setting up Eltwise9
I0702 00:34:49.381960 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.381969 32261 net.cpp:165] Memory required for data: 4288524
I0702 00:34:49.381976 32261 layer_factory.hpp:77] Creating layer ReLU19
I0702 00:34:49.381988 32261 net.cpp:106] Creating Layer ReLU19
I0702 00:34:49.381996 32261 net.cpp:454] ReLU19 <- Eltwise9
I0702 00:34:49.382004 32261 net.cpp:397] ReLU19 -> Eltwise9 (in-place)
I0702 00:34:49.382014 32261 net.cpp:150] Setting up ReLU19
I0702 00:34:49.382020 32261 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.382028 32261 net.cpp:165] Memory required for data: 4304908
I0702 00:34:49.382035 32261 layer_factory.hpp:77] Creating layer Pooling1
I0702 00:34:49.382045 32261 net.cpp:106] Creating Layer Pooling1
I0702 00:34:49.382050 32261 net.cpp:454] Pooling1 <- Eltwise9
I0702 00:34:49.382062 32261 net.cpp:411] Pooling1 -> Pooling1
I0702 00:34:49.382078 32261 net.cpp:150] Setting up Pooling1
I0702 00:34:49.382086 32261 net.cpp:157] Top shape: 1 64 1 1 (64)
I0702 00:34:49.382095 32261 net.cpp:165] Memory required for data: 4305164
I0702 00:34:49.382102 32261 layer_factory.hpp:77] Creating layer InnerProduct1
I0702 00:34:49.382113 32261 net.cpp:106] Creating Layer InnerProduct1
I0702 00:34:49.382120 32261 net.cpp:454] InnerProduct1 <- Pooling1
I0702 00:34:49.382133 32261 net.cpp:411] InnerProduct1 -> InnerProduct1
I0702 00:34:49.382174 32261 net.cpp:150] Setting up InnerProduct1
I0702 00:34:49.382184 32261 net.cpp:157] Top shape: 1 10 (10)
I0702 00:34:49.382192 32261 net.cpp:165] Memory required for data: 4305204
I0702 00:34:49.382203 32261 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0702 00:34:49.382213 32261 net.cpp:106] Creating Layer InnerProduct1_InnerProduct1_0_split
I0702 00:34:49.382220 32261 net.cpp:454] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0702 00:34:49.382230 32261 net.cpp:411] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0702 00:34:49.382243 32261 net.cpp:411] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0702 00:34:49.382262 32261 net.cpp:150] Setting up InnerProduct1_InnerProduct1_0_split
I0702 00:34:49.382272 32261 net.cpp:157] Top shape: 1 10 (10)
I0702 00:34:49.382280 32261 net.cpp:157] Top shape: 1 10 (10)
I0702 00:34:49.382288 32261 net.cpp:165] Memory required for data: 4305284
I0702 00:34:49.382294 32261 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0702 00:34:49.382304 32261 net.cpp:106] Creating Layer SoftmaxWithLoss1
I0702 00:34:49.382310 32261 net.cpp:454] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0702 00:34:49.382318 32261 net.cpp:454] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0702 00:34:49.382338 32261 net.cpp:411] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0702 00:34:49.382351 32261 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0702 00:34:49.383065 13010 net.cpp:150] Setting up Convolution20
I0702 00:34:49.382186  4664 net.cpp:150] Setting up Convolution21
I0702 00:34:49.382375 32261 net.cpp:150] Setting up SoftmaxWithLoss1
I0702 00:34:49.383081 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.383090 13010 net.cpp:165] Memory required for data: 4173836
I0702 00:34:49.382385 32261 net.cpp:157] Top shape: (1)
I0702 00:34:49.383103 13010 layer_factory.hpp:77] Creating layer BatchNorm20
I0702 00:34:49.382393 32261 net.cpp:160]     with loss weight 1
I0702 00:34:49.382203  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.382212  4664 net.cpp:165] Memory required for data: 4239372
I0702 00:34:49.382403 32261 net.cpp:165] Memory required for data: 4305288
I0702 00:34:49.382411 32261 layer_factory.hpp:77] Creating layer Accuracy1
I0702 00:34:49.383121 13010 net.cpp:106] Creating Layer BatchNorm20
I0702 00:34:49.382225  4664 layer_factory.hpp:77] Creating layer BatchNorm21
I0702 00:34:49.383132 13010 net.cpp:454] BatchNorm20 <- Convolution20
I0702 00:34:49.383144 13010 net.cpp:397] BatchNorm20 -> Convolution20 (in-place)
I0702 00:34:49.382251  4664 net.cpp:106] Creating Layer BatchNorm21
I0702 00:34:49.382261  4664 net.cpp:454] BatchNorm21 <- Convolution21
I0702 00:34:49.382272  4664 net.cpp:397] BatchNorm21 -> Convolution21 (in-place)
I0702 00:34:49.383170 13010 net.cpp:150] Setting up BatchNorm20
I0702 00:34:49.383182 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.383190 13010 net.cpp:165] Memory required for data: 4190220
I0702 00:34:49.382297  4664 net.cpp:150] Setting up BatchNorm21
I0702 00:34:49.382308  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.382316  4664 net.cpp:165] Memory required for data: 4255756
I0702 00:34:49.383208 13010 layer_factory.hpp:77] Creating layer Scale20
I0702 00:34:49.383219 13010 net.cpp:106] Creating Layer Scale20
I0702 00:34:49.382333  4664 layer_factory.hpp:77] Creating layer Scale21
I0702 00:34:49.382344  4664 net.cpp:106] Creating Layer Scale21
I0702 00:34:49.383226 13010 net.cpp:454] Scale20 <- Convolution20
I0702 00:34:49.383235 13010 net.cpp:397] Scale20 -> Convolution20 (in-place)
I0702 00:34:49.382350  4664 net.cpp:454] Scale21 <- Convolution21
I0702 00:34:49.382359  4664 net.cpp:397] Scale21 -> Convolution21 (in-place)
I0702 00:34:49.383258 13010 layer_factory.hpp:77] Creating layer Scale20
I0702 00:34:49.383291 13010 net.cpp:150] Setting up Scale20
I0702 00:34:49.382381  4664 layer_factory.hpp:77] Creating layer Scale21
I0702 00:34:49.382407  4664 net.cpp:150] Setting up Scale21
I0702 00:34:49.383301 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.383311 13010 net.cpp:165] Memory required for data: 4206604
I0702 00:34:49.383322 13010 layer_factory.hpp:77] Creating layer ReLU18
I0702 00:34:49.383332 13010 net.cpp:106] Creating Layer ReLU18
I0702 00:34:49.382416  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.383337 13010 net.cpp:454] ReLU18 <- Convolution20
I0702 00:34:49.382431  4664 net.cpp:165] Memory required for data: 4272140
I0702 00:34:49.382443  4664 layer_factory.hpp:77] Creating layer Eltwise9
I0702 00:34:49.383008 20914 net.cpp:150] Setting up Convolution21
I0702 00:34:49.383349 13010 net.cpp:397] ReLU18 -> Convolution20 (in-place)
I0702 00:34:49.382454  4664 net.cpp:106] Creating Layer Eltwise9
I0702 00:34:49.383361 13010 net.cpp:150] Setting up ReLU18
I0702 00:34:49.382462  4664 net.cpp:454] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0702 00:34:49.383368 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.383024 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.383034 20914 net.cpp:165] Memory required for data: 4239372
I0702 00:34:49.382468  4664 net.cpp:454] Eltwise9 <- Convolution21
I0702 00:34:49.382480  4664 net.cpp:411] Eltwise9 -> Eltwise9
I0702 00:34:49.383376 13010 net.cpp:165] Memory required for data: 4222988
I0702 00:34:49.383046 20914 layer_factory.hpp:77] Creating layer BatchNorm21
I0702 00:34:49.382493  4664 net.cpp:150] Setting up Eltwise9
I0702 00:34:49.383383 13010 layer_factory.hpp:77] Creating layer Convolution21
I0702 00:34:49.383067 20914 net.cpp:106] Creating Layer BatchNorm21
I0702 00:34:49.383075 20914 net.cpp:454] BatchNorm21 <- Convolution21
I0702 00:34:49.383085 20914 net.cpp:397] BatchNorm21 -> Convolution21 (in-place)
I0702 00:34:49.382500  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.382509  4664 net.cpp:165] Memory required for data: 4288524
I0702 00:34:49.382516  4664 layer_factory.hpp:77] Creating layer ReLU19
I0702 00:34:49.383411 13010 net.cpp:106] Creating Layer Convolution21
I0702 00:34:49.383112 20914 net.cpp:150] Setting up BatchNorm21
I0702 00:34:49.383123 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.383132 20914 net.cpp:165] Memory required for data: 4255756
I0702 00:34:49.382524  4664 net.cpp:106] Creating Layer ReLU19
I0702 00:34:49.382531  4664 net.cpp:454] ReLU19 <- Eltwise9
I0702 00:34:49.383424 13010 net.cpp:454] Convolution21 <- Convolution20
I0702 00:34:49.382539  4664 net.cpp:397] ReLU19 -> Eltwise9 (in-place)
I0702 00:34:49.383440 13010 net.cpp:411] Convolution21 -> Convolution21
I0702 00:34:49.383147 20914 layer_factory.hpp:77] Creating layer Scale21
I0702 00:34:49.382550  4664 net.cpp:150] Setting up ReLU19
I0702 00:34:49.383162 20914 net.cpp:106] Creating Layer Scale21
I0702 00:34:49.382556  4664 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.383172 20914 net.cpp:454] Scale21 <- Convolution21
I0702 00:34:49.383182 20914 net.cpp:397] Scale21 -> Convolution21 (in-place)
I0702 00:34:49.383198 20914 layer_factory.hpp:77] Creating layer Scale21
I0702 00:34:49.382565  4664 net.cpp:165] Memory required for data: 4304908
I0702 00:34:49.382570  4664 layer_factory.hpp:77] Creating layer Pooling1
I0702 00:34:49.383235 20914 net.cpp:150] Setting up Scale21
I0702 00:34:49.382586  4664 net.cpp:106] Creating Layer Pooling1
I0702 00:34:49.382594  4664 net.cpp:454] Pooling1 <- Eltwise9
I0702 00:34:49.383247 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.382604  4664 net.cpp:411] Pooling1 -> Pooling1
I0702 00:34:49.383256 20914 net.cpp:165] Memory required for data: 4272140
I0702 00:34:49.382618  4664 net.cpp:150] Setting up Pooling1
I0702 00:34:49.383271 20914 layer_factory.hpp:77] Creating layer Eltwise9
I0702 00:34:49.383281 20914 net.cpp:106] Creating Layer Eltwise9
I0702 00:34:49.382628  4664 net.cpp:157] Top shape: 1 64 1 1 (64)
I0702 00:34:49.383289 20914 net.cpp:454] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0702 00:34:49.383297 20914 net.cpp:454] Eltwise9 <- Convolution21
I0702 00:34:49.382637  4664 net.cpp:165] Memory required for data: 4305164
I0702 00:34:49.383306 20914 net.cpp:411] Eltwise9 -> Eltwise9
I0702 00:34:49.382643  4664 layer_factory.hpp:77] Creating layer InnerProduct1
I0702 00:34:49.382658  4664 net.cpp:106] Creating Layer InnerProduct1
I0702 00:34:49.383319 20914 net.cpp:150] Setting up Eltwise9
I0702 00:34:49.383327 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.382666  4664 net.cpp:454] InnerProduct1 <- Pooling1
I0702 00:34:49.383334 20914 net.cpp:165] Memory required for data: 4288524
I0702 00:34:49.383340 20914 layer_factory.hpp:77] Creating layer ReLU19
I0702 00:34:49.383358 20914 net.cpp:106] Creating Layer ReLU19
I0702 00:34:49.383366 20914 net.cpp:454] ReLU19 <- Eltwise9
I0702 00:34:49.382676  4664 net.cpp:411] InnerProduct1 -> InnerProduct1
I0702 00:34:49.383375 20914 net.cpp:397] ReLU19 -> Eltwise9 (in-place)
I0702 00:34:49.382719  4664 net.cpp:150] Setting up InnerProduct1
I0702 00:34:49.383386 20914 net.cpp:150] Setting up ReLU19
I0702 00:34:49.382732  4664 net.cpp:157] Top shape: 1 10 (10)
I0702 00:34:49.383393 20914 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.383401 20914 net.cpp:165] Memory required for data: 4304908
I0702 00:34:49.382741  4664 net.cpp:165] Memory required for data: 4305204
I0702 00:34:49.382753  4664 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0702 00:34:49.383407 20914 layer_factory.hpp:77] Creating layer Pooling1
I0702 00:34:49.382768  4664 net.cpp:106] Creating Layer InnerProduct1_InnerProduct1_0_split
I0702 00:34:49.383417 20914 net.cpp:106] Creating Layer Pooling1
I0702 00:34:49.382777  4664 net.cpp:454] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0702 00:34:49.383426 20914 net.cpp:454] Pooling1 <- Eltwise9
I0702 00:34:49.382786  4664 net.cpp:411] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0702 00:34:49.383435 20914 net.cpp:411] Pooling1 -> Pooling1
I0702 00:34:49.382798  4664 net.cpp:411] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0702 00:34:49.383450 20914 net.cpp:150] Setting up Pooling1
I0702 00:34:49.383456 20914 net.cpp:157] Top shape: 1 64 1 1 (64)
I0702 00:34:49.382812  4664 net.cpp:150] Setting up InnerProduct1_InnerProduct1_0_split
I0702 00:34:49.383466 20914 net.cpp:165] Memory required for data: 4305164
I0702 00:34:49.382820  4664 net.cpp:157] Top shape: 1 10 (10)
I0702 00:34:49.383471 20914 layer_factory.hpp:77] Creating layer InnerProduct1
I0702 00:34:49.382828  4664 net.cpp:157] Top shape: 1 10 (10)
I0702 00:34:49.383482 20914 net.cpp:106] Creating Layer InnerProduct1
I0702 00:34:49.382836  4664 net.cpp:165] Memory required for data: 4305284
I0702 00:34:49.383489 20914 net.cpp:454] InnerProduct1 <- Pooling1
I0702 00:34:49.383504 20914 net.cpp:411] InnerProduct1 -> InnerProduct1
I0702 00:34:49.382843  4664 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0702 00:34:49.382853  4664 net.cpp:106] Creating Layer SoftmaxWithLoss1
I0702 00:34:49.382859  4664 net.cpp:454] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0702 00:34:49.382866  4664 net.cpp:454] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0702 00:34:49.383551 20914 net.cpp:150] Setting up InnerProduct1
I0702 00:34:49.382884  4664 net.cpp:411] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0702 00:34:49.382899  4664 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0702 00:34:49.383564 20914 net.cpp:157] Top shape: 1 10 (10)
I0702 00:34:49.382922  4664 net.cpp:150] Setting up SoftmaxWithLoss1
I0702 00:34:49.383574 20914 net.cpp:165] Memory required for data: 4305204
I0702 00:34:49.383584 20914 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0702 00:34:49.382933  4664 net.cpp:157] Top shape: (1)
I0702 00:34:49.383594 20914 net.cpp:106] Creating Layer InnerProduct1_InnerProduct1_0_split
I0702 00:34:49.383602 20914 net.cpp:454] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0702 00:34:49.382943  4664 net.cpp:160]     with loss weight 1
I0702 00:34:49.383615 20914 net.cpp:411] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0702 00:34:49.382959  4664 net.cpp:165] Memory required for data: 4305288
I0702 00:34:49.382966  4664 layer_factory.hpp:77] Creating layer Accuracy1
I0702 00:34:49.383626 20914 net.cpp:411] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0702 00:34:49.383639 20914 net.cpp:150] Setting up InnerProduct1_InnerProduct1_0_split
I0702 00:34:49.383646 20914 net.cpp:157] Top shape: 1 10 (10)
I0702 00:34:49.383656 20914 net.cpp:157] Top shape: 1 10 (10)
I0702 00:34:49.383662 20914 net.cpp:165] Memory required for data: 4305284
I0702 00:34:49.383669 20914 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0702 00:34:49.383678 20914 net.cpp:106] Creating Layer SoftmaxWithLoss1
I0702 00:34:49.383685 20914 net.cpp:454] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0702 00:34:49.383693 20914 net.cpp:454] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0702 00:34:49.383718 20914 net.cpp:411] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0702 00:34:49.383736 20914 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0702 00:34:49.383757 20914 net.cpp:150] Setting up SoftmaxWithLoss1
I0702 00:34:49.383766 20914 net.cpp:157] Top shape: (1)
I0702 00:34:49.383775 20914 net.cpp:160]     with loss weight 1
I0702 00:34:49.383786 20914 net.cpp:165] Memory required for data: 4305288
I0702 00:34:49.383793 20914 layer_factory.hpp:77] Creating layer Accuracy1
I0702 00:34:49.384263 13010 net.cpp:150] Setting up Convolution21
I0702 00:34:49.383595 32261 net.cpp:106] Creating Layer Accuracy1
I0702 00:34:49.384277 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.384287 13010 net.cpp:165] Memory required for data: 4239372
I0702 00:34:49.383620 32261 net.cpp:454] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0702 00:34:49.383630 32261 net.cpp:454] Accuracy1 <- Data2_Data1_1_split_1
I0702 00:34:49.384299 13010 layer_factory.hpp:77] Creating layer BatchNorm21
I0702 00:34:49.383641 32261 net.cpp:411] Accuracy1 -> Accuracy1
I0702 00:34:49.384325 13010 net.cpp:106] Creating Layer BatchNorm21
I0702 00:34:49.384335 13010 net.cpp:454] BatchNorm21 <- Convolution21
I0702 00:34:49.384346 13010 net.cpp:397] BatchNorm21 -> Convolution21 (in-place)
I0702 00:34:49.384372 13010 net.cpp:150] Setting up BatchNorm21
I0702 00:34:49.384382 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.384392 13010 net.cpp:165] Memory required for data: 4255756
I0702 00:34:49.384418 13010 layer_factory.hpp:77] Creating layer Scale21
I0702 00:34:49.384438 13010 net.cpp:106] Creating Layer Scale21
I0702 00:34:49.384447 13010 net.cpp:454] Scale21 <- Convolution21
I0702 00:34:49.384457 13010 net.cpp:397] Scale21 -> Convolution21 (in-place)
I0702 00:34:49.384474 13010 layer_factory.hpp:77] Creating layer Scale21
I0702 00:34:49.384505 13010 net.cpp:150] Setting up Scale21
I0702 00:34:49.384517 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.384533 13010 net.cpp:165] Memory required for data: 4272140
I0702 00:34:49.384546 13010 layer_factory.hpp:77] Creating layer Eltwise9
I0702 00:34:49.384557 13010 net.cpp:106] Creating Layer Eltwise9
I0702 00:34:49.384563 13010 net.cpp:454] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I0702 00:34:49.384572 13010 net.cpp:454] Eltwise9 <- Convolution21
I0702 00:34:49.384582 13010 net.cpp:411] Eltwise9 -> Eltwise9
I0702 00:34:49.384594 13010 net.cpp:150] Setting up Eltwise9
I0702 00:34:49.384603 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.384611 13010 net.cpp:165] Memory required for data: 4288524
I0702 00:34:49.384618 13010 layer_factory.hpp:77] Creating layer ReLU19
I0702 00:34:49.384631 13010 net.cpp:106] Creating Layer ReLU19
I0702 00:34:49.384639 13010 net.cpp:454] ReLU19 <- Eltwise9
I0702 00:34:49.384646 13010 net.cpp:397] ReLU19 -> Eltwise9 (in-place)
I0702 00:34:49.384656 13010 net.cpp:150] Setting up ReLU19
I0702 00:34:49.384663 13010 net.cpp:157] Top shape: 1 64 8 8 (4096)
I0702 00:34:49.384671 13010 net.cpp:165] Memory required for data: 4304908
I0702 00:34:49.384678 13010 layer_factory.hpp:77] Creating layer Pooling1
I0702 00:34:49.384687 13010 net.cpp:106] Creating Layer Pooling1
I0702 00:34:49.383756  4664 net.cpp:106] Creating Layer Accuracy1
I0702 00:34:49.383780  4664 net.cpp:454] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0702 00:34:49.383792  4664 net.cpp:454] Accuracy1 <- Data2_Data1_1_split_1
I0702 00:34:49.383805  4664 net.cpp:411] Accuracy1 -> Accuracy1
I0702 00:34:49.384694 13010 net.cpp:454] Pooling1 <- Eltwise9
I0702 00:34:49.384708 13010 net.cpp:411] Pooling1 -> Pooling1
I0702 00:34:49.384727 13010 net.cpp:150] Setting up Pooling1
I0702 00:34:49.384735 13010 net.cpp:157] Top shape: 1 64 1 1 (64)
I0702 00:34:49.384745 13010 net.cpp:165] Memory required for data: 4305164
I0702 00:34:49.384752 13010 layer_factory.hpp:77] Creating layer InnerProduct1
I0702 00:34:49.384766 13010 net.cpp:106] Creating Layer InnerProduct1
I0702 00:34:49.384775 13010 net.cpp:454] InnerProduct1 <- Pooling1
I0702 00:34:49.384785 13010 net.cpp:411] InnerProduct1 -> InnerProduct1
I0702 00:34:49.384829 13010 net.cpp:150] Setting up InnerProduct1
I0702 00:34:49.384840 13010 net.cpp:157] Top shape: 1 10 (10)
I0702 00:34:49.384850 13010 net.cpp:165] Memory required for data: 4305204
I0702 00:34:49.384860 13010 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I0702 00:34:49.384871 13010 net.cpp:106] Creating Layer InnerProduct1_InnerProduct1_0_split
I0702 00:34:49.384877 13010 net.cpp:454] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I0702 00:34:49.384892 13010 net.cpp:411] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I0702 00:34:49.384909 13010 net.cpp:411] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I0702 00:34:49.384922 13010 net.cpp:150] Setting up InnerProduct1_InnerProduct1_0_split
I0702 00:34:49.384929 13010 net.cpp:157] Top shape: 1 10 (10)
I0702 00:34:49.384938 13010 net.cpp:157] Top shape: 1 10 (10)
I0702 00:34:49.384945 13010 net.cpp:165] Memory required for data: 4305284
I0702 00:34:49.384953 13010 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0702 00:34:49.384961 13010 net.cpp:106] Creating Layer SoftmaxWithLoss1
I0702 00:34:49.384968 13010 net.cpp:454] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I0702 00:34:49.384976 13010 net.cpp:454] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I0702 00:34:49.384994 13010 net.cpp:411] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I0702 00:34:49.385008 13010 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I0702 00:34:49.385033 13010 net.cpp:150] Setting up SoftmaxWithLoss1
I0702 00:34:49.385044 13010 net.cpp:157] Top shape: (1)
I0702 00:34:49.385053 13010 net.cpp:160]     with loss weight 1
I0702 00:34:49.385066 13010 net.cpp:165] Memory required for data: 4305288
I0702 00:34:49.385072 13010 layer_factory.hpp:77] Creating layer Accuracy1
I0702 00:34:49.384732 20914 net.cpp:106] Creating Layer Accuracy1
I0702 00:34:49.384755 20914 net.cpp:454] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0702 00:34:49.384770 20914 net.cpp:454] Accuracy1 <- Data2_Data1_1_split_1
I0702 00:34:49.384788 20914 net.cpp:411] Accuracy1 -> Accuracy1
I0702 00:34:49.384923 32261 net.cpp:150] Setting up Accuracy1
I0702 00:34:49.384946 32261 net.cpp:157] Top shape: (1)
I0702 00:34:49.384958 32261 net.cpp:165] Memory required for data: 4305292
I0702 00:34:49.384966 32261 net.cpp:228] Accuracy1 does not need backward computation.
I0702 00:34:49.384974 32261 net.cpp:226] SoftmaxWithLoss1 needs backward computation.
I0702 00:34:49.384982 32261 net.cpp:226] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0702 00:34:49.384989 32261 net.cpp:226] InnerProduct1 needs backward computation.
I0702 00:34:49.384996 32261 net.cpp:226] Pooling1 needs backward computation.
I0702 00:34:49.385002 32261 net.cpp:226] ReLU19 needs backward computation.
I0702 00:34:49.385008 32261 net.cpp:226] Eltwise9 needs backward computation.
I0702 00:34:49.385016 32261 net.cpp:226] Scale21 needs backward computation.
I0702 00:34:49.385022 32261 net.cpp:226] BatchNorm21 needs backward computation.
I0702 00:34:49.385028 32261 net.cpp:226] Convolution21 needs backward computation.
I0702 00:34:49.385035 32261 net.cpp:226] ReLU18 needs backward computation.
I0702 00:34:49.385041 32261 net.cpp:226] Scale20 needs backward computation.
I0702 00:34:49.385048 32261 net.cpp:226] BatchNorm20 needs backward computation.
I0702 00:34:49.385059 32261 net.cpp:226] Convolution20 needs backward computation.
I0702 00:34:49.385069 32261 net.cpp:226] Eltwise8_ReLU17_0_split needs backward computation.
I0702 00:34:49.385076 32261 net.cpp:226] ReLU17 needs backward computation.
I0702 00:34:49.385082 32261 net.cpp:226] Eltwise8 needs backward computation.
I0702 00:34:49.385089 32261 net.cpp:226] Scale19 needs backward computation.
I0702 00:34:49.385095 32261 net.cpp:226] BatchNorm19 needs backward computation.
I0702 00:34:49.385102 32261 net.cpp:226] Convolution19 needs backward computation.
I0702 00:34:49.385108 32261 net.cpp:226] ReLU16 needs backward computation.
I0702 00:34:49.385114 32261 net.cpp:226] Scale18 needs backward computation.
I0702 00:34:49.385120 32261 net.cpp:226] BatchNorm18 needs backward computation.
I0702 00:34:49.385126 32261 net.cpp:226] Convolution18 needs backward computation.
I0702 00:34:49.385133 32261 net.cpp:226] Eltwise7_ReLU15_0_split needs backward computation.
I0702 00:34:49.385140 32261 net.cpp:226] ReLU15 needs backward computation.
I0702 00:34:49.385146 32261 net.cpp:226] Eltwise7 needs backward computation.
I0702 00:34:49.385157 32261 net.cpp:226] Scale17 needs backward computation.
I0702 00:34:49.385166 32261 net.cpp:226] BatchNorm17 needs backward computation.
I0702 00:34:49.385176 32261 net.cpp:226] Convolution17 needs backward computation.
I0702 00:34:49.385185 32261 net.cpp:226] ReLU14 needs backward computation.
I0702 00:34:49.385190 32261 net.cpp:226] Scale16 needs backward computation.
I0702 00:34:49.385197 32261 net.cpp:226] BatchNorm16 needs backward computation.
I0702 00:34:49.385910 13010 net.cpp:106] Creating Layer Accuracy1
I0702 00:34:49.385203 32261 net.cpp:226] Convolution16 needs backward computation.
I0702 00:34:49.385210 32261 net.cpp:226] Scale15 needs backward computation.
I0702 00:34:49.385217 32261 net.cpp:226] BatchNorm15 needs backward computation.
I0702 00:34:49.385223 32261 net.cpp:226] Convolution15 needs backward computation.
I0702 00:34:49.385932 13010 net.cpp:454] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I0702 00:34:49.385943 13010 net.cpp:454] Accuracy1 <- Data2_Data1_1_split_1
I0702 00:34:49.385236 32261 net.cpp:226] Eltwise6_ReLU13_0_split needs backward computation.
I0702 00:34:49.385046  4664 net.cpp:150] Setting up Accuracy1
I0702 00:34:49.385956 13010 net.cpp:411] Accuracy1 -> Accuracy1
I0702 00:34:49.385254 32261 net.cpp:226] ReLU13 needs backward computation.
I0702 00:34:49.385273 32261 net.cpp:226] Eltwise6 needs backward computation.
I0702 00:34:49.385288 32261 net.cpp:226] Scale14 needs backward computation.
I0702 00:34:49.385066  4664 net.cpp:157] Top shape: (1)
I0702 00:34:49.385089  4664 net.cpp:165] Memory required for data: 4305292
I0702 00:34:49.385294 32261 net.cpp:226] BatchNorm14 needs backward computation.
I0702 00:34:49.385099  4664 net.cpp:228] Accuracy1 does not need backward computation.
I0702 00:34:49.385300 32261 net.cpp:226] Convolution14 needs backward computation.
I0702 00:34:49.385308 32261 net.cpp:226] ReLU12 needs backward computation.
I0702 00:34:49.385120  4664 net.cpp:226] SoftmaxWithLoss1 needs backward computation.
I0702 00:34:49.385152  4664 net.cpp:226] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0702 00:34:49.385313 32261 net.cpp:226] Scale13 needs backward computation.
I0702 00:34:49.385319 32261 net.cpp:226] BatchNorm13 needs backward computation.
I0702 00:34:49.385325 32261 net.cpp:226] Convolution13 needs backward computation.
I0702 00:34:49.385332 32261 net.cpp:226] Eltwise5_ReLU11_0_split needs backward computation.
I0702 00:34:49.385339 32261 net.cpp:226] ReLU11 needs backward computation.
I0702 00:34:49.385345 32261 net.cpp:226] Eltwise5 needs backward computation.
I0702 00:34:49.385352 32261 net.cpp:226] Scale12 needs backward computation.
I0702 00:34:49.385167  4664 net.cpp:226] InnerProduct1 needs backward computation.
I0702 00:34:49.385359 32261 net.cpp:226] BatchNorm12 needs backward computation.
I0702 00:34:49.385175  4664 net.cpp:226] Pooling1 needs backward computation.
I0702 00:34:49.385365 32261 net.cpp:226] Convolution12 needs backward computation.
I0702 00:34:49.385371 32261 net.cpp:226] ReLU10 needs backward computation.
I0702 00:34:49.385377 32261 net.cpp:226] Scale11 needs backward computation.
I0702 00:34:49.385202  4664 net.cpp:226] ReLU19 needs backward computation.
I0702 00:34:49.385210  4664 net.cpp:226] Eltwise9 needs backward computation.
I0702 00:34:49.385383 32261 net.cpp:226] BatchNorm11 needs backward computation.
I0702 00:34:49.385236  4664 net.cpp:226] Scale21 needs backward computation.
I0702 00:34:49.385390 32261 net.cpp:226] Convolution11 needs backward computation.
I0702 00:34:49.385396 32261 net.cpp:226] Eltwise4_ReLU9_0_split needs backward computation.
I0702 00:34:49.385402 32261 net.cpp:226] ReLU9 needs backward computation.
I0702 00:34:49.385409 32261 net.cpp:226] Eltwise4 needs backward computation.
I0702 00:34:49.385416 32261 net.cpp:226] Scale10 needs backward computation.
I0702 00:34:49.385422 32261 net.cpp:226] BatchNorm10 needs backward computation.
I0702 00:34:49.385428 32261 net.cpp:226] Convolution10 needs backward computation.
I0702 00:34:49.385244  4664 net.cpp:226] BatchNorm21 needs backward computation.
I0702 00:34:49.385435 32261 net.cpp:226] ReLU8 needs backward computation.
I0702 00:34:49.385280  4664 net.cpp:226] Convolution21 needs backward computation.
I0702 00:34:49.385442 32261 net.cpp:226] Scale9 needs backward computation.
I0702 00:34:49.385448 32261 net.cpp:226] BatchNorm9 needs backward computation.
I0702 00:34:49.385454 32261 net.cpp:226] Convolution9 needs backward computation.
I0702 00:34:49.385291  4664 net.cpp:226] ReLU18 needs backward computation.
I0702 00:34:49.385298  4664 net.cpp:226] Scale20 needs backward computation.
I0702 00:34:49.385460 32261 net.cpp:226] Scale8 needs backward computation.
I0702 00:34:49.385468 32261 net.cpp:226] BatchNorm8 needs backward computation.
I0702 00:34:49.385473 32261 net.cpp:226] Convolution8 needs backward computation.
I0702 00:34:49.385479 32261 net.cpp:226] Eltwise3_ReLU7_0_split needs backward computation.
I0702 00:34:49.385486 32261 net.cpp:226] ReLU7 needs backward computation.
I0702 00:34:49.385324  4664 net.cpp:226] BatchNorm20 needs backward computation.
I0702 00:34:49.385493 32261 net.cpp:226] Eltwise3 needs backward computation.
I0702 00:34:49.385334  4664 net.cpp:226] Convolution20 needs backward computation.
I0702 00:34:49.385502 32261 net.cpp:226] Scale7 needs backward computation.
I0702 00:34:49.385352  4664 net.cpp:226] Eltwise8_ReLU17_0_split needs backward computation.
I0702 00:34:49.385512 32261 net.cpp:226] BatchNorm7 needs backward computation.
I0702 00:34:49.385519 32261 net.cpp:226] Convolution7 needs backward computation.
I0702 00:34:49.385525 32261 net.cpp:226] ReLU6 needs backward computation.
I0702 00:34:49.385531 32261 net.cpp:226] Scale6 needs backward computation.
I0702 00:34:49.385537 32261 net.cpp:226] BatchNorm6 needs backward computation.
I0702 00:34:49.385547 32261 net.cpp:226] Convolution6 needs backward computation.
I0702 00:34:49.385368  4664 net.cpp:226] ReLU17 needs backward computation.
I0702 00:34:49.385375  4664 net.cpp:226] Eltwise8 needs backward computation.
I0702 00:34:49.385402  4664 net.cpp:226] Scale19 needs backward computation.
I0702 00:34:49.385560 32261 net.cpp:226] Eltwise2_ReLU5_0_split needs backward computation.
I0702 00:34:49.385571 32261 net.cpp:226] ReLU5 needs backward computation.
I0702 00:34:49.385577 32261 net.cpp:226] Eltwise2 needs backward computation.
I0702 00:34:49.385584 32261 net.cpp:226] Scale5 needs backward computation.
I0702 00:34:49.385409  4664 net.cpp:226] BatchNorm19 needs backward computation.
I0702 00:34:49.385591 32261 net.cpp:226] BatchNorm5 needs backward computation.
I0702 00:34:49.385416  4664 net.cpp:226] Convolution19 needs backward computation.
I0702 00:34:49.385597 32261 net.cpp:226] Convolution5 needs backward computation.
I0702 00:34:49.385603 32261 net.cpp:226] ReLU4 needs backward computation.
I0702 00:34:49.385435  4664 net.cpp:226] ReLU16 needs backward computation.
I0702 00:34:49.385609 32261 net.cpp:226] Scale4 needs backward computation.
I0702 00:34:49.385454  4664 net.cpp:226] Scale18 needs backward computation.
I0702 00:34:49.385615 32261 net.cpp:226] BatchNorm4 needs backward computation.
I0702 00:34:49.385629 32261 net.cpp:226] Convolution4 needs backward computation.
I0702 00:34:49.385637 32261 net.cpp:226] Eltwise1_ReLU3_0_split needs backward computation.
I0702 00:34:49.385644 32261 net.cpp:226] ReLU3 needs backward computation.
I0702 00:34:49.385463  4664 net.cpp:226] BatchNorm18 needs backward computation.
I0702 00:34:49.385469  4664 net.cpp:226] Convolution18 needs backward computation.
I0702 00:34:49.385496  4664 net.cpp:226] Eltwise7_ReLU15_0_split needs backward computation.
I0702 00:34:49.385506  4664 net.cpp:226] ReLU15 needs backward computation.
I0702 00:34:49.385650 32261 net.cpp:226] Eltwise1 needs backward computation.
I0702 00:34:49.385512  4664 net.cpp:226] Eltwise7 needs backward computation.
I0702 00:34:49.386046 20914 net.cpp:150] Setting up Accuracy1
I0702 00:34:49.385658 32261 net.cpp:226] Scale3 needs backward computation.
I0702 00:34:49.386070 20914 net.cpp:157] Top shape: (1)
I0702 00:34:49.386081 20914 net.cpp:165] Memory required for data: 4305292
I0702 00:34:49.385663 32261 net.cpp:226] BatchNorm3 needs backward computation.
I0702 00:34:49.385669 32261 net.cpp:226] Convolution3 needs backward computation.
I0702 00:34:49.385520  4664 net.cpp:226] Scale17 needs backward computation.
I0702 00:34:49.386090 20914 net.cpp:228] Accuracy1 does not need backward computation.
I0702 00:34:49.386098 20914 net.cpp:226] SoftmaxWithLoss1 needs backward computation.
I0702 00:34:49.386106 20914 net.cpp:226] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0702 00:34:49.385675 32261 net.cpp:226] ReLU2 needs backward computation.
I0702 00:34:49.385681 32261 net.cpp:226] Scale2 needs backward computation.
I0702 00:34:49.385526  4664 net.cpp:226] BatchNorm17 needs backward computation.
I0702 00:34:49.386113 20914 net.cpp:226] InnerProduct1 needs backward computation.
I0702 00:34:49.385687 32261 net.cpp:226] BatchNorm2 needs backward computation.
I0702 00:34:49.385565  4664 net.cpp:226] Convolution17 needs backward computation.
I0702 00:34:49.386121 20914 net.cpp:226] Pooling1 needs backward computation.
I0702 00:34:49.386127 20914 net.cpp:226] ReLU19 needs backward computation.
I0702 00:34:49.386133 20914 net.cpp:226] Eltwise9 needs backward computation.
I0702 00:34:49.385694 32261 net.cpp:226] Convolution2 needs backward computation.
I0702 00:34:49.386140 20914 net.cpp:226] Scale21 needs backward computation.
I0702 00:34:49.386147 20914 net.cpp:226] BatchNorm21 needs backward computation.
I0702 00:34:49.386153 20914 net.cpp:226] Convolution21 needs backward computation.
I0702 00:34:49.386159 20914 net.cpp:226] ReLU18 needs backward computation.
I0702 00:34:49.385700 32261 net.cpp:226] Convolution1_ReLU1_0_split needs backward computation.
I0702 00:34:49.385574  4664 net.cpp:226] ReLU14 needs backward computation.
I0702 00:34:49.386167 20914 net.cpp:226] Scale20 needs backward computation.
I0702 00:34:49.386173 20914 net.cpp:226] BatchNorm20 needs backward computation.
I0702 00:34:49.386178 20914 net.cpp:226] Convolution20 needs backward computation.
I0702 00:34:49.386184 20914 net.cpp:226] Eltwise8_ReLU17_0_split needs backward computation.
I0702 00:34:49.385707 32261 net.cpp:226] ReLU1 needs backward computation.
I0702 00:34:49.385581  4664 net.cpp:226] Scale16 needs backward computation.
I0702 00:34:49.386191 20914 net.cpp:226] ReLU17 needs backward computation.
I0702 00:34:49.386198 20914 net.cpp:226] Eltwise8 needs backward computation.
I0702 00:34:49.385713 32261 net.cpp:226] Scale1 needs backward computation.
I0702 00:34:49.385602  4664 net.cpp:226] BatchNorm16 needs backward computation.
I0702 00:34:49.386204 20914 net.cpp:226] Scale19 needs backward computation.
I0702 00:34:49.386210 20914 net.cpp:226] BatchNorm19 needs backward computation.
I0702 00:34:49.386216 20914 net.cpp:226] Convolution19 needs backward computation.
I0702 00:34:49.385720 32261 net.cpp:226] BatchNorm1 needs backward computation.
I0702 00:34:49.385725 32261 net.cpp:226] Convolution1 needs backward computation.
I0702 00:34:49.385614  4664 net.cpp:226] Convolution16 needs backward computation.
I0702 00:34:49.386229 20914 net.cpp:226] ReLU16 needs backward computation.
I0702 00:34:49.385733 32261 net.cpp:228] Data2_Data1_1_split does not need backward computation.
I0702 00:34:49.385627  4664 net.cpp:226] Scale15 needs backward computation.
I0702 00:34:49.386238 20914 net.cpp:226] Scale18 needs backward computation.
I0702 00:34:49.385740 32261 net.cpp:228] Data1 does not need backward computation.
I0702 00:34:49.385634  4664 net.cpp:226] BatchNorm15 needs backward computation.
I0702 00:34:49.386245 20914 net.cpp:226] BatchNorm18 needs backward computation.
I0702 00:34:49.385640  4664 net.cpp:226] Convolution15 needs backward computation.
I0702 00:34:49.386250 20914 net.cpp:226] Convolution18 needs backward computation.
I0702 00:34:49.386257 20914 net.cpp:226] Eltwise7_ReLU15_0_split needs backward computation.
I0702 00:34:49.386265 20914 net.cpp:226] ReLU15 needs backward computation.
I0702 00:34:49.386270 20914 net.cpp:226] Eltwise7 needs backward computation.
I0702 00:34:49.386277 20914 net.cpp:226] Scale17 needs backward computation.
I0702 00:34:49.385749 32261 net.cpp:270] This network produces output Accuracy1
I0702 00:34:49.386284 20914 net.cpp:226] BatchNorm17 needs backward computation.
I0702 00:34:49.385757 32261 net.cpp:270] This network produces output SoftmaxWithLoss1
I0702 00:34:49.385648  4664 net.cpp:226] Eltwise6_ReLU13_0_split needs backward computation.
I0702 00:34:49.386291 20914 net.cpp:226] Convolution17 needs backward computation.
I0702 00:34:49.385838 32261 net.cpp:283] Network initialization done.
I0702 00:34:49.385685  4664 net.cpp:226] ReLU13 needs backward computation.
I0702 00:34:49.386297 20914 net.cpp:226] ReLU14 needs backward computation.
I0702 00:34:49.386303 20914 net.cpp:226] Scale16 needs backward computation.
I0702 00:34:49.385694  4664 net.cpp:226] Eltwise6 needs backward computation.
I0702 00:34:49.386310 20914 net.cpp:226] BatchNorm16 needs backward computation.
I0702 00:34:49.385972 32261 solver.cpp:204] Test network set
I0702 00:34:49.385705  4664 net.cpp:226] Scale14 needs backward computation.
I0702 00:34:49.386317 20914 net.cpp:226] Convolution16 needs backward computation.
I0702 00:34:49.386322 20914 net.cpp:226] Scale15 needs backward computation.
I0702 00:34:49.385725  4664 net.cpp:226] BatchNorm14 needs backward computation.
I0702 00:34:49.386328 20914 net.cpp:226] BatchNorm15 needs backward computation.
I0702 00:34:49.386334 20914 net.cpp:226] Convolution15 needs backward computation.
I0702 00:34:49.385733  4664 net.cpp:226] Convolution14 needs backward computation.
I0702 00:34:49.386342 20914 net.cpp:226] Eltwise6_ReLU13_0_split needs backward computation.
I0702 00:34:49.385740  4664 net.cpp:226] ReLU12 needs backward computation.
I0702 00:34:49.386358 20914 net.cpp:226] ReLU13 needs backward computation.
I0702 00:34:49.386035 32261 solver.cpp:79] Solver scaffolding done.
I0702 00:34:49.385747  4664 net.cpp:226] Scale13 needs backward computation.
I0702 00:34:49.386366 20914 net.cpp:226] Eltwise6 needs backward computation.
I0702 00:34:49.385756  4664 net.cpp:226] BatchNorm13 needs backward computation.
I0702 00:34:49.386765 13010 net.cpp:150] Setting up Accuracy1
I0702 00:34:49.386373 20914 net.cpp:226] Scale14 needs backward computation.
I0702 00:34:49.386379 20914 net.cpp:226] BatchNorm14 needs backward computation.
I0702 00:34:49.386385 20914 net.cpp:226] Convolution14 needs backward computation.
I0702 00:34:49.385764  4664 net.cpp:226] Convolution13 needs backward computation.
I0702 00:34:49.386392 20914 net.cpp:226] ReLU12 needs backward computation.
I0702 00:34:49.385771  4664 net.cpp:226] Eltwise5_ReLU11_0_split needs backward computation.
I0702 00:34:49.385777  4664 net.cpp:226] ReLU11 needs backward computation.
I0702 00:34:49.386399 20914 net.cpp:226] Scale13 needs backward computation.
I0702 00:34:49.386404 20914 net.cpp:226] BatchNorm13 needs backward computation.
I0702 00:34:49.386410 20914 net.cpp:226] Convolution13 needs backward computation.
I0702 00:34:49.386416 20914 net.cpp:226] Eltwise5_ReLU11_0_split needs backward computation.
I0702 00:34:49.386790 13010 net.cpp:157] Top shape: (1)
I0702 00:34:49.386423 20914 net.cpp:226] ReLU11 needs backward computation.
I0702 00:34:49.386430 20914 net.cpp:226] Eltwise5 needs backward computation.
I0702 00:34:49.386801 13010 net.cpp:165] Memory required for data: 4305292
I0702 00:34:49.386436 20914 net.cpp:226] Scale12 needs backward computation.
I0702 00:34:49.386442 20914 net.cpp:226] BatchNorm12 needs backward computation.
I0702 00:34:49.386809 13010 net.cpp:228] Accuracy1 does not need backward computation.
I0702 00:34:49.386448 20914 net.cpp:226] Convolution12 needs backward computation.
I0702 00:34:49.386456 20914 net.cpp:226] ReLU10 needs backward computation.
I0702 00:34:49.385783  4664 net.cpp:226] Eltwise5 needs backward computation.
I0702 00:34:49.386461 20914 net.cpp:226] Scale11 needs backward computation.
I0702 00:34:49.385828  4664 net.cpp:226] Scale12 needs backward computation.
I0702 00:34:49.386817 13010 net.cpp:226] SoftmaxWithLoss1 needs backward computation.
I0702 00:34:49.386467 20914 net.cpp:226] BatchNorm11 needs backward computation.
I0702 00:34:49.386473 20914 net.cpp:226] Convolution11 needs backward computation.
I0702 00:34:49.386479 20914 net.cpp:226] Eltwise4_ReLU9_0_split needs backward computation.
I0702 00:34:49.386487 20914 net.cpp:226] ReLU9 needs backward computation.
I0702 00:34:49.385835  4664 net.cpp:226] BatchNorm12 needs backward computation.
I0702 00:34:49.386824 13010 net.cpp:226] InnerProduct1_InnerProduct1_0_split needs backward computation.
I0702 00:34:49.386492 20914 net.cpp:226] Eltwise4 needs backward computation.
I0702 00:34:49.386499 20914 net.cpp:226] Scale10 needs backward computation.
I0702 00:34:49.386507 20914 net.cpp:226] BatchNorm10 needs backward computation.
I0702 00:34:49.385843  4664 net.cpp:226] Convolution12 needs backward computation.
I0702 00:34:49.386832 13010 net.cpp:226] InnerProduct1 needs backward computation.
I0702 00:34:49.386839 13010 net.cpp:226] Pooling1 needs backward computation.
I0702 00:34:49.386512 20914 net.cpp:226] Convolution10 needs backward computation.
I0702 00:34:49.386518 20914 net.cpp:226] ReLU8 needs backward computation.
I0702 00:34:49.385849  4664 net.cpp:226] ReLU10 needs backward computation.
I0702 00:34:49.386845 13010 net.cpp:226] ReLU19 needs backward computation.
I0702 00:34:49.386525 20914 net.cpp:226] Scale9 needs backward computation.
I0702 00:34:49.386531 20914 net.cpp:226] BatchNorm9 needs backward computation.
I0702 00:34:49.386538 20914 net.cpp:226] Convolution9 needs backward computation.
I0702 00:34:49.385855  4664 net.cpp:226] Scale11 needs backward computation.
I0702 00:34:49.386852 13010 net.cpp:226] Eltwise9 needs backward computation.
I0702 00:34:49.386543 20914 net.cpp:226] Scale8 needs backward computation.
I0702 00:34:49.385862  4664 net.cpp:226] BatchNorm11 needs backward computation.
I0702 00:34:49.385869  4664 net.cpp:226] Convolution11 needs backward computation.
I0702 00:34:49.386859 13010 net.cpp:226] Scale21 needs backward computation.
I0702 00:34:49.386549 20914 net.cpp:226] BatchNorm8 needs backward computation.
I0702 00:34:49.386555 20914 net.cpp:226] Convolution8 needs backward computation.
I0702 00:34:49.385875  4664 net.cpp:226] Eltwise4_ReLU9_0_split needs backward computation.
I0702 00:34:49.386865 13010 net.cpp:226] BatchNorm21 needs backward computation.
I0702 00:34:49.386562 20914 net.cpp:226] Eltwise3_ReLU7_0_split needs backward computation.
I0702 00:34:49.385881  4664 net.cpp:226] ReLU9 needs backward computation.
I0702 00:34:49.386569 20914 net.cpp:226] ReLU7 needs backward computation.
I0702 00:34:49.385888  4664 net.cpp:226] Eltwise4 needs backward computation.
I0702 00:34:49.386575 20914 net.cpp:226] Eltwise3 needs backward computation.
I0702 00:34:49.386581 20914 net.cpp:226] Scale7 needs backward computation.
I0702 00:34:49.385901  4664 net.cpp:226] Scale10 needs backward computation.
I0702 00:34:49.386587 20914 net.cpp:226] BatchNorm7 needs backward computation.
I0702 00:34:49.385908  4664 net.cpp:226] BatchNorm10 needs backward computation.
I0702 00:34:49.386871 13010 net.cpp:226] Convolution21 needs backward computation.
I0702 00:34:49.386878 13010 net.cpp:226] ReLU18 needs backward computation.
I0702 00:34:49.386593 20914 net.cpp:226] Convolution7 needs backward computation.
I0702 00:34:49.386600 20914 net.cpp:226] ReLU6 needs backward computation.
I0702 00:34:49.385915  4664 net.cpp:226] Convolution10 needs backward computation.
I0702 00:34:49.386884 13010 net.cpp:226] Scale20 needs backward computation.
I0702 00:34:49.386606 20914 net.cpp:226] Scale6 needs backward computation.
I0702 00:34:49.385922  4664 net.cpp:226] ReLU8 needs backward computation.
I0702 00:34:49.386890 13010 net.cpp:226] BatchNorm20 needs backward computation.
I0702 00:34:49.386612 20914 net.cpp:226] BatchNorm6 needs backward computation.
I0702 00:34:49.386618 20914 net.cpp:226] Convolution6 needs backward computation.
I0702 00:34:49.386896 13010 net.cpp:226] Convolution20 needs backward computation.
I0702 00:34:49.386624 20914 net.cpp:226] Eltwise2_ReLU5_0_split needs backward computation.
I0702 00:34:49.386904 13010 net.cpp:226] Eltwise8_ReLU17_0_split needs backward computation.
I0702 00:34:49.386631 20914 net.cpp:226] ReLU5 needs backward computation.
I0702 00:34:49.385928  4664 net.cpp:226] Scale9 needs backward computation.
I0702 00:34:49.386910 13010 net.cpp:226] ReLU17 needs backward computation.
I0702 00:34:49.386916 13010 net.cpp:226] Eltwise8 needs backward computation.
I0702 00:34:49.386637 20914 net.cpp:226] Eltwise2 needs backward computation.
I0702 00:34:49.386643 20914 net.cpp:226] Scale5 needs backward computation.
I0702 00:34:49.386649 20914 net.cpp:226] BatchNorm5 needs backward computation.
I0702 00:34:49.385954  4664 net.cpp:226] BatchNorm9 needs backward computation.
I0702 00:34:49.386924 13010 net.cpp:226] Scale19 needs backward computation.
I0702 00:34:49.386656 20914 net.cpp:226] Convolution5 needs backward computation.
I0702 00:34:49.386662 20914 net.cpp:226] ReLU4 needs backward computation.
I0702 00:34:49.385987  4664 net.cpp:226] Convolution9 needs backward computation.
I0702 00:34:49.386929 13010 net.cpp:226] BatchNorm19 needs backward computation.
I0702 00:34:49.386668 20914 net.cpp:226] Scale4 needs backward computation.
I0702 00:34:49.385995  4664 net.cpp:226] Scale8 needs backward computation.
I0702 00:34:49.386935 13010 net.cpp:226] Convolution19 needs backward computation.
I0702 00:34:49.386674 20914 net.cpp:226] BatchNorm4 needs backward computation.
I0702 00:34:49.386003  4664 net.cpp:226] BatchNorm8 needs backward computation.
I0702 00:34:49.386942 13010 net.cpp:226] ReLU16 needs backward computation.
I0702 00:34:49.386685 20914 net.cpp:226] Convolution4 needs backward computation.
I0702 00:34:49.386008  4664 net.cpp:226] Convolution8 needs backward computation.
I0702 00:34:49.386948 13010 net.cpp:226] Scale18 needs backward computation.
I0702 00:34:49.386693 20914 net.cpp:226] Eltwise1_ReLU3_0_split needs backward computation.
I0702 00:34:49.386699 20914 net.cpp:226] ReLU3 needs backward computation.
I0702 00:34:49.386015  4664 net.cpp:226] Eltwise3_ReLU7_0_split needs backward computation.
I0702 00:34:49.386955 13010 net.cpp:226] BatchNorm18 needs backward computation.
I0702 00:34:49.386960 13010 net.cpp:226] Convolution18 needs backward computation.
I0702 00:34:49.386706 20914 net.cpp:226] Eltwise1 needs backward computation.
I0702 00:34:49.386713 20914 net.cpp:226] Scale3 needs backward computation.
I0702 00:34:49.386021  4664 net.cpp:226] ReLU7 needs backward computation.
I0702 00:34:49.386029  4664 net.cpp:226] Eltwise3 needs backward computation.
I0702 00:34:49.386967 13010 net.cpp:226] Eltwise7_ReLU15_0_split needs backward computation.
I0702 00:34:49.386719 20914 net.cpp:226] BatchNorm3 needs backward computation.
I0702 00:34:49.386035  4664 net.cpp:226] Scale7 needs backward computation.
I0702 00:34:49.386973 13010 net.cpp:226] ReLU15 needs backward computation.
I0702 00:34:49.386725 20914 net.cpp:226] Convolution3 needs backward computation.
I0702 00:34:49.386732 20914 net.cpp:226] ReLU2 needs backward computation.
I0702 00:34:49.386042  4664 net.cpp:226] BatchNorm7 needs backward computation.
I0702 00:34:49.386979 13010 net.cpp:226] Eltwise7 needs backward computation.
I0702 00:34:49.386739 20914 net.cpp:226] Scale2 needs backward computation.
I0702 00:34:49.386049  4664 net.cpp:226] Convolution7 needs backward computation.
I0702 00:34:49.386744 20914 net.cpp:226] BatchNorm2 needs backward computation.
I0702 00:34:49.386054  4664 net.cpp:226] ReLU6 needs backward computation.
I0702 00:34:49.386750 20914 net.cpp:226] Convolution2 needs backward computation.
I0702 00:34:49.386065  4664 net.cpp:226] Scale6 needs backward computation.
I0702 00:34:49.386986 13010 net.cpp:226] Scale17 needs backward computation.
I0702 00:34:49.386757 20914 net.cpp:226] Convolution1_ReLU1_0_split needs backward computation.
I0702 00:34:49.386765 20914 net.cpp:226] ReLU1 needs backward computation.
I0702 00:34:49.386088  4664 net.cpp:226] BatchNorm6 needs backward computation.
I0702 00:34:49.386993 13010 net.cpp:226] BatchNorm17 needs backward computation.
I0702 00:34:49.386770 20914 net.cpp:226] Scale1 needs backward computation.
I0702 00:34:49.386096  4664 net.cpp:226] Convolution6 needs backward computation.
I0702 00:34:49.386999 13010 net.cpp:226] Convolution17 needs backward computation.
I0702 00:34:49.387006 13010 net.cpp:226] ReLU14 needs backward computation.
I0702 00:34:49.386776 20914 net.cpp:226] BatchNorm1 needs backward computation.
I0702 00:34:49.386103  4664 net.cpp:226] Eltwise2_ReLU5_0_split needs backward computation.
I0702 00:34:49.387012 13010 net.cpp:226] Scale16 needs backward computation.
I0702 00:34:49.386782 20914 net.cpp:226] Convolution1 needs backward computation.
I0702 00:34:49.386111  4664 net.cpp:226] ReLU5 needs backward computation.
I0702 00:34:49.387018 13010 net.cpp:226] BatchNorm16 needs backward computation.
I0702 00:34:49.386790 20914 net.cpp:228] Data2_Data1_1_split does not need backward computation.
I0702 00:34:49.386116  4664 net.cpp:226] Eltwise2 needs backward computation.
I0702 00:34:49.387024 13010 net.cpp:226] Convolution16 needs backward computation.
I0702 00:34:49.386797 20914 net.cpp:228] Data1 does not need backward computation.
I0702 00:34:49.386803 20914 net.cpp:270] This network produces output Accuracy1
I0702 00:34:49.386123  4664 net.cpp:226] Scale5 needs backward computation.
I0702 00:34:49.386131  4664 net.cpp:226] BatchNorm5 needs backward computation.
I0702 00:34:49.387030 13010 net.cpp:226] Scale15 needs backward computation.
I0702 00:34:49.387037 13010 net.cpp:226] BatchNorm15 needs backward computation.
I0702 00:34:49.386811 20914 net.cpp:270] This network produces output SoftmaxWithLoss1
I0702 00:34:49.386137  4664 net.cpp:226] Convolution5 needs backward computation.
I0702 00:34:49.387043 13010 net.cpp:226] Convolution15 needs backward computation.
I0702 00:34:49.386889 20914 net.cpp:283] Network initialization done.
I0702 00:34:49.386143  4664 net.cpp:226] ReLU4 needs backward computation.
I0702 00:34:49.387049 13010 net.cpp:226] Eltwise6_ReLU13_0_split needs backward computation.
I0702 00:34:49.387068 13010 net.cpp:226] ReLU13 needs backward computation.
I0702 00:34:49.387075 13010 net.cpp:226] Eltwise6 needs backward computation.
I0702 00:34:49.387082 13010 net.cpp:226] Scale14 needs backward computation.
I0702 00:34:49.387089 13010 net.cpp:226] BatchNorm14 needs backward computation.
I0702 00:34:49.386593 32261 caffe.cpp:219] Starting Optimization
I0702 00:34:49.386149  4664 net.cpp:226] Scale4 needs backward computation.
I0702 00:34:49.387095 13010 net.cpp:226] Convolution14 needs backward computation.
I0702 00:34:49.386155  4664 net.cpp:226] BatchNorm4 needs backward computation.
I0702 00:34:49.387101 13010 net.cpp:226] ReLU12 needs backward computation.
I0702 00:34:49.386191  4664 net.cpp:226] Convolution4 needs backward computation.
I0702 00:34:49.387109 13010 net.cpp:226] Scale13 needs backward computation.
I0702 00:34:49.387115 13010 net.cpp:226] BatchNorm13 needs backward computation.
I0702 00:34:49.386200  4664 net.cpp:226] Eltwise1_ReLU3_0_split needs backward computation.
I0702 00:34:49.387120 13010 net.cpp:226] Convolution13 needs backward computation.
I0702 00:34:49.386207  4664 net.cpp:226] ReLU3 needs backward computation.
I0702 00:34:49.387127 13010 net.cpp:226] Eltwise5_ReLU11_0_split needs backward computation.
I0702 00:34:49.386611 32261 solver.cpp:461] Solving resnet_cifar10
I0702 00:34:49.386618 32261 solver.cpp:462] Learning Rate Policy: multistep
I0702 00:34:49.386214  4664 net.cpp:226] Eltwise1 needs backward computation.
I0702 00:34:49.387142 13010 net.cpp:226] ReLU11 needs backward computation.
I0702 00:34:49.386220  4664 net.cpp:226] Scale3 needs backward computation.
I0702 00:34:49.387153 13010 net.cpp:226] Eltwise5 needs backward computation.
I0702 00:34:49.386232  4664 net.cpp:226] BatchNorm3 needs backward computation.
I0702 00:34:49.387161 13010 net.cpp:226] Scale12 needs backward computation.
I0702 00:34:49.386240  4664 net.cpp:226] Convolution3 needs backward computation.
I0702 00:34:49.387166 13010 net.cpp:226] BatchNorm12 needs backward computation.
I0702 00:34:49.386260  4664 net.cpp:226] ReLU2 needs backward computation.
I0702 00:34:49.386267  4664 net.cpp:226] Scale2 needs backward computation.
I0702 00:34:49.386274  4664 net.cpp:226] BatchNorm2 needs backward computation.
I0702 00:34:49.386281  4664 net.cpp:226] Convolution2 needs backward computation.
I0702 00:34:49.386287  4664 net.cpp:226] Convolution1_ReLU1_0_split needs backward computation.
I0702 00:34:49.386294  4664 net.cpp:226] ReLU1 needs backward computation.
I0702 00:34:49.386301  4664 net.cpp:226] Scale1 needs backward computation.
I0702 00:34:49.387173 13010 net.cpp:226] Convolution12 needs backward computation.
I0702 00:34:49.386307  4664 net.cpp:226] BatchNorm1 needs backward computation.
I0702 00:34:49.387179 13010 net.cpp:226] ReLU10 needs backward computation.
I0702 00:34:49.386313  4664 net.cpp:226] Convolution1 needs backward computation.
I0702 00:34:49.387185 13010 net.cpp:226] Scale11 needs backward computation.
I0702 00:34:49.387192 13010 net.cpp:226] BatchNorm11 needs backward computation.
I0702 00:34:49.386320  4664 net.cpp:228] Data2_Data1_1_split does not need backward computation.
I0702 00:34:49.387197 13010 net.cpp:226] Convolution11 needs backward computation.
I0702 00:34:49.387070 20914 solver.cpp:204] Test network set
I0702 00:34:49.386332  4664 net.cpp:228] Data1 does not need backward computation.
I0702 00:34:49.387204 13010 net.cpp:226] Eltwise4_ReLU9_0_split needs backward computation.
I0702 00:34:49.386353  4664 net.cpp:270] This network produces output Accuracy1
I0702 00:34:49.387210 13010 net.cpp:226] ReLU9 needs backward computation.
I0702 00:34:49.386360  4664 net.cpp:270] This network produces output SoftmaxWithLoss1
I0702 00:34:49.387217 13010 net.cpp:226] Eltwise4 needs backward computation.
I0702 00:34:49.387224 13010 net.cpp:226] Scale10 needs backward computation.
I0702 00:34:49.387230 13010 net.cpp:226] BatchNorm10 needs backward computation.
I0702 00:34:49.387236 13010 net.cpp:226] Convolution10 needs backward computation.
I0702 00:34:49.387243 13010 net.cpp:226] ReLU8 needs backward computation.
I0702 00:34:49.387249 13010 net.cpp:226] Scale9 needs backward computation.
I0702 00:34:49.387255 13010 net.cpp:226] BatchNorm9 needs backward computation.
I0702 00:34:49.387261 13010 net.cpp:226] Convolution9 needs backward computation.
I0702 00:34:49.386464  4664 net.cpp:283] Network initialization done.
I0702 00:34:49.387269 13010 net.cpp:226] Scale8 needs backward computation.
I0702 00:34:49.387274 13010 net.cpp:226] BatchNorm8 needs backward computation.
I0702 00:34:49.387152 20914 solver.cpp:79] Solver scaffolding done.
I0702 00:34:49.387280 13010 net.cpp:226] Convolution8 needs backward computation.
I0702 00:34:49.387287 13010 net.cpp:226] Eltwise3_ReLU7_0_split needs backward computation.
I0702 00:34:49.387295 13010 net.cpp:226] ReLU7 needs backward computation.
I0702 00:34:49.387300 13010 net.cpp:226] Eltwise3 needs backward computation.
I0702 00:34:49.387307 13010 net.cpp:226] Scale7 needs backward computation.
I0702 00:34:49.387313 13010 net.cpp:226] BatchNorm7 needs backward computation.
I0702 00:34:49.387320 13010 net.cpp:226] Convolution7 needs backward computation.
I0702 00:34:49.387326 13010 net.cpp:226] ReLU6 needs backward computation.
I0702 00:34:49.387332 13010 net.cpp:226] Scale6 needs backward computation.
I0702 00:34:49.386673  4664 solver.cpp:204] Test network set
I0702 00:34:49.387338 13010 net.cpp:226] BatchNorm6 needs backward computation.
I0702 00:34:49.387344 13010 net.cpp:226] Convolution6 needs backward computation.
I0702 00:34:49.387351 13010 net.cpp:226] Eltwise2_ReLU5_0_split needs backward computation.
I0702 00:34:49.387357 13010 net.cpp:226] ReLU5 needs backward computation.
I0702 00:34:49.387363 13010 net.cpp:226] Eltwise2 needs backward computation.
I0702 00:34:49.387370 13010 net.cpp:226] Scale5 needs backward computation.
I0702 00:34:49.387377 13010 net.cpp:226] BatchNorm5 needs backward computation.
I0702 00:34:49.387383 13010 net.cpp:226] Convolution5 needs backward computation.
I0702 00:34:49.387389 13010 net.cpp:226] ReLU4 needs backward computation.
I0702 00:34:49.387395 13010 net.cpp:226] Scale4 needs backward computation.
I0702 00:34:49.387413 13010 net.cpp:226] BatchNorm4 needs backward computation.
I0702 00:34:49.387426 13010 net.cpp:226] Convolution4 needs backward computation.
I0702 00:34:49.387434 13010 net.cpp:226] Eltwise1_ReLU3_0_split needs backward computation.
I0702 00:34:49.387440 13010 net.cpp:226] ReLU3 needs backward computation.
I0702 00:34:49.387447 13010 net.cpp:226] Eltwise1 needs backward computation.
I0702 00:34:49.387454 13010 net.cpp:226] Scale3 needs backward computation.
I0702 00:34:49.387460 13010 net.cpp:226] BatchNorm3 needs backward computation.
I0702 00:34:49.387466 13010 net.cpp:226] Convolution3 needs backward computation.
I0702 00:34:49.387473 13010 net.cpp:226] ReLU2 needs backward computation.
I0702 00:34:49.386776  4664 solver.cpp:79] Solver scaffolding done.
I0702 00:34:49.387480 13010 net.cpp:226] Scale2 needs backward computation.
I0702 00:34:49.387485 13010 net.cpp:226] BatchNorm2 needs backward computation.
I0702 00:34:49.387491 13010 net.cpp:226] Convolution2 needs backward computation.
I0702 00:34:49.387498 13010 net.cpp:226] Convolution1_ReLU1_0_split needs backward computation.
I0702 00:34:49.387506 13010 net.cpp:226] ReLU1 needs backward computation.
I0702 00:34:49.387511 13010 net.cpp:226] Scale1 needs backward computation.
I0702 00:34:49.387517 13010 net.cpp:226] BatchNorm1 needs backward computation.
I0702 00:34:49.387523 13010 net.cpp:226] Convolution1 needs backward computation.
I0702 00:34:49.387531 13010 net.cpp:228] Data2_Data1_1_split does not need backward computation.
I0702 00:34:49.387538 13010 net.cpp:228] Data1 does not need backward computation.
I0702 00:34:49.387544 13010 net.cpp:270] This network produces output Accuracy1
I0702 00:34:49.387552 13010 net.cpp:270] This network produces output SoftmaxWithLoss1
I0702 00:34:49.387626 13010 net.cpp:283] Network initialization done.
I0702 00:34:49.387801 13010 solver.cpp:204] Test network set
I0702 00:34:49.387881 13010 solver.cpp:79] Solver scaffolding done.
I0702 00:34:49.387524 20914 caffe.cpp:219] Starting Optimization
I0702 00:34:49.387542 20914 solver.cpp:461] Solving resnet_cifar10
I0702 00:34:49.387549 20914 solver.cpp:462] Learning Rate Policy: multistep
I0702 00:34:49.387537 32261 solver.cpp:297] Ready to sync parameter numbers of parameter 274848 numbers of parameter blob 149
I0702 00:34:49.388233 13010 caffe.cpp:219] Starting Optimization
I0702 00:34:49.388250 13010 solver.cpp:461] Solving resnet_cifar10
I0702 00:34:49.388257 13010 solver.cpp:462] Learning Rate Policy: multistep
I0702 00:34:49.387365  4664 caffe.cpp:219] Starting Optimization
I0702 00:34:49.387382  4664 solver.cpp:461] Solving resnet_cifar10
I0702 00:34:49.387389  4664 solver.cpp:462] Learning Rate Policy: multistep
I0702 00:34:49.388468 20914 solver.cpp:297] Ready to sync parameter numbers of parameter 274848 numbers of parameter blob 149
I0702 00:34:49.389189 13010 solver.cpp:297] Ready to sync parameter numbers of parameter 274848 numbers of parameter blob 149
I0702 00:34:49.388296  4664 solver.cpp:297] Ready to sync parameter numbers of parameter 274848 numbers of parameter blob 149
I0702 00:34:49.390139 32261 solver.cpp:224] parameter sync set
I0702 00:34:49.389937  4664 solver.cpp:224] parameter sync set
I0702 00:34:49.390836 13010 solver.cpp:224] parameter sync set
I0702 00:34:49.390455 20914 solver.cpp:224] parameter sync set
I0702 00:34:49.391640 13010 solver.cpp:516] Iteration 0, Testing net (#0)
I0702 00:34:49.391360 20914 solver.cpp:516] Iteration 0, Testing net (#0)
I0702 00:34:49.391093 32261 solver.cpp:516] Iteration 0, Testing net (#0)
I0702 00:34:49.391872 13010 blocking_queue.cpp:50] Data layer prefetch queue empty
I0702 00:34:49.390961  4664 solver.cpp:516] Iteration 0, Testing net (#0)
I0702 00:34:49.990181  4664 blocking_queue.cpp:50] Data layer prefetch queue empty
I0702 00:34:50.032977 20914 blocking_queue.cpp:50] Data layer prefetch queue empty
I0702 00:34:50.067838 32261 blocking_queue.cpp:50] Data layer prefetch queue empty
I0702 00:34:51.184990 20914 solver.cpp:592]     Test net output local #0: Accuracy1 = 0.09
I0702 00:34:51.411510  4664 solver.cpp:592]     Test net output local #0: Accuracy1 = 0.13
I0702 00:34:51.411625  4664 solver.cpp:592]     Test net output local #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0702 00:34:51.413405 32261 solver.cpp:592]     Test net output local #0: Accuracy1 = 0.11
I0702 00:34:51.909306 13010 solver.cpp:592]     Test net output local #0: Accuracy1 = 0.07
I0702 00:34:51.909452 13010 solver.cpp:592]     Test net output local #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0702 00:34:51.909095 20914 solver.cpp:600]     Test net output all #0: Accuracy1 = 0.1
I0702 00:34:51.909134 20914 solver.cpp:592]     Test net output local #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0702 00:34:51.908772 32261 solver.cpp:592]     Test net output local #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0702 00:34:51.909163 20914 solver.cpp:600]     Test net output all #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I0702 00:34:52.162675 32261 solver.cpp:417] 0  display time 0 ms.
I0702 00:34:52.163018 20914 solver.cpp:417] 0  display time 0 ms.
I0702 00:34:52.162729 32261 solver.cpp:442] iteraion 0 cost 2772 ms totallycertain part cost3
I0702 00:34:52.163498 13010 solver.cpp:417] 0  display time 0 ms.
I0702 00:34:52.163622 13010 solver.cpp:442] iteraion 0 cost 2772 ms totallycertain part cost8
W0702 00:34:52.163033 20957 benchmark.cpp:84] Timer has never been run before reading time.
I0702 00:34:52.162698  4664 solver.cpp:417] 0  display time 0 ms.
I0702 00:34:52.163352 20957 solver.cpp:235]  rank = 0 Iteration 1 (1 iter/s, 0s/100 iters), loss = 2.96042
I0702 00:34:52.162748  4664 solver.cpp:442] iteraion 0 cost 2772 ms totallycertain part cost470
I0702 00:34:52.163424 20957 solver.cpp:255]     Train net output #0: SoftmaxWithLoss1 = 2.96042 (* 1 = 2.96042 loss)
I0702 00:34:52.163167 20914 solver.cpp:442] iteraion 0 cost 2772 ms totallycertain part cost1
W0702 00:34:52.169205  4695 benchmark.cpp:84] Timer has never been run before reading time.
I0702 00:34:52.169323  4695 solver.cpp:235]  rank = 1 Iteration 1 (1 iter/s, 0s/100 iters), loss = 3.69156
I0702 00:34:52.169350  4695 solver.cpp:255]     Train net output #0: SoftmaxWithLoss1 = 3.69156 (* 1 = 3.69156 loss)
W0702 00:34:52.169734 32292 benchmark.cpp:84] Timer has never been run before reading time.
I0702 00:34:52.169885 32292 solver.cpp:235]  rank = 2 Iteration 1 (1 iter/s, 0s/100 iters), loss = 3.22166
I0702 00:34:52.169914 32292 solver.cpp:255]     Train net output #0: SoftmaxWithLoss1 = 3.22166 (* 1 = 3.22166 loss)
W0702 00:34:52.171298 13041 benchmark.cpp:84] Timer has never been run before reading time.
I0702 00:34:52.171484 13041 solver.cpp:235]  rank = 3 Iteration 1 (1 iter/s, 0s/100 iters), loss = 3.14093
I0702 00:34:52.171548 13041 solver.cpp:255]     Train net output #0: SoftmaxWithLoss1 = 3.14093 (* 1 = 3.14093 loss)
I0702 00:34:52.286527 20914 solver.cpp:442] iteraion 1 cost 122 ms totallycertain part cost1
I0702 00:34:52.405057 20914 solver.cpp:442] iteraion 2 cost 118 ms totallycertain part cost1
I0702 00:34:52.525882 20914 solver.cpp:442] iteraion 3 cost 120 ms totallycertain part cost1
I0702 00:34:53.473282 20914 solver.cpp:442] iteraion 4 cost 947 ms totallycertain part cost579
I0702 00:34:53.976646 20914 solver.cpp:442] iteraion 5 cost 503 ms totallycertain part cost391
I0702 00:34:54.608295 20914 solver.cpp:442] iteraion 6 cost 631 ms totallycertain part cost518
I0702 00:34:55.112612 20914 solver.cpp:442] iteraion 7 cost 504 ms totallycertain part cost392
I0702 00:34:55.706782 20914 solver.cpp:442] iteraion 8 cost 594 ms totallycertain part cost481
I0702 00:34:56.217722 20914 solver.cpp:442] iteraion 9 cost 510 ms totallycertain part cost400
I0702 00:34:57.693338 20914 solver.cpp:442] iteraion 10 cost 1475 ms totallycertain part cost1152
I0702 00:34:58.404518 20914 solver.cpp:442] iteraion 11 cost 711 ms totallycertain part cost598
I0702 00:34:59.453881 20914 solver.cpp:442] iteraion 12 cost 1049 ms totallycertain part cost937
I0702 00:35:00.792546 20914 solver.cpp:442] iteraion 13 cost 1338 ms totallycertain part cost1225
I0702 00:35:01.383798 20914 solver.cpp:442] iteraion 14 cost 591 ms totallycertain part cost478
I0702 00:35:01.767822 20914 solver.cpp:442] iteraion 15 cost 383 ms totallycertain part cost271
I0702 00:35:02.227588 20914 solver.cpp:442] iteraion 16 cost 459 ms totallycertain part cost346
I0702 00:35:02.720929 20914 solver.cpp:442] iteraion 17 cost 493 ms totallycertain part cost380
I0702 00:35:03.270571 20914 solver.cpp:442] iteraion 18 cost 549 ms totallycertain part cost431
I0702 00:35:03.740612 20914 solver.cpp:442] iteraion 19 cost 469 ms totallycertain part cost358
I0702 00:35:04.164937 20914 solver.cpp:442] iteraion 20 cost 424 ms totallycertain part cost312
I0702 00:35:06.383108 20914 solver.cpp:442] iteraion 21 cost 2218 ms totallycertain part cost2107
I0702 00:35:06.828003 20914 solver.cpp:442] iteraion 22 cost 444 ms totallycertain part cost328
I0702 00:35:07.445552 20914 solver.cpp:442] iteraion 23 cost 617 ms totallycertain part cost506
I0702 00:35:07.971117 20914 solver.cpp:442] iteraion 24 cost 525 ms totallycertain part cost413
I0702 00:35:08.680495 20914 solver.cpp:442] iteraion 25 cost 709 ms totallycertain part cost599
I0702 00:35:09.778816 20914 solver.cpp:442] iteraion 26 cost 1098 ms totallycertain part cost987
I0702 00:35:10.609822 20914 solver.cpp:442] iteraion 27 cost 830 ms totallycertain part cost719
I0702 00:35:10.943826 20914 solver.cpp:442] iteraion 28 cost 333 ms totallycertain part cost222
I0702 00:35:11.466538 20914 solver.cpp:442] iteraion 29 cost 522 ms totallycertain part cost411
I0702 00:35:11.985404 20914 solver.cpp:442] iteraion 30 cost 518 ms totallycertain part cost406
I0702 00:35:12.369010 20914 solver.cpp:442] iteraion 31 cost 383 ms totallycertain part cost271
I0702 00:35:12.830677 20914 solver.cpp:442] iteraion 32 cost 461 ms totallycertain part cost348
I0702 00:35:13.239794 20914 solver.cpp:442] iteraion 33 cost 408 ms totallycertain part cost295
I0702 00:35:13.623137 20914 solver.cpp:442] iteraion 34 cost 383 ms totallycertain part cost270
I0702 00:35:14.105749 20914 solver.cpp:442] iteraion 35 cost 482 ms totallycertain part cost371
I0702 00:35:14.899780 20914 solver.cpp:442] iteraion 36 cost 793 ms totallycertain part cost680
I0702 00:35:15.385097 20914 solver.cpp:442] iteraion 37 cost 485 ms totallycertain part cost372
I0702 00:35:16.551797 20914 solver.cpp:442] iteraion 38 cost 1166 ms totallycertain part cost1057
I0702 00:35:17.303766 20914 solver.cpp:442] iteraion 39 cost 751 ms totallycertain part cost642
I0702 00:35:17.612570 20914 solver.cpp:442] iteraion 40 cost 308 ms totallycertain part cost200
I0702 00:35:18.297914 20914 solver.cpp:442] iteraion 41 cost 685 ms totallycertain part cost578
I0702 00:35:18.600224 20914 solver.cpp:442] iteraion 42 cost 302 ms totallycertain part cost193
I0702 00:35:18.913586 20914 solver.cpp:442] iteraion 43 cost 313 ms totallycertain part cost205
I0702 00:35:19.251421 20914 solver.cpp:442] iteraion 44 cost 337 ms totallycertain part cost229
I0702 00:35:19.697593 20914 solver.cpp:442] iteraion 45 cost 446 ms totallycertain part cost1
I0702 00:35:20.106371 20914 solver.cpp:442] iteraion 46 cost 408 ms totallycertain part cost1
I0702 00:35:20.572325 20914 solver.cpp:442] iteraion 47 cost 465 ms totallycertain part cost1
I0702 00:35:20.993482 20914 solver.cpp:442] iteraion 48 cost 421 ms totallycertain part cost89
I0702 00:35:21.475836 20914 solver.cpp:442] iteraion 49 cost 482 ms totallycertain part cost221
I0702 00:35:22.147835 20914 solver.cpp:442] iteraion 50 cost 671 ms totallycertain part cost1
I0702 00:35:23.884428 20914 solver.cpp:442] iteraion 51 cost 1736 ms totallycertain part cost1307
I0702 00:35:24.255328 20914 solver.cpp:442] iteraion 52 cost 370 ms totallycertain part cost260
I0702 00:35:24.562949 20914 solver.cpp:442] iteraion 53 cost 307 ms totallycertain part cost197
I0702 00:35:24.942695 20914 solver.cpp:442] iteraion 54 cost 379 ms totallycertain part cost270
I0702 00:35:25.265704 20914 solver.cpp:442] iteraion 55 cost 322 ms totallycertain part cost212
I0702 00:35:25.510412 20914 solver.cpp:442] iteraion 56 cost 244 ms totallycertain part cost136
I0702 00:35:26.358573 20914 solver.cpp:442] iteraion 57 cost 848 ms totallycertain part cost738
I0702 00:35:26.906786 20914 solver.cpp:442] iteraion 58 cost 548 ms totallycertain part cost438
I0702 00:35:27.387346 20914 solver.cpp:442] iteraion 59 cost 480 ms totallycertain part cost371
I0702 00:35:27.716780 20914 solver.cpp:442] iteraion 60 cost 329 ms totallycertain part cost221
I0702 00:35:27.934293 20914 solver.cpp:442] iteraion 61 cost 217 ms totallycertain part cost108
I0702 00:35:28.281131 20914 solver.cpp:442] iteraion 62 cost 346 ms totallycertain part cost236
I0702 00:35:28.875610 20914 solver.cpp:442] iteraion 63 cost 594 ms totallycertain part cost486
I0702 00:35:29.141101 20914 solver.cpp:442] iteraion 64 cost 265 ms totallycertain part cost156
I0702 00:35:29.611523 20914 solver.cpp:442] iteraion 65 cost 470 ms totallycertain part cost361
I0702 00:35:29.960294 20914 solver.cpp:442] iteraion 66 cost 348 ms totallycertain part cost241
I0702 00:35:30.302532 20914 solver.cpp:442] iteraion 67 cost 342 ms totallycertain part cost232
I0702 00:35:30.818148 20914 solver.cpp:442] iteraion 68 cost 515 ms totallycertain part cost405
I0702 00:35:31.156896 20914 solver.cpp:442] iteraion 69 cost 338 ms totallycertain part cost227
I0702 00:35:31.846623 20914 solver.cpp:442] iteraion 70 cost 689 ms totallycertain part cost582
I0702 00:35:32.169785 20914 solver.cpp:442] iteraion 71 cost 323 ms totallycertain part cost213
I0702 00:35:32.426265 20914 solver.cpp:442] iteraion 72 cost 256 ms totallycertain part cost147
I0702 00:35:32.804832 20914 solver.cpp:442] iteraion 73 cost 378 ms totallycertain part cost269
I0702 00:35:33.229950 20914 solver.cpp:442] iteraion 74 cost 424 ms totallycertain part cost314
I0702 00:35:33.451328 20914 solver.cpp:442] iteraion 75 cost 221 ms totallycertain part cost112
I0702 00:35:33.700508 20914 solver.cpp:442] iteraion 76 cost 249 ms totallycertain part cost140
I0702 00:35:33.982067 20914 solver.cpp:442] iteraion 77 cost 281 ms totallycertain part cost170
I0702 00:35:34.502969 20914 solver.cpp:442] iteraion 78 cost 520 ms totallycertain part cost411
I0702 00:35:34.797343 20914 solver.cpp:442] iteraion 79 cost 294 ms totallycertain part cost185
I0702 00:35:35.080934 20914 solver.cpp:442] iteraion 80 cost 283 ms totallycertain part cost173
I0702 00:35:35.355090 20914 solver.cpp:442] iteraion 81 cost 274 ms totallycertain part cost165
I0702 00:35:35.793315 20914 solver.cpp:442] iteraion 82 cost 438 ms totallycertain part cost329
I0702 00:35:36.124987 20914 solver.cpp:442] iteraion 83 cost 331 ms totallycertain part cost200
I0702 00:35:36.432034 20914 solver.cpp:442] iteraion 84 cost 306 ms totallycertain part cost192
I0702 00:35:37.111599 20914 solver.cpp:442] iteraion 85 cost 679 ms totallycertain part cost561
I0702 00:35:37.377661 20914 solver.cpp:442] iteraion 86 cost 265 ms totallycertain part cost157
I0702 00:35:37.656677 20914 solver.cpp:442] iteraion 87 cost 278 ms totallycertain part cost169
I0702 00:35:38.084528 20914 solver.cpp:442] iteraion 88 cost 427 ms totallycertain part cost317
I0702 00:35:38.499083 20914 solver.cpp:442] iteraion 89 cost 414 ms totallycertain part cost305
I0702 00:35:38.778234 20914 solver.cpp:442] iteraion 90 cost 279 ms totallycertain part cost164
I0702 00:35:39.104562 20914 solver.cpp:442] iteraion 91 cost 326 ms totallycertain part cost211
I0702 00:35:39.332968 20914 solver.cpp:442] iteraion 92 cost 228 ms totallycertain part cost115
I0702 00:35:39.761225 20914 solver.cpp:442] iteraion 93 cost 428 ms totallycertain part cost1
I0702 00:35:40.151974 20914 solver.cpp:442] iteraion 94 cost 390 ms totallycertain part cost1
I0702 00:35:40.776276 20914 solver.cpp:442] iteraion 95 cost 624 ms totallycertain part cost1
I0702 00:35:41.112608 20914 solver.cpp:442] iteraion 96 cost 336 ms totallycertain part cost1
I0702 00:35:41.358249 20914 solver.cpp:442] iteraion 97 cost 245 ms totallycertain part cost1
I0702 00:35:42.860472 20914 solver.cpp:442] iteraion 98 cost 1502 ms totallycertain part cost1
I0702 00:35:43.248737 20914 solver.cpp:442] iteraion 99 cost 388 ms totallycertain part cost1
I0702 00:35:43.578939 20914 solver.cpp:417] 100  display time 0 ms.
I0702 00:35:43.579078 20914 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0702 00:35:43.580010 20914 solver.cpp:442] iteraion 100 cost 331 ms totallycertain part cost1
I0702 00:35:43.580251 20959 solver.cpp:235]  rank = 0 Iteration 101 (1.94492 iter/s, 51.416s/100 iters), loss = 1.97964
I0702 00:35:43.580315 20959 solver.cpp:255]     Train net output #0: SoftmaxWithLoss1 = 1.97964 (* 1 = 1.97964 loss)
I0702 00:35:43.585621  1446 solver.cpp:235]  rank = 2 Iteration 101 (1.94496 iter/s, 51.415s/100 iters), loss = 2.12013
I0702 00:35:43.586395 14656 solver.cpp:235]  rank = 3 Iteration 101 (1.945 iter/s, 51.414s/100 iters), loss = 1.90582
I0702 00:35:43.585750  1446 solver.cpp:255]     Train net output #0: SoftmaxWithLoss1 = 2.12013 (* 1 = 2.12013 loss)
I0702 00:35:43.585541  4698 solver.cpp:235]  rank = 1 Iteration 101 (1.94492 iter/s, 51.416s/100 iters), loss = 2.1991
I0702 00:35:43.585583  4698 solver.cpp:255]     Train net output #0: SoftmaxWithLoss1 = 2.1991 (* 1 = 2.1991 loss)
I0702 00:35:43.586508 14656 solver.cpp:255]     Train net output #0: SoftmaxWithLoss1 = 1.90582 (* 1 = 1.90582 loss)
I0702 00:35:43.826001 20914 solver.cpp:442] iteraion 101 cost 245 ms totallycertain part cost1
I0702 00:35:44.088923 20914 solver.cpp:442] iteraion 102 cost 262 ms totallycertain part cost1
I0702 00:35:44.420073 20914 solver.cpp:442] iteraion 103 cost 330 ms totallycertain part cost1
I0702 00:35:44.819595 20914 solver.cpp:442] iteraion 104 cost 399 ms totallycertain part cost1
I0702 00:35:45.103310 20914 solver.cpp:442] iteraion 105 cost 283 ms totallycertain part cost1
I0702 00:35:45.281733 20914 solver.cpp:442] iteraion 106 cost 178 ms totallycertain part cost1
I0702 00:35:45.699592 20914 solver.cpp:442] iteraion 107 cost 417 ms totallycertain part cost1
I0702 00:35:45.954831 20914 solver.cpp:442] iteraion 108 cost 255 ms totallycertain part cost1
I0702 00:35:46.152712 20914 solver.cpp:442] iteraion 109 cost 197 ms totallycertain part cost1
I0702 00:35:46.355088 20914 solver.cpp:442] iteraion 110 cost 202 ms totallycertain part cost1
I0702 00:35:46.604032 20914 solver.cpp:442] iteraion 111 cost 248 ms totallycertain part cost1
I0702 00:35:46.793839 20914 solver.cpp:442] iteraion 112 cost 189 ms totallycertain part cost1
I0702 00:35:47.682067 20914 solver.cpp:442] iteraion 113 cost 888 ms totallycertain part cost1
I0702 00:35:47.931124 20914 solver.cpp:442] iteraion 114 cost 248 ms totallycertain part cost1
I0702 00:35:48.124374 20914 solver.cpp:442] iteraion 115 cost 193 ms totallycertain part cost1
I0702 00:35:48.642942 20914 solver.cpp:442] iteraion 116 cost 518 ms totallycertain part cost1
I0702 00:35:48.998718 20914 solver.cpp:442] iteraion 117 cost 355 ms totallycertain part cost1
I0702 00:35:49.218104 20914 solver.cpp:442] iteraion 118 cost 219 ms totallycertain part cost1
I0702 00:35:49.523391 20914 solver.cpp:442] iteraion 119 cost 305 ms totallycertain part cost1
I0702 00:35:49.776007 20914 solver.cpp:442] iteraion 120 cost 252 ms totallycertain part cost13
I0702 00:35:50.065547 20914 solver.cpp:442] iteraion 121 cost 289 ms totallycertain part cost28
I0702 00:35:50.412595 20914 solver.cpp:442] iteraion 122 cost 346 ms totallycertain part cost1
I0702 00:35:50.712775 20914 solver.cpp:442] iteraion 123 cost 299 ms totallycertain part cost1
I0702 00:35:51.003044 20914 solver.cpp:442] iteraion 124 cost 290 ms totallycertain part cost39
I0702 00:35:51.397315 20914 solver.cpp:442] iteraion 125 cost 394 ms totallycertain part cost133
I0702 00:35:51.686094 20914 solver.cpp:442] iteraion 126 cost 288 ms totallycertain part cost178
I0702 00:35:51.921810 20914 solver.cpp:442] iteraion 127 cost 235 ms totallycertain part cost125
I0702 00:35:52.165899 20914 solver.cpp:442] iteraion 128 cost 243 ms totallycertain part cost128
I0702 00:35:52.723428 20914 solver.cpp:442] iteraion 129 cost 557 ms totallycertain part cost1
I0702 00:35:53.066370 20914 solver.cpp:442] iteraion 130 cost 342 ms totallycertain part cost115
I0702 00:35:53.670465 20914 solver.cpp:442] iteraion 131 cost 603 ms totallycertain part cost324
I0702 00:35:53.858497 20914 solver.cpp:442] iteraion 132 cost 187 ms totallycertain part cost70
I0702 00:35:54.356117 20914 solver.cpp:442] iteraion 133 cost 497 ms totallycertain part cost387
I0702 00:35:54.790385 20914 solver.cpp:442] iteraion 134 cost 434 ms totallycertain part cost322
I0702 00:35:55.081284 20914 solver.cpp:442] iteraion 135 cost 290 ms totallycertain part cost180
I0702 00:35:55.351220 20914 solver.cpp:442] iteraion 136 cost 269 ms totallycertain part cost160
I0702 00:35:55.717983 20914 solver.cpp:442] iteraion 137 cost 366 ms totallycertain part cost255
I0702 00:35:55.976461 20914 solver.cpp:442] iteraion 138 cost 258 ms totallycertain part cost146
I0702 00:35:56.485982 20914 solver.cpp:442] iteraion 139 cost 509 ms totallycertain part cost396
I0702 00:35:57.298239 20914 solver.cpp:442] iteraion 140 cost 812 ms totallycertain part cost700
I0702 00:35:57.711508 20914 solver.cpp:442] iteraion 141 cost 413 ms totallycertain part cost304
I0702 00:35:58.607918 20914 solver.cpp:442] iteraion 142 cost 896 ms totallycertain part cost786
I0702 00:35:58.807832 20914 solver.cpp:442] iteraion 143 cost 199 ms totallycertain part cost87
I0702 00:35:58.988173 20914 solver.cpp:442] iteraion 144 cost 180 ms totallycertain part cost70
I0702 00:35:59.207546 20914 solver.cpp:442] iteraion 145 cost 219 ms totallycertain part cost108
I0702 00:35:59.460654 20914 solver.cpp:442] iteraion 146 cost 252 ms totallycertain part cost143
I0702 00:35:59.752427 20914 solver.cpp:442] iteraion 147 cost 291 ms totallycertain part cost180
I0702 00:35:59.988566 20914 solver.cpp:442] iteraion 148 cost 235 ms totallycertain part cost125
I0702 00:36:00.423259 20914 solver.cpp:442] iteraion 149 cost 434 ms totallycertain part cost321
I0702 00:36:00.637763 20914 solver.cpp:442] iteraion 150 cost 214 ms totallycertain part cost102
I0702 00:36:00.806783 20914 solver.cpp:442] iteraion 151 cost 168 ms totallycertain part cost56
I0702 00:36:01.015296 20914 solver.cpp:442] iteraion 152 cost 208 ms totallycertain part cost96
I0702 00:36:01.261469 20914 solver.cpp:442] iteraion 153 cost 246 ms totallycertain part cost134
I0702 00:36:01.463169 20914 solver.cpp:442] iteraion 154 cost 201 ms totallycertain part cost91
I0702 00:36:01.693017 20914 solver.cpp:442] iteraion 155 cost 229 ms totallycertain part cost67
I0702 00:36:02.057404 20914 solver.cpp:442] iteraion 156 cost 364 ms totallycertain part cost163
I0702 00:36:02.365101 20914 solver.cpp:442] iteraion 157 cost 307 ms totallycertain part cost194
I0702 00:36:02.539379 20914 solver.cpp:442] iteraion 158 cost 174 ms totallycertain part cost62
I0702 00:36:02.922574 20914 solver.cpp:442] iteraion 159 cost 383 ms totallycertain part cost271
I0702 00:36:03.142627 20914 solver.cpp:442] iteraion 160 cost 219 ms totallycertain part cost106
I0702 00:36:03.369690 20914 solver.cpp:442] iteraion 161 cost 226 ms totallycertain part cost114
I0702 00:36:03.636493 20914 solver.cpp:442] iteraion 162 cost 266 ms totallycertain part cost153
I0702 00:36:03.839610 20914 solver.cpp:442] iteraion 163 cost 202 ms totallycertain part cost89
I0702 00:36:04.040689 20914 solver.cpp:442] iteraion 164 cost 200 ms totallycertain part cost89
I0702 00:36:04.272795 20914 solver.cpp:442] iteraion 165 cost 231 ms totallycertain part cost120
I0702 00:36:04.564412 20914 solver.cpp:442] iteraion 166 cost 291 ms totallycertain part cost181
I0702 00:36:05.227442 20914 solver.cpp:442] iteraion 167 cost 662 ms totallycertain part cost549
I0702 00:36:05.460294 20914 solver.cpp:442] iteraion 168 cost 232 ms totallycertain part cost119
I0702 00:36:06.090126 20914 solver.cpp:442] iteraion 169 cost 629 ms totallycertain part cost517
I0702 00:36:06.701809 20914 solver.cpp:442] iteraion 170 cost 611 ms totallycertain part cost502
I0702 00:36:06.967981 20914 solver.cpp:442] iteraion 171 cost 266 ms totallycertain part cost157
I0702 00:36:13.403558 20914 solver.cpp:442] iteraion 172 cost 6435 ms totallycertain part cost6327
I0702 00:36:13.635541 20914 solver.cpp:442] iteraion 173 cost 231 ms totallycertain part cost116
I0702 00:36:13.883298 20914 solver.cpp:442] iteraion 174 cost 247 ms totallycertain part cost139
I0702 00:36:15.627377 20914 solver.cpp:442] iteraion 175 cost 1743 ms totallycertain part cost1
I0702 00:36:18.582084 20914 solver.cpp:442] iteraion 176 cost 2954 ms totallycertain part cost1975
I0702 00:36:18.781982 20914 solver.cpp:442] iteraion 177 cost 199 ms totallycertain part cost86
I0702 00:36:19.742174 20914 solver.cpp:442] iteraion 178 cost 960 ms totallycertain part cost851
I0702 00:36:21.121692 20914 solver.cpp:442] iteraion 179 cost 1379 ms totallycertain part cost1269
I0702 00:36:21.927057 20914 solver.cpp:442] iteraion 180 cost 805 ms totallycertain part cost693
I0702 00:36:22.209224 20914 solver.cpp:442] iteraion 181 cost 282 ms totallycertain part cost173
I0702 00:36:24.959033 20914 solver.cpp:442] iteraion 182 cost 2749 ms totallycertain part cost2641
I0702 00:36:25.237990 20914 solver.cpp:442] iteraion 183 cost 278 ms totallycertain part cost164
I0702 00:36:25.405278 20914 solver.cpp:442] iteraion 184 cost 167 ms totallycertain part cost55
I0702 00:36:25.580724 20914 solver.cpp:442] iteraion 185 cost 175 ms totallycertain part cost64
I0702 00:36:25.828619 20914 solver.cpp:442] iteraion 186 cost 247 ms totallycertain part cost135
I0702 00:36:26.215862 20914 solver.cpp:442] iteraion 187 cost 387 ms totallycertain part cost276
I0702 00:36:26.462610 20914 solver.cpp:442] iteraion 188 cost 246 ms totallycertain part cost135
I0702 00:36:26.673554 20914 solver.cpp:442] iteraion 189 cost 210 ms totallycertain part cost98
I0702 00:36:26.982612 20914 solver.cpp:442] iteraion 190 cost 308 ms totallycertain part cost191
I0702 00:36:27.166318 20914 solver.cpp:442] iteraion 191 cost 183 ms totallycertain part cost73
I0702 00:36:27.506269 20914 solver.cpp:442] iteraion 192 cost 339 ms totallycertain part cost229
I0702 00:36:27.715479 20914 solver.cpp:442] iteraion 193 cost 209 ms totallycertain part cost98
I0702 00:36:27.890424 20914 solver.cpp:442] iteraion 194 cost 174 ms totallycertain part cost63
I0702 00:36:28.036285 20914 solver.cpp:442] iteraion 195 cost 145 ms totallycertain part cost33
I0702 00:36:28.318670 20914 solver.cpp:442] iteraion 196 cost 282 ms totallycertain part cost170
I0702 00:36:28.491506 20914 solver.cpp:442] iteraion 197 cost 172 ms totallycertain part cost61
I0702 00:36:28.753947 20914 solver.cpp:442] iteraion 198 cost 262 ms totallycertain part cost150
I0702 00:36:28.967900 20914 solver.cpp:442] iteraion 199 cost 213 ms totallycertain part cost102
I0702 00:36:29.180902 20914 solver.cpp:417] 200  display time 0 ms.
I0702 00:36:29.181036 20914 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0702 00:36:29.181918 20914 solver.cpp:442] iteraion 200 cost 213 ms totallycertain part cost102
I0702 00:36:29.181386  4700 solver.cpp:235]  rank = 1 Iteration 201 (2.19322 iter/s, 45.595s/100 iters), loss = 2.03448
I0702 00:36:29.181502  4700 solver.cpp:255]     Train net output #0: SoftmaxWithLoss1 = 2.03448 (* 1 = 2.03448 loss)
I0702 00:36:29.187839 20960 solver.cpp:235]  rank = 0 Iteration 201 (2.19265 iter/s, 45.607s/100 iters), loss = 1.99498
I0702 00:36:29.187944 20960 solver.cpp:255]     Train net output #0: SoftmaxWithLoss1 = 1.99498 (* 1 = 1.99498 loss)
I0702 00:36:29.189450 14658 solver.cpp:235]  rank = 3 Iteration 201 (2.19289 iter/s, 45.602s/100 iters), loss = 2.11016
I0702 00:36:29.189580 14658 solver.cpp:255]     Train net output #0: SoftmaxWithLoss1 = 2.11016 (* 1 = 2.11016 loss)
I0702 00:36:29.188864  1448 solver.cpp:235]  rank = 2 Iteration 201 (2.19284 iter/s, 45.603s/100 iters), loss = 1.97992
I0702 00:36:29.188920  1448 solver.cpp:255]     Train net output #0: SoftmaxWithLoss1 = 1.97992 (* 1 = 1.97992 loss)
I0702 00:36:29.340495 20914 solver.cpp:442] iteraion 201 cost 158 ms totallycertain part cost49
I0702 00:36:29.599043 20914 solver.cpp:442] iteraion 202 cost 258 ms totallycertain part cost150
I0702 00:36:29.898322 20914 solver.cpp:442] iteraion 203 cost 299 ms totallycertain part cost1
I0702 00:36:30.911806 20914 solver.cpp:442] iteraion 204 cost 1013 ms totallycertain part cost795
I0702 00:36:31.130961 20914 solver.cpp:442] iteraion 205 cost 218 ms totallycertain part cost110
I0702 00:36:31.668982 20914 solver.cpp:442] iteraion 206 cost 537 ms totallycertain part cost1
I0702 00:36:31.965473 20914 solver.cpp:442] iteraion 207 cost 296 ms totallycertain part cost1
I0702 00:36:32.232810 20914 solver.cpp:442] iteraion 208 cost 266 ms totallycertain part cost1
I0702 00:36:32.459283 20914 solver.cpp:442] iteraion 209 cost 226 ms totallycertain part cost1
I0702 00:36:32.658838 20914 solver.cpp:442] iteraion 210 cost 199 ms totallycertain part cost1
I0702 00:36:32.885044 20914 solver.cpp:442] iteraion 211 cost 226 ms totallycertain part cost1
I0702 00:36:33.882465 20914 solver.cpp:442] iteraion 212 cost 997 ms totallycertain part cost1
I0702 00:36:34.661943 20914 solver.cpp:442] iteraion 213 cost 779 ms totallycertain part cost1
I0702 00:36:34.945019 20914 solver.cpp:442] iteraion 214 cost 282 ms totallycertain part cost1
I0702 00:36:35.289047 20914 solver.cpp:442] iteraion 215 cost 343 ms totallycertain part cost57
I0702 00:36:35.996845 20914 solver.cpp:442] iteraion 216 cost 707 ms totallycertain part cost6
I0702 00:36:36.592619 20914 solver.cpp:442] iteraion 217 cost 595 ms totallycertain part cost385
I0702 00:36:36.773094 20914 solver.cpp:442] iteraion 218 cost 180 ms totallycertain part cost1
I0702 00:36:36.933104 20914 solver.cpp:442] iteraion 219 cost 159 ms totallycertain part cost15
I0702 00:36:37.222045 20914 solver.cpp:442] iteraion 220 cost 288 ms totallycertain part cost146
I0702 00:36:37.426800 20914 solver.cpp:442] iteraion 221 cost 204 ms totallycertain part cost68
I0702 00:36:37.673372 20914 solver.cpp:442] iteraion 222 cost 246 ms totallycertain part cost109
I0702 00:36:37.804889 20914 solver.cpp:442] iteraion 223 cost 131 ms totallycertain part cost17
I0702 00:36:38.055174 20914 solver.cpp:442] iteraion 224 cost 250 ms totallycertain part cost137
I0702 00:36:38.605880 20914 solver.cpp:442] iteraion 225 cost 550 ms totallycertain part cost1
I0702 00:36:39.082908 20914 solver.cpp:442] iteraion 226 cost 476 ms totallycertain part cost1
I0702 00:36:39.330288 20914 solver.cpp:442] iteraion 227 cost 247 ms totallycertain part cost1
I0702 00:36:39.559454 20914 solver.cpp:442] iteraion 228 cost 229 ms totallycertain part cost1
I0702 00:36:39.720140 20914 solver.cpp:442] iteraion 229 cost 160 ms totallycertain part cost1
I0702 00:36:39.930541 20914 solver.cpp:442] iteraion 230 cost 210 ms totallycertain part cost1
I0702 00:36:40.149843 20914 solver.cpp:442] iteraion 231 cost 219 ms totallycertain part cost1
I0702 00:36:40.450358 20914 solver.cpp:442] iteraion 232 cost 300 ms totallycertain part cost1
I0702 00:36:40.625597 20914 solver.cpp:442] iteraion 233 cost 175 ms totallycertain part cost1
I0702 00:36:40.889045 20914 solver.cpp:442] iteraion 234 cost 263 ms totallycertain part cost1
I0702 00:36:41.031141 20914 solver.cpp:442] iteraion 235 cost 141 ms totallycertain part cost1
I0702 00:36:41.211062 20914 solver.cpp:442] iteraion 236 cost 179 ms totallycertain part cost1
I0702 00:36:41.376415 20914 solver.cpp:442] iteraion 237 cost 165 ms totallycertain part cost1
I0702 00:36:41.551709 20914 solver.cpp:442] iteraion 238 cost 175 ms totallycertain part cost1
I0702 00:36:41.699409 20914 solver.cpp:442] iteraion 239 cost 147 ms totallycertain part cost1
I0702 00:36:41.920224 20914 solver.cpp:442] iteraion 240 cost 220 ms totallycertain part cost1
I0702 00:36:42.138110 20914 solver.cpp:442] iteraion 241 cost 217 ms totallycertain part cost1
I0702 00:36:42.330021 20914 solver.cpp:442] iteraion 242 cost 191 ms totallycertain part cost1
I0702 00:36:42.539822 20914 solver.cpp:442] iteraion 243 cost 209 ms totallycertain part cost1
I0702 00:36:42.696801 20914 solver.cpp:442] iteraion 244 cost 156 ms totallycertain part cost1
I0702 00:36:42.849589 20914 solver.cpp:442] iteraion 245 cost 152 ms totallycertain part cost1
I0702 00:36:43.129101 20914 solver.cpp:442] iteraion 246 cost 279 ms totallycertain part cost1
I0702 00:36:43.284786 20914 solver.cpp:442] iteraion 247 cost 155 ms totallycertain part cost10
I0702 00:36:43.648982 20914 solver.cpp:442] iteraion 248 cost 364 ms totallycertain part cost1
I0702 00:36:44.288671 20914 solver.cpp:442] iteraion 249 cost 639 ms totallycertain part cost1
I0702 00:36:44.473242 20914 solver.cpp:442] iteraion 250 cost 184 ms totallycertain part cost1
I0702 00:36:44.653930 20914 solver.cpp:442] iteraion 251 cost 180 ms totallycertain part cost1
I0702 00:36:44.840956 20914 solver.cpp:442] iteraion 252 cost 186 ms totallycertain part cost1
I0702 00:36:44.995724 20914 solver.cpp:442] iteraion 253 cost 154 ms totallycertain part cost1
I0702 00:36:45.159265 20914 solver.cpp:442] iteraion 254 cost 163 ms totallycertain part cost1
I0702 00:36:45.334661 20914 solver.cpp:442] iteraion 255 cost 175 ms totallycertain part cost1
I0702 00:36:45.486732 20914 solver.cpp:442] iteraion 256 cost 151 ms totallycertain part cost1
I0702 00:36:45.689221 20914 solver.cpp:442] iteraion 257 cost 202 ms totallycertain part cost1
I0702 00:36:45.851042 20914 solver.cpp:442] iteraion 258 cost 161 ms totallycertain part cost1
I0702 00:36:46.019222 20914 solver.cpp:442] iteraion 259 cost 168 ms totallycertain part cost1
I0702 00:36:46.305064 20914 solver.cpp:442] iteraion 260 cost 285 ms totallycertain part cost1
I0702 00:36:47.322118 20914 solver.cpp:442] iteraion 261 cost 1016 ms totallycertain part cost1
I0702 00:36:47.613308 20914 solver.cpp:442] iteraion 262 cost 291 ms totallycertain part cost22
I0702 00:36:47.754472 20914 solver.cpp:442] iteraion 263 cost 141 ms totallycertain part cost1
I0702 00:36:47.994323 20914 solver.cpp:442] iteraion 264 cost 239 ms totallycertain part cost1
I0702 00:36:48.180210 20914 solver.cpp:442] iteraion 265 cost 185 ms totallycertain part cost1
I0702 00:36:48.381732 20914 solver.cpp:442] iteraion 266 cost 201 ms totallycertain part cost1
I0702 00:36:48.651291 20914 solver.cpp:442] iteraion 267 cost 269 ms totallycertain part cost1
I0702 00:36:48.822988 20914 solver.cpp:442] iteraion 268 cost 171 ms totallycertain part cost1
I0702 00:36:49.015465 20914 solver.cpp:442] iteraion 269 cost 192 ms totallycertain part cost1
I0702 00:36:49.264062 20914 solver.cpp:442] iteraion 270 cost 248 ms totallycertain part cost1
I0702 00:36:49.433858 20914 solver.cpp:442] iteraion 271 cost 169 ms totallycertain part cost1
I0702 00:36:49.617341 20914 solver.cpp:442] iteraion 272 cost 183 ms totallycertain part cost1
I0702 00:36:49.764767 20914 solver.cpp:442] iteraion 273 cost 147 ms totallycertain part cost1
I0702 00:36:49.897116 20914 solver.cpp:442] iteraion 274 cost 131 ms totallycertain part cost1
I0702 00:36:50.064965 20914 solver.cpp:442] iteraion 275 cost 167 ms totallycertain part cost1
I0702 00:36:50.342344 20914 solver.cpp:442] iteraion 276 cost 277 ms totallycertain part cost152
I0702 00:36:50.617142 20914 solver.cpp:442] iteraion 277 cost 274 ms totallycertain part cost156
I0702 00:36:50.795140 20914 solver.cpp:442] iteraion 278 cost 177 ms totallycertain part cost57
I0702 00:36:50.972745 20914 solver.cpp:442] iteraion 279 cost 177 ms totallycertain part cost56
I0702 00:36:51.227366 20914 solver.cpp:442] iteraion 280 cost 254 ms totallycertain part cost134
I0702 00:36:51.430409 20914 solver.cpp:442] iteraion 281 cost 202 ms totallycertain part cost83
I0702 00:36:51.605731 20914 solver.cpp:442] iteraion 282 cost 174 ms totallycertain part cost57
I0702 00:36:51.818745 20914 solver.cpp:442] iteraion 283 cost 212 ms totallycertain part cost92
I0702 00:36:51.985610 20914 solver.cpp:442] iteraion 284 cost 166 ms totallycertain part cost46
I0702 00:36:52.193084 20914 solver.cpp:442] iteraion 285 cost 207 ms totallycertain part cost88
I0702 00:36:52.456127 20914 solver.cpp:442] iteraion 286 cost 262 ms totallycertain part cost147
I0702 00:36:52.586457 20914 solver.cpp:442] iteraion 287 cost 130 ms totallycertain part cost10
I0702 00:36:52.764230 20914 solver.cpp:442] iteraion 288 cost 177 ms totallycertain part cost55
I0702 00:36:53.289155 20914 solver.cpp:442] iteraion 289 cost 524 ms totallycertain part cost405
I0702 00:36:53.458324 20914 solver.cpp:442] iteraion 290 cost 168 ms totallycertain part cost50
I0702 00:36:53.594337 20914 solver.cpp:442] iteraion 291 cost 135 ms totallycertain part cost15
I0702 00:36:53.957198 20914 solver.cpp:442] iteraion 292 cost 362 ms totallycertain part cost243
I0702 00:36:54.226064 20914 solver.cpp:442] iteraion 293 cost 268 ms totallycertain part cost149
I0702 00:36:54.392453 20914 solver.cpp:442] iteraion 294 cost 166 ms totallycertain part cost50
I0702 00:36:54.521592 20914 solver.cpp:442] iteraion 295 cost 128 ms totallycertain part cost9
I0702 00:36:54.745445 20914 solver.cpp:442] iteraion 296 cost 223 ms totallycertain part cost110
I0702 00:36:54.913799 20914 solver.cpp:442] iteraion 297 cost 168 ms totallycertain part cost48
I0702 00:36:56.880890 20914 solver.cpp:442] iteraion 298 cost 1966 ms totallycertain part cost1851
I0702 00:36:57.040637 20914 solver.cpp:442] iteraion 299 cost 159 ms totallycertain part cost35
I0702 00:36:57.175101 20914 solver.cpp:417] 300  display time 0 ms.
I0702 00:36:57.175267 20914 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0702 00:36:57.176184 20914 solver.cpp:442] iteraion 300 cost 135 ms totallycertain part cost19
I0702 00:36:57.175539  4701 solver.cpp:235]  rank = 1 Iteration 301 (3.57219 iter/s, 27.994s/100 iters), loss = 1.80782
I0702 00:36:57.175705  4701 solver.cpp:255]     Train net output #0: SoftmaxWithLoss1 = 1.80782 (* 1 = 1.80782 loss)
I0702 00:36:57.187242 22531 solver.cpp:235]  rank = 0 Iteration 301 (3.57156 iter/s, 27.999s/100 iters), loss = 1.92473
I0702 00:36:57.187400 22531 solver.cpp:255]     Train net output #0: SoftmaxWithLoss1 = 1.92473 (* 1 = 1.92473 loss)
I0702 00:36:57.190443  1449 solver.cpp:235]  rank = 2 Iteration 301 (3.5713 iter/s, 28.001s/100 iters), loss = 1.87279
I0702 00:36:57.190505  1449 solver.cpp:255]     Train net output #0: SoftmaxWithLoss1 = 1.87279 (* 1 = 1.87279 loss)
I0702 00:36:57.194461 14659 solver.cpp:235]  rank = 3 Iteration 301 (3.57092 iter/s, 28.004s/100 iters), loss = 1.89082
I0702 00:36:57.194599 14659 solver.cpp:255]     Train net output #0: SoftmaxWithLoss1 = 1.89082 (* 1 = 1.89082 loss)
I0702 00:36:57.412016 20914 solver.cpp:442] iteraion 301 cost 235 ms totallycertain part cost122
I0702 00:36:57.688325 20914 solver.cpp:442] iteraion 302 cost 276 ms totallycertain part cost1
I0702 00:36:57.853514 20914 solver.cpp:442] iteraion 303 cost 164 ms totallycertain part cost1
I0702 00:36:58.063427 20914 solver.cpp:442] iteraion 304 cost 209 ms totallycertain part cost1
I0702 00:36:58.482858 20914 solver.cpp:442] iteraion 305 cost 419 ms totallycertain part cost1
I0702 00:36:58.708248 20914 solver.cpp:442] iteraion 306 cost 225 ms totallycertain part cost1
I0702 00:36:58.846325 20914 solver.cpp:442] iteraion 307 cost 137 ms totallycertain part cost1
I0702 00:36:58.983688 20914 solver.cpp:442] iteraion 308 cost 137 ms totallycertain part cost1
I0702 00:36:59.196058 20914 solver.cpp:442] iteraion 309 cost 212 ms totallycertain part cost1
I0702 00:36:59.429800 20914 solver.cpp:442] iteraion 310 cost 233 ms totallycertain part cost1
I0702 00:36:59.571277 20914 solver.cpp:442] iteraion 311 cost 141 ms totallycertain part cost1
I0702 00:36:59.712942 20914 solver.cpp:442] iteraion 312 cost 141 ms totallycertain part cost1
I0702 00:36:59.849663 20914 solver.cpp:442] iteraion 313 cost 136 ms totallycertain part cost1
I0702 00:37:00.017177 20914 solver.cpp:442] iteraion 314 cost 167 ms totallycertain part cost1
I0702 00:37:00.238458 20914 solver.cpp:442] iteraion 315 cost 221 ms totallycertain part cost1
I0702 00:37:00.370296 20914 solver.cpp:442] iteraion 316 cost 131 ms totallycertain part cost1
I0702 00:37:01.226861 20914 solver.cpp:442] iteraion 317 cost 856 ms totallycertain part cost1
I0702 00:37:01.710882 20914 solver.cpp:442] iteraion 318 cost 483 ms totallycertain part cost310
I0702 00:37:02.675036 20914 solver.cpp:442] iteraion 319 cost 964 ms totallycertain part cost850
I0702 00:37:02.885228 20914 solver.cpp:442] iteraion 320 cost 210 ms totallycertain part cost87
I0702 00:37:03.336606 20914 solver.cpp:442] iteraion 321 cost 451 ms totallycertain part cost328
I0702 00:37:03.463825 20914 solver.cpp:442] iteraion 322 cost 127 ms totallycertain part cost1
I0702 00:37:03.946058 20914 solver.cpp:442] iteraion 323 cost 482 ms totallycertain part cost360
I0702 00:37:04.081486 20914 solver.cpp:442] iteraion 324 cost 135 ms totallycertain part cost10
I0702 00:37:04.253048 20914 solver.cpp:442] iteraion 325 cost 171 ms totallycertain part cost47
I0702 00:37:04.390938 20914 solver.cpp:442] iteraion 326 cost 137 ms totallycertain part cost16
I0702 00:37:04.526074 20914 solver.cpp:442] iteraion 327 cost 135 ms totallycertain part cost10
I0702 00:37:04.676401 20914 solver.cpp:442] iteraion 328 cost 150 ms totallycertain part cost25
I0702 00:37:04.821174 20914 solver.cpp:442] iteraion 329 cost 144 ms totallycertain part cost22
I0702 00:37:05.000766 20914 solver.cpp:442] iteraion 330 cost 179 ms totallycertain part cost56
I0702 00:37:05.344462 20914 solver.cpp:442] iteraion 331 cost 343 ms totallycertain part cost218
I0702 00:37:05.498682 20914 solver.cpp:442] iteraion 332 cost 154 ms totallycertain part cost27
I0702 00:37:05.634588 20914 solver.cpp:442] iteraion 333 cost 135 ms totallycertain part cost9
I0702 00:37:05.780587 20914 solver.cpp:442] iteraion 334 cost 145 ms totallycertain part cost20
I0702 00:37:05.974102 20914 solver.cpp:442] iteraion 335 cost 193 ms totallycertain part cost70
I0702 00:37:06.194332 20914 solver.cpp:442] iteraion 336 cost 220 ms totallycertain part cost95
I0702 00:37:06.336153 20914 solver.cpp:442] iteraion 337 cost 141 ms totallycertain part cost18
I0702 00:37:06.487998 20914 solver.cpp:442] iteraion 338 cost 151 ms totallycertain part cost37
I0702 00:37:06.737720 20914 solver.cpp:442] iteraion 339 cost 249 ms totallycertain part cost136
I0702 00:37:06.964589 20914 solver.cpp:442] iteraion 340 cost 226 ms totallycertain part cost1
I0702 00:37:07.131706 20914 solver.cpp:442] iteraion 341 cost 166 ms totallycertain part cost1
I0702 00:37:07.287209 20914 solver.cpp:442] iteraion 342 cost 155 ms totallycertain part cost4
I0702 00:37:09.087087 20914 solver.cpp:442] iteraion 343 cost 1799 ms totallycertain part cost1658
I0702 00:37:09.281870 20914 solver.cpp:442] iteraion 344 cost 194 ms totallycertain part cost70
I0702 00:37:09.404489 20914 solver.cpp:442] iteraion 345 cost 122 ms totallycertain part cost1
I0702 00:37:10.026412 20914 solver.cpp:442] iteraion 346 cost 621 ms totallycertain part cost497
I0702 00:37:10.169003 20914 solver.cpp:442] iteraion 347 cost 142 ms totallycertain part cost24
I0702 00:37:10.310822 20914 solver.cpp:442] iteraion 348 cost 141 ms totallycertain part cost20
I0702 00:37:10.440665 20914 solver.cpp:442] iteraion 349 cost 129 ms totallycertain part cost7
I0702 00:37:10.565814 20914 solver.cpp:442] iteraion 350 cost 125 ms totallycertain part cost1
I0702 00:37:10.746450 20914 solver.cpp:442] iteraion 351 cost 180 ms totallycertain part cost53
I0702 00:37:10.879578 20914 solver.cpp:442] iteraion 352 cost 133 ms totallycertain part cost7
I0702 00:37:11.006052 20914 solver.cpp:442] iteraion 353 cost 126 ms totallycertain part cost1
I0702 00:37:11.266887 20914 solver.cpp:442] iteraion 354 cost 260 ms totallycertain part cost141
I0702 00:37:11.527645 20914 solver.cpp:442] iteraion 355 cost 260 ms totallycertain part cost138
I0702 00:37:11.662436 20914 solver.cpp:442] iteraion 356 cost 134 ms totallycertain part cost18
I0702 00:37:11.794404 20914 solver.cpp:442] iteraion 357 cost 131 ms totallycertain part cost1
I0702 00:37:11.926596 20914 solver.cpp:442] iteraion 358 cost 132 ms totallycertain part cost9
I0702 00:37:12.080317 20914 solver.cpp:442] iteraion 359 cost 153 ms totallycertain part cost25
I0702 00:37:12.215232 20914 solver.cpp:442] iteraion 360 cost 134 ms totallycertain part cost9
I0702 00:37:12.353976 20914 solver.cpp:442] iteraion 361 cost 138 ms totallycertain part cost11
I0702 00:37:12.537437 20914 solver.cpp:442] iteraion 362 cost 183 ms totallycertain part cost55
I0702 00:37:12.686003 20914 solver.cpp:442] iteraion 363 cost 148 ms totallycertain part cost22
I0702 00:37:12.878648 20914 solver.cpp:442] iteraion 364 cost 192 ms totallycertain part cost65
I0702 00:37:13.008147 20914 solver.cpp:442] iteraion 365 cost 129 ms totallycertain part cost3
I0702 00:37:13.200085 20914 solver.cpp:442] iteraion 366 cost 191 ms totallycertain part cost66
I0702 00:37:13.394402 20914 solver.cpp:442] iteraion 367 cost 194 ms totallycertain part cost67
I0702 00:37:13.594521 20914 solver.cpp:442] iteraion 368 cost 199 ms totallycertain part cost78
I0702 00:37:13.724680 20914 solver.cpp:442] iteraion 369 cost 130 ms totallycertain part cost16
I0702 00:37:14.380347 20914 solver.cpp:442] iteraion 370 cost 655 ms totallycertain part cost542
I0702 00:37:15.020550 20914 solver.cpp:442] iteraion 371 cost 640 ms totallycertain part cost210
I0702 00:37:15.514542 20914 solver.cpp:442] iteraion 372 cost 493 ms totallycertain part cost375
I0702 00:37:15.661283 20914 solver.cpp:442] iteraion 373 cost 146 ms totallycertain part cost28
I0702 00:37:15.810240 20914 solver.cpp:442] iteraion 374 cost 148 ms totallycertain part cost31
I0702 00:37:15.945853 20914 solver.cpp:442] iteraion 375 cost 135 ms totallycertain part cost5
I0702 00:37:16.173336 20914 solver.cpp:442] iteraion 376 cost 227 ms totallycertain part cost107
I0702 00:37:16.362483 20914 solver.cpp:442] iteraion 377 cost 189 ms totallycertain part cost69
I0702 00:37:16.499375 20914 solver.cpp:442] iteraion 378 cost 136 ms totallycertain part cost17
I0702 00:37:16.630794 20914 solver.cpp:442] iteraion 379 cost 131 ms totallycertain part cost13
I0702 00:37:16.842870 20914 solver.cpp:442] iteraion 380 cost 211 ms totallycertain part cost89
I0702 00:37:17.052676 20914 solver.cpp:442] iteraion 381 cost 209 ms totallycertain part cost91
I0702 00:37:17.273588 20914 solver.cpp:442] iteraion 382 cost 220 ms totallycertain part cost101
I0702 00:37:17.407297 20914 solver.cpp:442] iteraion 383 cost 133 ms totallycertain part cost14
I0702 00:37:17.589717 20914 solver.cpp:442] iteraion 384 cost 182 ms totallycertain part cost64
I0702 00:37:17.744983 20914 solver.cpp:442] iteraion 385 cost 155 ms totallycertain part cost38
I0702 00:37:17.886951 20914 solver.cpp:442] iteraion 386 cost 141 ms totallycertain part cost23
I0702 00:37:18.016837 20931 image_data_layer.cpp:188] Restarting data prefetching from start.
I0702 00:37:18.082293 20914 solver.cpp:442] iteraion 387 cost 195 ms totallycertain part cost74
I0702 00:37:18.227854 20914 solver.cpp:442] iteraion 388 cost 145 ms totallycertain part cost28
I0702 00:37:18.389219 20914 solver.cpp:442] iteraion 389 cost 161 ms totallycertain part cost41
I0702 00:37:18.513279 20914 solver.cpp:442] iteraion 390 cost 123 ms totallycertain part cost5
I0702 00:37:18.633994 20914 solver.cpp:442] iteraion 391 cost 120 ms totallycertain part cost1
I0702 00:37:19.761355 20914 solver.cpp:442] iteraion 392 cost 1127 ms totallycertain part cost1012
I0702 00:37:19.887383 20914 solver.cpp:442] iteraion 393 cost 125 ms totallycertain part cost8
I0702 00:37:20.010326 20914 solver.cpp:442] iteraion 394 cost 122 ms totallycertain part cost8
I0702 00:37:20.137888 20914 solver.cpp:442] iteraion 395 cost 127 ms totallycertain part cost11
I0702 00:37:21.144704 20914 solver.cpp:442] iteraion 396 cost 1006 ms totallycertain part cost893
I0702 00:37:21.878105 20914 solver.cpp:442] iteraion 397 cost 733 ms totallycertain part cost1
I0702 00:37:22.866488 20914 solver.cpp:442] iteraion 398 cost 988 ms totallycertain part cost875
I0702 00:37:23.079579 20914 solver.cpp:442] iteraion 399 cost 212 ms totallycertain part cost96
I0702 00:37:23.225839 20914 solver.cpp:417] 400  display time 0 ms.
I0702 00:37:23.225963 20914 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0702 00:37:23.226861 20914 solver.cpp:442] iteraion 400 cost 147 ms totallycertain part cost31
I0702 00:37:23.232137 14660 solver.cpp:235]  rank = 3 Iteration 401 (3.84069 iter/s, 26.037s/100 iters), loss = 1.85732
I0702 00:37:23.232064  4702 solver.cpp:235]  rank = 1 Iteration 401 (3.83789 iter/s, 26.056s/100 iters), loss = 1.50768
I0702 00:37:23.232234  4702 solver.cpp:255]     Train net output #0: SoftmaxWithLoss1 = 1.50768 (* 1 = 1.50768 loss)
I0702 00:37:23.232928 22532 solver.cpp:235]  rank = 0 Iteration 401 (3.83951 iter/s, 26.045s/100 iters), loss = 1.61443
I0702 00:37:23.233052 22532 solver.cpp:255]     Train net output #0: SoftmaxWithLoss1 = 1.61443 (* 1 = 1.61443 loss)
I0702 00:37:23.233875  1450 solver.cpp:235]  rank = 2 Iteration 401 (3.8398 iter/s, 26.043s/100 iters), loss = 1.55122
I0702 00:37:23.233932  1450 solver.cpp:255]     Train net output #0: SoftmaxWithLoss1 = 1.55122 (* 1 = 1.55122 loss)
I0702 00:37:23.235028 14660 solver.cpp:255]     Train net output #0: SoftmaxWithLoss1 = 1.85732 (* 1 = 1.85732 loss)
I0702 00:37:23.380125 20914 solver.cpp:442] iteraion 401 cost 153 ms totallycertain part cost35
I0702 00:37:23.515926 20914 solver.cpp:442] iteraion 402 cost 135 ms totallycertain part cost17
I0702 00:37:23.684937 20914 solver.cpp:442] iteraion 403 cost 168 ms totallycertain part cost51
I0702 00:37:23.809547 20914 solver.cpp:442] iteraion 404 cost 124 ms totallycertain part cost5
I0702 00:37:23.936363 20914 solver.cpp:442] iteraion 405 cost 126 ms totallycertain part cost9
I0702 00:37:24.061802 20914 solver.cpp:442] iteraion 406 cost 125 ms totallycertain part cost9
I0702 00:37:24.189010 20914 solver.cpp:442] iteraion 407 cost 127 ms totallycertain part cost9
I0702 00:37:24.310621 20914 solver.cpp:442] iteraion 408 cost 121 ms totallycertain part cost5
I0702 00:37:24.432296 20914 solver.cpp:442] iteraion 409 cost 121 ms totallycertain part cost3
I0702 00:37:24.561969 20914 solver.cpp:442] iteraion 410 cost 129 ms totallycertain part cost12
I0702 00:37:24.693624 20914 solver.cpp:442] iteraion 411 cost 131 ms totallycertain part cost11
I0702 00:37:24.818209 20914 solver.cpp:442] iteraion 412 cost 124 ms totallycertain part cost8
I0702 00:37:24.943668 20914 solver.cpp:442] iteraion 413 cost 125 ms totallycertain part cost8
I0702 00:37:25.072177 20914 solver.cpp:442] iteraion 414 cost 128 ms totallycertain part cost15
I0702 00:37:25.311780 20914 solver.cpp:442] iteraion 415 cost 239 ms totallycertain part cost1
I0702 00:37:25.447371 20914 solver.cpp:442] iteraion 416 cost 135 ms totallycertain part cost1
I0702 00:37:25.604311 20914 solver.cpp:442] iteraion 417 cost 156 ms totallycertain part cost1
I0702 00:37:25.749244 20914 solver.cpp:442] iteraion 418 cost 144 ms totallycertain part cost2
I0702 00:37:25.880311 20914 solver.cpp:442] iteraion 419 cost 130 ms totallycertain part cost14
I0702 00:37:26.106572 20914 solver.cpp:442] iteraion 420 cost 226 ms totallycertain part cost1
I0702 00:37:26.232672 20914 solver.cpp:442] iteraion 421 cost 125 ms totallycertain part cost8
I0702 00:37:26.356920 20914 solver.cpp:442] iteraion 422 cost 124 ms totallycertain part cost6
I0702 00:37:26.531255 20914 solver.cpp:442] iteraion 423 cost 174 ms totallycertain part cost1
I0702 00:37:26.649324 20914 solver.cpp:442] iteraion 424 cost 117 ms totallycertain part cost4
I0702 00:37:26.995730 20914 solver.cpp:442] iteraion 425 cost 346 ms totallycertain part cost1
I0702 00:37:27.450609 20914 solver.cpp:442] iteraion 426 cost 454 ms totallycertain part cost335
I0702 00:37:27.647320 20914 solver.cpp:442] iteraion 427 cost 196 ms totallycertain part cost78
I0702 00:37:27.806200 20914 solver.cpp:442] iteraion 428 cost 158 ms totallycertain part cost41
I0702 00:37:28.016358 20914 solver.cpp:442] iteraion 429 cost 210 ms totallycertain part cost89
I0702 00:37:28.142802 20914 solver.cpp:442] iteraion 430 cost 126 ms totallycertain part cost7
I0702 00:37:28.269191 20914 solver.cpp:442] iteraion 431 cost 126 ms totallycertain part cost5
I0702 00:37:28.552831 20914 solver.cpp:442] iteraion 432 cost 283 ms totallycertain part cost163
I0702 00:37:28.678835 20914 solver.cpp:442] iteraion 433 cost 125 ms totallycertain part cost6
I0702 00:37:28.808230 20914 solver.cpp:442] iteraion 434 cost 129 ms totallycertain part cost9
I0702 00:37:28.933733 20914 solver.cpp:442] iteraion 435 cost 125 ms totallycertain part cost5
I0702 00:37:29.062880 20914 solver.cpp:442] iteraion 436 cost 128 ms totallycertain part cost9
I0702 00:37:29.187402 20914 solver.cpp:442] iteraion 437 cost 124 ms totallycertain part cost3
I0702 00:37:29.325376 20914 solver.cpp:442] iteraion 438 cost 137 ms totallycertain part cost19
I0702 00:37:29.455847 20914 solver.cpp:442] iteraion 439 cost 130 ms totallycertain part cost14
I0702 00:37:29.899237 20914 solver.cpp:442] iteraion 440 cost 443 ms totallycertain part cost323
I0702 00:37:30.025593 20914 solver.cpp:442] iteraion 441 cost 126 ms totallycertain part cost6
I0702 00:37:30.150080 20914 solver.cpp:442] iteraion 442 cost 124 ms totallycertain part cost6
I0702 00:37:30.275629 20914 solver.cpp:442] iteraion 443 cost 125 ms totallycertain part cost5
I0702 00:37:30.413580 20914 solver.cpp:442] iteraion 444 cost 137 ms totallycertain part cost18
I0702 00:37:30.540491 20914 solver.cpp:442] iteraion 445 cost 126 ms totallycertain part cost7
I0702 00:37:30.662426 20914 solver.cpp:442] iteraion 446 cost 121 ms totallycertain part cost1
I0702 00:37:30.946750 20914 solver.cpp:442] iteraion 447 cost 284 ms totallycertain part cost170
I0702 00:37:31.073391 20914 solver.cpp:442] iteraion 448 cost 126 ms totallycertain part cost6
I0702 00:37:31.195345 20914 solver.cpp:442] iteraion 449 cost 121 ms totallycertain part cost5
I0702 00:37:31.706288 20914 solver.cpp:442] iteraion 450 cost 510 ms totallycertain part cost391
I0702 00:37:31.835224 20914 solver.cpp:442] iteraion 451 cost 128 ms totallycertain part cost1
I0702 00:37:32.055951 20914 solver.cpp:442] iteraion 452 cost 220 ms totallycertain part cost100
I0702 00:37:32.197332 20914 solver.cpp:442] iteraion 453 cost 141 ms totallycertain part cost21
I0702 00:37:32.316576 20914 solver.cpp:442] iteraion 454 cost 119 ms totallycertain part cost1
I0702 00:37:32.782532 20914 solver.cpp:442] iteraion 455 cost 465 ms totallycertain part cost350
I0702 00:37:32.905376 20914 solver.cpp:442] iteraion 456 cost 122 ms totallycertain part cost4
I0702 00:37:33.171411 20914 solver.cpp:442] iteraion 457 cost 265 ms totallycertain part cost147
I0702 00:37:33.295385 20914 solver.cpp:442] iteraion 458 cost 123 ms totallycertain part cost7
I0702 00:37:33.418838 20914 solver.cpp:442] iteraion 459 cost 123 ms totallycertain part cost2
I0702 00:37:33.754628 20914 solver.cpp:442] iteraion 460 cost 335 ms totallycertain part cost219
I0702 00:37:33.876437 20914 solver.cpp:442] iteraion 461 cost 121 ms totallycertain part cost3
I0702 00:37:33.998921 20914 solver.cpp:442] iteraion 462 cost 122 ms totallycertain part cost5
I0702 00:37:34.121080 20914 solver.cpp:442] iteraion 463 cost 122 ms totallycertain part cost3
I0702 00:37:34.242928 20914 solver.cpp:442] iteraion 464 cost 121 ms totallycertain part cost3
I0702 00:37:34.366808 20914 solver.cpp:442] iteraion 465 cost 123 ms totallycertain part cost4
I0702 00:37:34.492122 20914 solver.cpp:442] iteraion 466 cost 125 ms totallycertain part cost7
I0702 00:37:34.614600 20914 solver.cpp:442] iteraion 467 cost 122 ms totallycertain part cost3
I0702 00:37:34.738745 20914 solver.cpp:442] iteraion 468 cost 124 ms totallycertain part cost6
I0702 00:37:34.859539 20914 solver.cpp:442] iteraion 469 cost 120 ms totallycertain part cost2
I0702 00:37:34.980669 20914 solver.cpp:442] iteraion 470 cost 120 ms totallycertain part cost2
I0702 00:37:35.108685 20914 solver.cpp:442] iteraion 471 cost 127 ms totallycertain part cost7
I0702 00:37:35.234051 20914 solver.cpp:442] iteraion 472 cost 125 ms totallycertain part cost7
I0702 00:37:35.356472 20914 solver.cpp:442] iteraion 473 cost 122 ms totallycertain part cost4
I0702 00:37:35.480659 20914 solver.cpp:442] iteraion 474 cost 124 ms totallycertain part cost5
I0702 00:37:35.604670 20914 solver.cpp:442] iteraion 475 cost 123 ms totallycertain part cost4
I0702 00:37:35.727948 20914 solver.cpp:442] iteraion 476 cost 123 ms totallycertain part cost5
I0702 00:37:35.853016 20914 solver.cpp:442] iteraion 477 cost 124 ms totallycertain part cost6
I0702 00:37:35.982750 20914 solver.cpp:442] iteraion 478 cost 129 ms totallycertain part cost12
I0702 00:37:36.106060 20914 solver.cpp:442] iteraion 479 cost 123 ms totallycertain part cost3
I0702 00:37:36.228427 20914 solver.cpp:442] iteraion 480 cost 122 ms totallycertain part cost3
I0702 00:37:36.350493 20914 solver.cpp:442] iteraion 481 cost 121 ms totallycertain part cost4
I0702 00:37:36.471994 20914 solver.cpp:442] iteraion 482 cost 121 ms totallycertain part cost1
I0702 00:37:36.593786 20914 solver.cpp:442] iteraion 483 cost 121 ms totallycertain part cost3
I0702 00:37:36.716763 20914 solver.cpp:442] iteraion 484 cost 122 ms totallycertain part cost4
I0702 00:37:36.842531 20914 solver.cpp:442] iteraion 485 cost 125 ms totallycertain part cost1
I0702 00:37:36.963285 20914 solver.cpp:442] iteraion 486 cost 120 ms totallycertain part cost2
I0702 00:37:37.382417 20914 solver.cpp:442] iteraion 487 cost 418 ms totallycertain part cost299
I0702 00:37:37.915688 20914 solver.cpp:442] iteraion 488 cost 533 ms totallycertain part cost417
yhrun: Job step aborted: Waiting up to 2 seconds for job step to finish.
*** Aborted at 1530463057 (unix time) try "date -d @1530463057" if you are using GNU date ***
PC: @     0x2b2a2371a0f2 __kmp_x86_pause
*** SIGTERM (@0x1232) received by PID 4664 (TID 0x2b2a258968a0) from PID 4658; stack trace: ***
    @       0x392220f710 (unknown)
    @     0x2b2a2371a0f2 __kmp_x86_pause
yhrun: got SIGCONT
slurmd[cn9640]: *** STEP 5818141.0 CANCELLED AT 2018-07-02T00:37:37 ***
*** Aborted at 1530463057 (unix time) try "date -d @1530463057" if you are using GNU date ***
PC: @     0x2b2407df7681 __kmp_wait_sleep
*** Aborted at 1530463057 (unix time) try "date -d @1530463057" if you are using GNU date ***
PC: @     0x2b7f852b76a6 __kmp_wait_sleep
*** Aborted at 1530463057 (unix time) try "date -d @1530463057" if you are using GNU date ***
PC: @     0x2b8c837eb7d8 __kmp_wait_sleep
yhrun: forcing job termination
